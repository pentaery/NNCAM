{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 加载数据\n",
    "dataset = nc.Dataset('../data/io_ML_10t.nc')\n",
    "\n",
    "# 定义输入和输出变量列表\n",
    "input_vars = {\n",
    "    \"U\": dataset.variables[\"U\"][:],\n",
    "    \"V\": dataset.variables[\"V\"][:],\n",
    "    \"T\": dataset.variables[\"T\"][:],\n",
    "    \"Q\": dataset.variables[\"Q\"][:],\n",
    "    \"CLDLIQ\": dataset.variables[\"CLDLIQ\"][:],\n",
    "    \"CLDICE\": dataset.variables[\"CLDICE\"][:],\n",
    "    \"NUMLIQ\": dataset.variables[\"NUMLIQ\"][:],\n",
    "    \"NUMICE\": dataset.variables[\"NUMICE\"][:],\n",
    "    \"PS\": np.expand_dims(dataset.variables[\"PS\"], axis=1),\n",
    "    \"PMID\": dataset.variables[\"PMID\"][:],\n",
    "    \"DPRES\": dataset.variables[\"DPRES\"][:],\n",
    "    \"Z3\": dataset.variables[\"Z3\"][:],\n",
    "    \"HEIGHT\": dataset.variables[\"HEIGHT\"][:],\n",
    "    \"TAUX\": np.expand_dims(dataset.variables[\"TAUX\"], axis=1),\n",
    "    \"TAUY\": np.expand_dims(dataset.variables[\"TAUY\"], axis=1),\n",
    "    \"SHFLX\": np.expand_dims(dataset.variables[\"SHFLX\"], axis=1),\n",
    "    \"LHFLX\": np.expand_dims(dataset.variables[\"LHFLX\"], axis=1)\n",
    "}\n",
    "\n",
    "output_vars = {\n",
    "    \"SPDQ\": dataset.variables[\"SPDQ\"][:],\n",
    "    \"SPDQC\": dataset.variables[\"SPDQC\"][:],\n",
    "    \"SPDQI\": dataset.variables[\"SPDQI\"][:],\n",
    "    \"SPNC\": dataset.variables[\"SPNC\"][:],\n",
    "    \"SPNI\": dataset.variables[\"SPNI\"][:],\n",
    "    \"SPDT\": dataset.variables[\"SPDT\"][:],\n",
    "    \"CLOUD\": dataset.variables[\"CLOUD\"][:],\n",
    "    \"CLDTOT\": np.expand_dims(dataset.variables[\"CLDTOT\"], axis=1),\n",
    "    \"CLDHGH\": np.expand_dims(dataset.variables[\"CLDHGH\"], axis=1),\n",
    "    \"CLDMED\": np.expand_dims(dataset.variables[\"CLDMED\"], axis=1),\n",
    "    \"CLDLOW\": np.expand_dims(dataset.variables[\"CLDLOW\"], axis=1),\n",
    "    \"PRECC\": np.expand_dims(dataset.variables[\"PRECC\"], axis=1),\n",
    "    \"PRECSC\": np.expand_dims(dataset.variables[\"PRECSC\"], axis=1),\n",
    "    \"CLOUDTOP\": dataset.variables[\"CLOUDTOP\"][:],\n",
    "    \"QRL\": dataset.variables[\"QRL\"][:],\n",
    "    \"QRS\": dataset.variables[\"QRS\"][:],\n",
    "    \"FSNT\": np.expand_dims(dataset.variables[\"FSNT\"], axis=1),\n",
    "    \"FSDS\": np.expand_dims(dataset.variables[\"FSDS\"], axis=1),\n",
    "    \"FSNS\": np.expand_dims(dataset.variables[\"FSNS\"], axis=1),\n",
    "    \"FLNS\": np.expand_dims(dataset.variables[\"FLNS\"], axis=1),\n",
    "    \"FLNT\": np.expand_dims(dataset.variables[\"FLNT\"], axis=1)\n",
    "}\n",
    "\n",
    "# 合并输入和输出数据\n",
    "input = np.concatenate(list(input_vars.values()), axis=1, dtype=np.float32)\n",
    "output = np.concatenate(list(output_vars.values()), axis=1, dtype=np.float32)\n",
    "\n",
    "# 重塑数据\n",
    "input_reshaped_train = input[:9,:,:,:].reshape((input.shape[1], -1))\n",
    "input_reshaped_test = input[9:,:,:,:].reshape((input.shape[1], -1))\n",
    "output_reshaped_train = output[:9,:,:,:].reshape((output.shape[1], -1))\n",
    "output_reshaped_test = output[9:,:,:,:].reshape((output.shape[1], -1))\n",
    "\n",
    "# 定义归一化函数\n",
    "def normalize_data(data, method='range', **kwargs):\n",
    "    \"\"\"\n",
    "    对数据进行归一化\n",
    "    参数:\n",
    "        data: 输入数据 (n_features, n_samples)\n",
    "        method: 归一化方法 ('range', 'std', 'minmax', 'zscore')\n",
    "        kwargs: 其他参数（如 min_value, max_value)\n",
    "    返回:\n",
    "        归一化后的数据\n",
    "    \"\"\"\n",
    "    if method == 'meanrange':  # (x - mean) / (max - min)\n",
    "        row_means = np.mean(data, axis=1, keepdims=True)\n",
    "        row_max = np.max(data, axis=1, keepdims=True)\n",
    "        row_min = np.min(data, axis=1, keepdims=True)\n",
    "        row_range = row_max - row_min\n",
    "        row_range[row_range == 0] = 1  # 防止除以 0\n",
    "        return (data - row_means) / row_range\n",
    "    \n",
    "    elif method == 'range':  # (x - min) / (max - min)\n",
    "        row_max = np.max(data, axis=1, keepdims=True)\n",
    "        row_min = np.min(data, axis=1, keepdims=True)\n",
    "        row_range = row_max - row_min\n",
    "        row_range[row_range == 0] = 1\n",
    "        return (data - row_min) / row_range\n",
    "    \n",
    "    elif method == 'std':  # x / std\n",
    "        row_std = np.std(data, axis=1, keepdims=True)\n",
    "        row_std[row_std == 0] = 1  # 防止除以 0\n",
    "        row_max = np.max(data, axis=1, keepdims=True)\n",
    "        row_min = np.min(data, axis=1, keepdims=True)\n",
    "        row_range = row_max - row_min\n",
    "        row_range[row_range == 0] = 1\n",
    "        return data / row_range\n",
    "    \n",
    "    elif method == 'exponential':\n",
    "        # 掩盖小于等于 1e-7 的值\n",
    "        masked_data = np.ma.masked_where(data <= 1e-7, data)\n",
    "        # 沿着 axis=1 计算均值，忽略掩盖的值\n",
    "        row_means = np.ma.mean(masked_data, axis=1, keepdims=True)\n",
    "        # 将掩盖后的均值（nan）替换为默认值（例如 1.0）\n",
    "        row_means = np.where(np.ma.getmask(row_means), 1.0, row_means.filled(1.0))\n",
    "        lam = 1 / row_means\n",
    "        return 1 - np.exp(-lam * data)\n",
    "    \n",
    "    elif method == \"logarithm\":\n",
    "        data_positive = np.where(data <= 0, 1e-10, data)  # Replace zeros/negatives with small positive value\n",
    "        log_data = np.log(data_positive)\n",
    "        row_means = np.mean(log_data, axis=1, keepdims=True)\n",
    "        row_max = np.max(log_data, axis=1, keepdims=True)\n",
    "        row_min = np.min(log_data, axis=1, keepdims=True)\n",
    "        row_range = row_max - row_min\n",
    "        row_range[row_range == 0] = 1  # Prevent division by zero\n",
    "        return (log_data - row_means) / row_range\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "\n",
    "# 如果需要对特定变量应用不同归一化，可以按变量拆分处理\n",
    "def normalize_by_variable(vars_dict, reshaped_data, method_dict):\n",
    "    \"\"\"\n",
    "    按变量类型应用不同归一化\n",
    "    参数:\n",
    "        vars_dict: 变量字典\n",
    "        reshaped_data: 重塑后的数据\n",
    "        method_dict: 变量名到归一化方法的映射\n",
    "    返回:\n",
    "        归一化后的数据\n",
    "    \"\"\"\n",
    "    start_idx = 0\n",
    "    normalized_chunks = []\n",
    "    for var_name, var_data in vars_dict.items():\n",
    "        var_size = var_data.shape[1]  # 每个变量的特征数\n",
    "        chunk = reshaped_data[start_idx:start_idx + var_size, :]\n",
    "        method = method_dict.get(var_name, 'range')  # 默认使用 'range'\n",
    "        normalized_chunk = normalize_data(chunk, method=method)\n",
    "        normalized_chunks.append(normalized_chunk)\n",
    "        start_idx += var_size\n",
    "    return np.concatenate(normalized_chunks, axis=0)\n",
    "\n",
    "# 示例：为不同变量指定不同归一化方法\n",
    "input_method_dict = {\n",
    "    \"U\": \"meanrange\", \n",
    "    \"V\": \"meanrange\",\n",
    "    \"T\": \"meanrange\", \n",
    "    \"Q\": \"meanrange\",\n",
    "    \"CLDLIQ\": \"exponential\",\n",
    "    \"CLDICE\": \"exponential\",\n",
    "    \"NUMLIQ\": \"logarithm\",\n",
    "    \"NUMICE\": \"logarithm\",\n",
    "    \"PS\": \"meanrange\",\n",
    "    \"PMID\": \"meanrange\",\n",
    "    \"DPRES\": \"meanrange\",\n",
    "    \"Z3\": \"meanrange\",\n",
    "    \"HEIGHT\": \"meanrange\",\n",
    "    \"TAUX\": \"meanrange\",\n",
    "    \"TAUY\": \"meanrange\",\n",
    "    \"SHFLX\": \"meanrange\",\n",
    "    \"LHFLX\": \"meanrange\"\n",
    "}\n",
    "\n",
    "output_method_dict = {\n",
    "    \"SPDQ\": \"std\",\n",
    "    \"SPDQC\": \"std\",\n",
    "    \"SPDQI\": \"std\",\n",
    "    \"SPNC\": \"std\",\n",
    "    \"SPNI\": \"std\",\n",
    "    \"SPDT\": \"std\",\n",
    "    \"PRECC\": \"std\",\n",
    "    \"PRECSC\": \"std\",\n",
    "    \"QRL\": \"std\",\n",
    "    \"QRS\": \"std\",\n",
    "    \"FSNT\": \"std\",\n",
    "    \"FSDS\": \"std\",\n",
    "    \"FSNS\": \"std\",\n",
    "    \"FLNS\": \"std\",\n",
    "    \"FLNT\": \"std\",\n",
    "}\n",
    "\n",
    "# 按变量归一化\n",
    "normalized_input_train = normalize_by_variable(input_vars, input_reshaped_train, input_method_dict)\n",
    "normalized_input_test = normalize_by_variable(input_vars, input_reshaped_test, input_method_dict)\n",
    "normalized_output_train = normalize_by_variable(output_vars, output_reshaped_train, output_method_dict)\n",
    "normalized_output_test = normalize_by_variable(output_vars, output_reshaped_test, output_method_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(311, 221184)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_output_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "0.509274\n",
      "0.3333392\n"
     ]
    }
   ],
   "source": [
    "row = 213\n",
    "print(np.max(normalized_output_test[row]))\n",
    "print(np.min(normalized_output_test[row]))\n",
    "print(np.mean(normalized_output_test[row]))\n",
    "print(np.std(normalized_output_test[row]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366, 1990656)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_reshaped_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(311, 221184)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_output_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(normalized_input_train).float()\n",
    "Y_train = torch.from_numpy(normalized_output_train).float()\n",
    "X_test = torch.from_numpy(normalized_input_test).float()\n",
    "Y_test = torch.from_numpy(normalized_output_test).float()\n",
    "train_dataset = TensorDataset(X_train.T, Y_train.T)\n",
    "test_dataset = TensorDataset(X_test.T, Y_test.T)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(366, 384) \n",
    "        self.fc2 = nn.Linear(384, 512) \n",
    "        self.fc3 = nn.Linear(512, 384)  \n",
    "        self.fc4 = nn.Linear(384, 311)\n",
    "\n",
    "        \n",
    "        # 定义 LeakyReLU，默认负斜率为 0.01\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))  \n",
    "        x = self.relu(self.fc2(x))  \n",
    "        x = self.relu(self.fc3(x))  \n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可用的 GPU 数量: 2\n"
     ]
    }
   ],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"可用的 GPU 数量: {num_gpus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyNetwork()\n",
    "# model = nn.DataParallel(model)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion = nn.MSELoss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总参数数量: 654775\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"总参数数量: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Batch [10/1944], Loss: 0.2862\n",
      "Epoch [1/15], Batch [20/1944], Loss: 0.1838\n",
      "Epoch [1/15], Batch [30/1944], Loss: 0.0676\n",
      "Epoch [1/15], Batch [40/1944], Loss: 0.0425\n",
      "Epoch [1/15], Batch [50/1944], Loss: 0.0404\n",
      "Epoch [1/15], Batch [60/1944], Loss: 0.0387\n",
      "Epoch [1/15], Batch [70/1944], Loss: 0.0274\n",
      "Epoch [1/15], Batch [80/1944], Loss: 0.0176\n",
      "Epoch [1/15], Batch [90/1944], Loss: 0.0241\n",
      "Epoch [1/15], Batch [100/1944], Loss: 0.0225\n",
      "Epoch [1/15], Batch [110/1944], Loss: 0.0252\n",
      "Epoch [1/15], Batch [120/1944], Loss: 0.0224\n",
      "Epoch [1/15], Batch [130/1944], Loss: 0.0228\n",
      "Epoch [1/15], Batch [140/1944], Loss: 0.0206\n",
      "Epoch [1/15], Batch [150/1944], Loss: 0.0187\n",
      "Epoch [1/15], Batch [160/1944], Loss: 0.0251\n",
      "Epoch [1/15], Batch [170/1944], Loss: 0.0315\n",
      "Epoch [1/15], Batch [180/1944], Loss: 0.0266\n",
      "Epoch [1/15], Batch [190/1944], Loss: 0.0268\n",
      "Epoch [1/15], Batch [200/1944], Loss: 0.0213\n",
      "Epoch [1/15], Batch [210/1944], Loss: 0.0181\n",
      "Epoch [1/15], Batch [220/1944], Loss: 0.0768\n",
      "Epoch [1/15], Batch [230/1944], Loss: 0.0403\n",
      "Epoch [1/15], Batch [240/1944], Loss: 0.0425\n",
      "Epoch [1/15], Batch [250/1944], Loss: 0.0318\n",
      "Epoch [1/15], Batch [260/1944], Loss: 0.0287\n",
      "Epoch [1/15], Batch [270/1944], Loss: 0.0341\n",
      "Epoch [1/15], Batch [280/1944], Loss: 0.0278\n",
      "Epoch [1/15], Batch [290/1944], Loss: 0.0180\n",
      "Epoch [1/15], Batch [300/1944], Loss: 0.0163\n",
      "Epoch [1/15], Batch [310/1944], Loss: 0.0251\n",
      "Epoch [1/15], Batch [320/1944], Loss: 0.0193\n",
      "Epoch [1/15], Batch [330/1944], Loss: 0.0241\n",
      "Epoch [1/15], Batch [340/1944], Loss: 0.0177\n",
      "Epoch [1/15], Batch [350/1944], Loss: 0.0184\n",
      "Epoch [1/15], Batch [360/1944], Loss: 0.0176\n",
      "Epoch [1/15], Batch [370/1944], Loss: 0.0178\n",
      "Epoch [1/15], Batch [380/1944], Loss: 0.0273\n",
      "Epoch [1/15], Batch [390/1944], Loss: 0.0295\n",
      "Epoch [1/15], Batch [400/1944], Loss: 0.0255\n",
      "Epoch [1/15], Batch [410/1944], Loss: 0.0233\n",
      "Epoch [1/15], Batch [420/1944], Loss: 0.0128\n",
      "Epoch [1/15], Batch [430/1944], Loss: 0.0180\n",
      "Epoch [1/15], Batch [440/1944], Loss: 0.0465\n",
      "Epoch [1/15], Batch [450/1944], Loss: 0.0354\n",
      "Epoch [1/15], Batch [460/1944], Loss: 0.0295\n",
      "Epoch [1/15], Batch [470/1944], Loss: 0.0266\n",
      "Epoch [1/15], Batch [480/1944], Loss: 0.0276\n",
      "Epoch [1/15], Batch [490/1944], Loss: 0.0297\n",
      "Epoch [1/15], Batch [500/1944], Loss: 0.0223\n",
      "Epoch [1/15], Batch [510/1944], Loss: 0.0158\n",
      "Epoch [1/15], Batch [520/1944], Loss: 0.0175\n",
      "Epoch [1/15], Batch [530/1944], Loss: 0.0220\n",
      "Epoch [1/15], Batch [540/1944], Loss: 0.0218\n",
      "Epoch [1/15], Batch [550/1944], Loss: 0.0226\n",
      "Epoch [1/15], Batch [560/1944], Loss: 0.0195\n",
      "Epoch [1/15], Batch [570/1944], Loss: 0.0167\n",
      "Epoch [1/15], Batch [580/1944], Loss: 0.0165\n",
      "Epoch [1/15], Batch [590/1944], Loss: 0.0200\n",
      "Epoch [1/15], Batch [600/1944], Loss: 0.0250\n",
      "Epoch [1/15], Batch [610/1944], Loss: 0.0271\n",
      "Epoch [1/15], Batch [620/1944], Loss: 0.0243\n",
      "Epoch [1/15], Batch [630/1944], Loss: 0.0187\n",
      "Epoch [1/15], Batch [640/1944], Loss: 0.0142\n",
      "Epoch [1/15], Batch [650/1944], Loss: 0.0745\n",
      "Epoch [1/15], Batch [660/1944], Loss: 0.0449\n",
      "Epoch [1/15], Batch [670/1944], Loss: 0.0359\n",
      "Epoch [1/15], Batch [680/1944], Loss: 0.0350\n",
      "Epoch [1/15], Batch [690/1944], Loss: 0.0319\n",
      "Epoch [1/15], Batch [700/1944], Loss: 0.0302\n",
      "Epoch [1/15], Batch [710/1944], Loss: 0.0263\n",
      "Epoch [1/15], Batch [720/1944], Loss: 0.0173\n",
      "Epoch [1/15], Batch [730/1944], Loss: 0.0155\n",
      "Epoch [1/15], Batch [740/1944], Loss: 0.0217\n",
      "Epoch [1/15], Batch [750/1944], Loss: 0.0168\n",
      "Epoch [1/15], Batch [760/1944], Loss: 0.0235\n",
      "Epoch [1/15], Batch [770/1944], Loss: 0.0181\n",
      "Epoch [1/15], Batch [780/1944], Loss: 0.0202\n",
      "Epoch [1/15], Batch [790/1944], Loss: 0.0151\n",
      "Epoch [1/15], Batch [800/1944], Loss: 0.0178\n",
      "Epoch [1/15], Batch [810/1944], Loss: 0.0236\n",
      "Epoch [1/15], Batch [820/1944], Loss: 0.0277\n",
      "Epoch [1/15], Batch [830/1944], Loss: 0.0259\n",
      "Epoch [1/15], Batch [840/1944], Loss: 0.0269\n",
      "Epoch [1/15], Batch [850/1944], Loss: 0.0164\n",
      "Epoch [1/15], Batch [860/1944], Loss: 0.0187\n",
      "Epoch [1/15], Batch [870/1944], Loss: 0.0506\n",
      "Epoch [1/15], Batch [880/1944], Loss: 0.0318\n",
      "Epoch [1/15], Batch [890/1944], Loss: 0.0308\n",
      "Epoch [1/15], Batch [900/1944], Loss: 0.0292\n",
      "Epoch [1/15], Batch [910/1944], Loss: 0.0314\n",
      "Epoch [1/15], Batch [920/1944], Loss: 0.0318\n",
      "Epoch [1/15], Batch [930/1944], Loss: 0.0231\n",
      "Epoch [1/15], Batch [940/1944], Loss: 0.0151\n",
      "Epoch [1/15], Batch [950/1944], Loss: 0.0184\n",
      "Epoch [1/15], Batch [960/1944], Loss: 0.0213\n",
      "Epoch [1/15], Batch [970/1944], Loss: 0.0183\n",
      "Epoch [1/15], Batch [980/1944], Loss: 0.0204\n",
      "Epoch [1/15], Batch [990/1944], Loss: 0.0183\n",
      "Epoch [1/15], Batch [1000/1944], Loss: 0.0171\n",
      "Epoch [1/15], Batch [1010/1944], Loss: 0.0158\n",
      "Epoch [1/15], Batch [1020/1944], Loss: 0.0165\n",
      "Epoch [1/15], Batch [1030/1944], Loss: 0.0258\n",
      "Epoch [1/15], Batch [1040/1944], Loss: 0.0282\n",
      "Epoch [1/15], Batch [1050/1944], Loss: 0.0259\n",
      "Epoch [1/15], Batch [1060/1944], Loss: 0.0224\n",
      "Epoch [1/15], Batch [1070/1944], Loss: 0.0129\n",
      "Epoch [1/15], Batch [1080/1944], Loss: 0.0132\n",
      "Epoch [1/15], Batch [1090/1944], Loss: 0.0287\n",
      "Epoch [1/15], Batch [1100/1944], Loss: 0.0288\n",
      "Epoch [1/15], Batch [1110/1944], Loss: 0.0282\n",
      "Epoch [1/15], Batch [1120/1944], Loss: 0.0232\n",
      "Epoch [1/15], Batch [1130/1944], Loss: 0.0267\n",
      "Epoch [1/15], Batch [1140/1944], Loss: 0.0268\n",
      "Epoch [1/15], Batch [1150/1944], Loss: 0.0192\n",
      "Epoch [1/15], Batch [1160/1944], Loss: 0.0139\n",
      "Epoch [1/15], Batch [1170/1944], Loss: 0.0209\n",
      "Epoch [1/15], Batch [1180/1944], Loss: 0.0190\n",
      "Epoch [1/15], Batch [1190/1944], Loss: 0.0222\n",
      "Epoch [1/15], Batch [1200/1944], Loss: 0.0187\n",
      "Epoch [1/15], Batch [1210/1944], Loss: 0.0190\n",
      "Epoch [1/15], Batch [1220/1944], Loss: 0.0174\n",
      "Epoch [1/15], Batch [1230/1944], Loss: 0.0166\n",
      "Epoch [1/15], Batch [1240/1944], Loss: 0.0213\n",
      "Epoch [1/15], Batch [1250/1944], Loss: 0.0261\n",
      "Epoch [1/15], Batch [1260/1944], Loss: 0.0263\n",
      "Epoch [1/15], Batch [1270/1944], Loss: 0.0262\n",
      "Epoch [1/15], Batch [1280/1944], Loss: 0.0193\n",
      "Epoch [1/15], Batch [1290/1944], Loss: 0.0157\n",
      "Epoch [1/15], Batch [1300/1944], Loss: 0.0608\n",
      "Epoch [1/15], Batch [1310/1944], Loss: 0.0284\n",
      "Epoch [1/15], Batch [1320/1944], Loss: 0.0260\n",
      "Epoch [1/15], Batch [1330/1944], Loss: 0.0259\n",
      "Epoch [1/15], Batch [1340/1944], Loss: 0.0260\n",
      "Epoch [1/15], Batch [1350/1944], Loss: 0.0290\n",
      "Epoch [1/15], Batch [1360/1944], Loss: 0.0241\n",
      "Epoch [1/15], Batch [1370/1944], Loss: 0.0160\n",
      "Epoch [1/15], Batch [1380/1944], Loss: 0.0167\n",
      "Epoch [1/15], Batch [1390/1944], Loss: 0.0246\n",
      "Epoch [1/15], Batch [1400/1944], Loss: 0.0190\n",
      "Epoch [1/15], Batch [1410/1944], Loss: 0.0229\n",
      "Epoch [1/15], Batch [1420/1944], Loss: 0.0169\n",
      "Epoch [1/15], Batch [1430/1944], Loss: 0.0184\n",
      "Epoch [1/15], Batch [1440/1944], Loss: 0.0172\n",
      "Epoch [1/15], Batch [1450/1944], Loss: 0.0177\n",
      "Epoch [1/15], Batch [1460/1944], Loss: 0.0252\n",
      "Epoch [1/15], Batch [1470/1944], Loss: 0.0286\n",
      "Epoch [1/15], Batch [1480/1944], Loss: 0.0253\n",
      "Epoch [1/15], Batch [1490/1944], Loss: 0.0241\n",
      "Epoch [1/15], Batch [1500/1944], Loss: 0.0128\n",
      "Epoch [1/15], Batch [1510/1944], Loss: 0.0178\n",
      "Epoch [1/15], Batch [1520/1944], Loss: 0.0294\n",
      "Epoch [1/15], Batch [1530/1944], Loss: 0.0231\n",
      "Epoch [1/15], Batch [1540/1944], Loss: 0.0224\n",
      "Epoch [1/15], Batch [1550/1944], Loss: 0.0231\n",
      "Epoch [1/15], Batch [1560/1944], Loss: 0.0263\n",
      "Epoch [1/15], Batch [1570/1944], Loss: 0.0269\n",
      "Epoch [1/15], Batch [1580/1944], Loss: 0.0209\n",
      "Epoch [1/15], Batch [1590/1944], Loss: 0.0152\n",
      "Epoch [1/15], Batch [1600/1944], Loss: 0.0185\n",
      "Epoch [1/15], Batch [1610/1944], Loss: 0.0228\n",
      "Epoch [1/15], Batch [1620/1944], Loss: 0.0220\n",
      "Epoch [1/15], Batch [1630/1944], Loss: 0.0221\n",
      "Epoch [1/15], Batch [1640/1944], Loss: 0.0192\n",
      "Epoch [1/15], Batch [1650/1944], Loss: 0.0163\n",
      "Epoch [1/15], Batch [1660/1944], Loss: 0.0164\n",
      "Epoch [1/15], Batch [1670/1944], Loss: 0.0198\n",
      "Epoch [1/15], Batch [1680/1944], Loss: 0.0249\n",
      "Epoch [1/15], Batch [1690/1944], Loss: 0.0271\n",
      "Epoch [1/15], Batch [1700/1944], Loss: 0.0239\n",
      "Epoch [1/15], Batch [1710/1944], Loss: 0.0190\n",
      "Epoch [1/15], Batch [1720/1944], Loss: 0.0144\n",
      "Epoch [1/15], Batch [1730/1944], Loss: 0.0569\n",
      "Epoch [1/15], Batch [1740/1944], Loss: 0.0216\n",
      "Epoch [1/15], Batch [1750/1944], Loss: 0.0229\n",
      "Epoch [1/15], Batch [1760/1944], Loss: 0.0237\n",
      "Epoch [1/15], Batch [1770/1944], Loss: 0.0256\n",
      "Epoch [1/15], Batch [1780/1944], Loss: 0.0263\n",
      "Epoch [1/15], Batch [1790/1944], Loss: 0.0262\n",
      "Epoch [1/15], Batch [1800/1944], Loss: 0.0169\n",
      "Epoch [1/15], Batch [1810/1944], Loss: 0.0161\n",
      "Epoch [1/15], Batch [1820/1944], Loss: 0.0238\n",
      "Epoch [1/15], Batch [1830/1944], Loss: 0.0182\n",
      "Epoch [1/15], Batch [1840/1944], Loss: 0.0244\n",
      "Epoch [1/15], Batch [1850/1944], Loss: 0.0188\n",
      "Epoch [1/15], Batch [1860/1944], Loss: 0.0208\n",
      "Epoch [1/15], Batch [1870/1944], Loss: 0.0155\n",
      "Epoch [1/15], Batch [1880/1944], Loss: 0.0172\n",
      "Epoch [1/15], Batch [1890/1944], Loss: 0.0227\n",
      "Epoch [1/15], Batch [1900/1944], Loss: 0.0279\n",
      "Epoch [1/15], Batch [1910/1944], Loss: 0.0257\n",
      "Epoch [1/15], Batch [1920/1944], Loss: 0.0266\n",
      "Epoch [1/15], Batch [1930/1944], Loss: 0.0166\n",
      "Epoch [1/15], Batch [1940/1944], Loss: 0.0185\n",
      "Epoch [1/15], Average Loss: 0.0273\n",
      "Epoch [1/15], Validation Loss: 0.0807\n",
      "Epoch [1/15], Current Learning Rate: 0.001\n",
      "Epoch [2/15], Batch [10/1944], Loss: 0.0358\n",
      "Epoch [2/15], Batch [20/1944], Loss: 0.0321\n",
      "Epoch [2/15], Batch [30/1944], Loss: 0.0310\n",
      "Epoch [2/15], Batch [40/1944], Loss: 0.0278\n",
      "Epoch [2/15], Batch [50/1944], Loss: 0.0310\n",
      "Epoch [2/15], Batch [60/1944], Loss: 0.0298\n",
      "Epoch [2/15], Batch [70/1944], Loss: 0.0215\n",
      "Epoch [2/15], Batch [80/1944], Loss: 0.0156\n",
      "Epoch [2/15], Batch [90/1944], Loss: 0.0247\n",
      "Epoch [2/15], Batch [100/1944], Loss: 0.0222\n",
      "Epoch [2/15], Batch [110/1944], Loss: 0.0250\n",
      "Epoch [2/15], Batch [120/1944], Loss: 0.0220\n",
      "Epoch [2/15], Batch [130/1944], Loss: 0.0215\n",
      "Epoch [2/15], Batch [140/1944], Loss: 0.0198\n",
      "Epoch [2/15], Batch [150/1944], Loss: 0.0186\n",
      "Epoch [2/15], Batch [160/1944], Loss: 0.0234\n",
      "Epoch [2/15], Batch [170/1944], Loss: 0.0285\n",
      "Epoch [2/15], Batch [180/1944], Loss: 0.0279\n",
      "Epoch [2/15], Batch [190/1944], Loss: 0.0284\n",
      "Epoch [2/15], Batch [200/1944], Loss: 0.0210\n",
      "Epoch [2/15], Batch [210/1944], Loss: 0.0169\n",
      "Epoch [2/15], Batch [220/1944], Loss: 0.0642\n",
      "Epoch [2/15], Batch [230/1944], Loss: 0.0341\n",
      "Epoch [2/15], Batch [240/1944], Loss: 0.0297\n",
      "Epoch [2/15], Batch [250/1944], Loss: 0.0285\n",
      "Epoch [2/15], Batch [260/1944], Loss: 0.0288\n",
      "Epoch [2/15], Batch [270/1944], Loss: 0.0316\n",
      "Epoch [2/15], Batch [280/1944], Loss: 0.0258\n",
      "Epoch [2/15], Batch [290/1944], Loss: 0.0169\n",
      "Epoch [2/15], Batch [300/1944], Loss: 0.0169\n",
      "Epoch [2/15], Batch [310/1944], Loss: 0.0249\n",
      "Epoch [2/15], Batch [320/1944], Loss: 0.0199\n",
      "Epoch [2/15], Batch [330/1944], Loss: 0.0241\n",
      "Epoch [2/15], Batch [340/1944], Loss: 0.0174\n",
      "Epoch [2/15], Batch [350/1944], Loss: 0.0182\n",
      "Epoch [2/15], Batch [360/1944], Loss: 0.0174\n",
      "Epoch [2/15], Batch [370/1944], Loss: 0.0182\n",
      "Epoch [2/15], Batch [380/1944], Loss: 0.0258\n",
      "Epoch [2/15], Batch [390/1944], Loss: 0.0293\n",
      "Epoch [2/15], Batch [400/1944], Loss: 0.0259\n",
      "Epoch [2/15], Batch [410/1944], Loss: 0.0246\n",
      "Epoch [2/15], Batch [420/1944], Loss: 0.0130\n",
      "Epoch [2/15], Batch [430/1944], Loss: 0.0183\n",
      "Epoch [2/15], Batch [440/1944], Loss: 0.0381\n",
      "Epoch [2/15], Batch [450/1944], Loss: 0.0957\n",
      "Epoch [2/15], Batch [460/1944], Loss: 0.0276\n",
      "Epoch [2/15], Batch [470/1944], Loss: 0.0261\n",
      "Epoch [2/15], Batch [480/1944], Loss: 0.0277\n",
      "Epoch [2/15], Batch [490/1944], Loss: 0.0284\n",
      "Epoch [2/15], Batch [500/1944], Loss: 0.0210\n",
      "Epoch [2/15], Batch [510/1944], Loss: 0.0153\n",
      "Epoch [2/15], Batch [520/1944], Loss: 0.0177\n",
      "Epoch [2/15], Batch [530/1944], Loss: 0.0218\n",
      "Epoch [2/15], Batch [540/1944], Loss: 0.0216\n",
      "Epoch [2/15], Batch [550/1944], Loss: 0.0220\n",
      "Epoch [2/15], Batch [560/1944], Loss: 0.0186\n",
      "Epoch [2/15], Batch [570/1944], Loss: 0.0155\n",
      "Epoch [2/15], Batch [580/1944], Loss: 0.0160\n",
      "Epoch [2/15], Batch [590/1944], Loss: 0.0194\n",
      "Epoch [2/15], Batch [600/1944], Loss: 0.0244\n",
      "Epoch [2/15], Batch [610/1944], Loss: 0.0263\n",
      "Epoch [2/15], Batch [620/1944], Loss: 0.0236\n",
      "Epoch [2/15], Batch [630/1944], Loss: 0.0183\n",
      "Epoch [2/15], Batch [640/1944], Loss: 0.0140\n",
      "Epoch [2/15], Batch [650/1944], Loss: 0.0643\n",
      "Epoch [2/15], Batch [660/1944], Loss: 0.0292\n",
      "Epoch [2/15], Batch [670/1944], Loss: 0.0287\n",
      "Epoch [2/15], Batch [680/1944], Loss: 0.0281\n",
      "Epoch [2/15], Batch [690/1944], Loss: 0.0277\n",
      "Epoch [2/15], Batch [700/1944], Loss: 0.0279\n",
      "Epoch [2/15], Batch [710/1944], Loss: 0.0246\n",
      "Epoch [2/15], Batch [720/1944], Loss: 0.0161\n",
      "Epoch [2/15], Batch [730/1944], Loss: 0.0153\n",
      "Epoch [2/15], Batch [740/1944], Loss: 0.0225\n",
      "Epoch [2/15], Batch [750/1944], Loss: 0.0175\n",
      "Epoch [2/15], Batch [760/1944], Loss: 0.0236\n",
      "Epoch [2/15], Batch [770/1944], Loss: 0.0178\n",
      "Epoch [2/15], Batch [780/1944], Loss: 0.0197\n",
      "Epoch [2/15], Batch [790/1944], Loss: 0.0145\n",
      "Epoch [2/15], Batch [800/1944], Loss: 0.0164\n",
      "Epoch [2/15], Batch [810/1944], Loss: 0.0221\n",
      "Epoch [2/15], Batch [820/1944], Loss: 0.0272\n",
      "Epoch [2/15], Batch [830/1944], Loss: 0.0250\n",
      "Epoch [2/15], Batch [840/1944], Loss: 0.0259\n",
      "Epoch [2/15], Batch [850/1944], Loss: 0.0160\n",
      "Epoch [2/15], Batch [860/1944], Loss: 0.0180\n",
      "Epoch [2/15], Batch [870/1944], Loss: 0.0433\n",
      "Epoch [2/15], Batch [880/1944], Loss: 0.0261\n",
      "Epoch [2/15], Batch [890/1944], Loss: 0.0259\n",
      "Epoch [2/15], Batch [900/1944], Loss: 0.0249\n",
      "Epoch [2/15], Batch [910/1944], Loss: 0.0281\n",
      "Epoch [2/15], Batch [920/1944], Loss: 0.0301\n",
      "Epoch [2/15], Batch [930/1944], Loss: 0.0223\n",
      "Epoch [2/15], Batch [940/1944], Loss: 0.0147\n",
      "Epoch [2/15], Batch [950/1944], Loss: 0.0187\n",
      "Epoch [2/15], Batch [960/1944], Loss: 0.0219\n",
      "Epoch [2/15], Batch [970/1944], Loss: 0.0190\n",
      "Epoch [2/15], Batch [980/1944], Loss: 0.0205\n",
      "Epoch [2/15], Batch [990/1944], Loss: 0.0179\n",
      "Epoch [2/15], Batch [1000/1944], Loss: 0.0170\n",
      "Epoch [2/15], Batch [1010/1944], Loss: 0.0156\n",
      "Epoch [2/15], Batch [1020/1944], Loss: 0.0163\n",
      "Epoch [2/15], Batch [1030/1944], Loss: 0.0257\n",
      "Epoch [2/15], Batch [1040/1944], Loss: 0.0285\n",
      "Epoch [2/15], Batch [1050/1944], Loss: 0.0263\n",
      "Epoch [2/15], Batch [1060/1944], Loss: 0.0226\n",
      "Epoch [2/15], Batch [1070/1944], Loss: 0.0130\n",
      "Epoch [2/15], Batch [1080/1944], Loss: 0.0126\n",
      "Epoch [2/15], Batch [1090/1944], Loss: 0.0245\n",
      "Epoch [2/15], Batch [1100/1944], Loss: 0.0255\n",
      "Epoch [2/15], Batch [1110/1944], Loss: 0.0260\n",
      "Epoch [2/15], Batch [1120/1944], Loss: 0.0229\n",
      "Epoch [2/15], Batch [1130/1944], Loss: 0.0259\n",
      "Epoch [2/15], Batch [1140/1944], Loss: 0.0268\n",
      "Epoch [2/15], Batch [1150/1944], Loss: 0.0186\n",
      "Epoch [2/15], Batch [1160/1944], Loss: 0.0137\n",
      "Epoch [2/15], Batch [1170/1944], Loss: 0.0213\n",
      "Epoch [2/15], Batch [1180/1944], Loss: 0.0194\n",
      "Epoch [2/15], Batch [1190/1944], Loss: 0.0222\n",
      "Epoch [2/15], Batch [1200/1944], Loss: 0.0186\n",
      "Epoch [2/15], Batch [1210/1944], Loss: 0.0186\n",
      "Epoch [2/15], Batch [1220/1944], Loss: 0.0171\n",
      "Epoch [2/15], Batch [1230/1944], Loss: 0.0165\n",
      "Epoch [2/15], Batch [1240/1944], Loss: 0.0211\n",
      "Epoch [2/15], Batch [1250/1944], Loss: 0.0260\n",
      "Epoch [2/15], Batch [1260/1944], Loss: 0.0262\n",
      "Epoch [2/15], Batch [1270/1944], Loss: 0.0260\n",
      "Epoch [2/15], Batch [1280/1944], Loss: 0.0189\n",
      "Epoch [2/15], Batch [1290/1944], Loss: 0.0150\n",
      "Epoch [2/15], Batch [1300/1944], Loss: 0.0541\n",
      "Epoch [2/15], Batch [1310/1944], Loss: 0.0255\n",
      "Epoch [2/15], Batch [1320/1944], Loss: 0.0239\n",
      "Epoch [2/15], Batch [1330/1944], Loss: 0.0236\n",
      "Epoch [2/15], Batch [1340/1944], Loss: 0.0253\n",
      "Epoch [2/15], Batch [1350/1944], Loss: 0.0279\n",
      "Epoch [2/15], Batch [1360/1944], Loss: 0.0234\n",
      "Epoch [2/15], Batch [1370/1944], Loss: 0.0157\n",
      "Epoch [2/15], Batch [1380/1944], Loss: 0.0166\n",
      "Epoch [2/15], Batch [1390/1944], Loss: 0.0254\n",
      "Epoch [2/15], Batch [1400/1944], Loss: 0.0197\n",
      "Epoch [2/15], Batch [1410/1944], Loss: 0.0230\n",
      "Epoch [2/15], Batch [1420/1944], Loss: 0.0167\n",
      "Epoch [2/15], Batch [1430/1944], Loss: 0.0178\n",
      "Epoch [2/15], Batch [1440/1944], Loss: 0.0166\n",
      "Epoch [2/15], Batch [1450/1944], Loss: 0.0175\n",
      "Epoch [2/15], Batch [1460/1944], Loss: 0.0250\n",
      "Epoch [2/15], Batch [1470/1944], Loss: 0.0285\n",
      "Epoch [2/15], Batch [1480/1944], Loss: 0.0253\n",
      "Epoch [2/15], Batch [1490/1944], Loss: 0.0240\n",
      "Epoch [2/15], Batch [1500/1944], Loss: 0.0127\n",
      "Epoch [2/15], Batch [1510/1944], Loss: 0.0180\n",
      "Epoch [2/15], Batch [1520/1944], Loss: 0.0285\n",
      "Epoch [2/15], Batch [1530/1944], Loss: 0.0217\n",
      "Epoch [2/15], Batch [1540/1944], Loss: 0.0219\n",
      "Epoch [2/15], Batch [1550/1944], Loss: 0.0226\n",
      "Epoch [2/15], Batch [1560/1944], Loss: 0.0257\n",
      "Epoch [2/15], Batch [1570/1944], Loss: 0.0265\n",
      "Epoch [2/15], Batch [1580/1944], Loss: 0.0207\n",
      "Epoch [2/15], Batch [1590/1944], Loss: 0.0152\n",
      "Epoch [2/15], Batch [1600/1944], Loss: 0.0189\n",
      "Epoch [2/15], Batch [1610/1944], Loss: 0.0234\n",
      "Epoch [2/15], Batch [1620/1944], Loss: 0.0227\n",
      "Epoch [2/15], Batch [1630/1944], Loss: 0.0220\n",
      "Epoch [2/15], Batch [1640/1944], Loss: 0.0190\n",
      "Epoch [2/15], Batch [1650/1944], Loss: 0.0162\n",
      "Epoch [2/15], Batch [1660/1944], Loss: 0.0162\n",
      "Epoch [2/15], Batch [1670/1944], Loss: 0.0198\n",
      "Epoch [2/15], Batch [1680/1944], Loss: 0.0249\n",
      "Epoch [2/15], Batch [1690/1944], Loss: 0.0272\n",
      "Epoch [2/15], Batch [1700/1944], Loss: 0.0242\n",
      "Epoch [2/15], Batch [1710/1944], Loss: 0.0191\n",
      "Epoch [2/15], Batch [1720/1944], Loss: 0.0144\n",
      "Epoch [2/15], Batch [1730/1944], Loss: 0.0566\n",
      "Epoch [2/15], Batch [1740/1944], Loss: 0.0206\n",
      "Epoch [2/15], Batch [1750/1944], Loss: 0.0223\n",
      "Epoch [2/15], Batch [1760/1944], Loss: 0.0232\n",
      "Epoch [2/15], Batch [1770/1944], Loss: 0.0252\n",
      "Epoch [2/15], Batch [1780/1944], Loss: 0.0259\n",
      "Epoch [2/15], Batch [1790/1944], Loss: 0.0250\n",
      "Epoch [2/15], Batch [1800/1944], Loss: 0.0165\n",
      "Epoch [2/15], Batch [1810/1944], Loss: 0.0161\n",
      "Epoch [2/15], Batch [1820/1944], Loss: 0.0241\n",
      "Epoch [2/15], Batch [1830/1944], Loss: 0.0184\n",
      "Epoch [2/15], Batch [1840/1944], Loss: 0.0244\n",
      "Epoch [2/15], Batch [1850/1944], Loss: 0.0188\n",
      "Epoch [2/15], Batch [1860/1944], Loss: 0.0207\n",
      "Epoch [2/15], Batch [1870/1944], Loss: 0.0153\n",
      "Epoch [2/15], Batch [1880/1944], Loss: 0.0170\n",
      "Epoch [2/15], Batch [1890/1944], Loss: 0.0227\n",
      "Epoch [2/15], Batch [1900/1944], Loss: 0.0280\n",
      "Epoch [2/15], Batch [1910/1944], Loss: 0.0257\n",
      "Epoch [2/15], Batch [1920/1944], Loss: 0.0265\n",
      "Epoch [2/15], Batch [1930/1944], Loss: 0.0164\n",
      "Epoch [2/15], Batch [1940/1944], Loss: 0.0183\n",
      "Epoch [2/15], Average Loss: 0.0232\n",
      "Epoch [2/15], Validation Loss: 0.0830\n",
      "Epoch [2/15], Current Learning Rate: 0.001\n",
      "Epoch [3/15], Batch [10/1944], Loss: 0.0276\n",
      "Epoch [3/15], Batch [20/1944], Loss: 0.0270\n",
      "Epoch [3/15], Batch [30/1944], Loss: 0.0260\n",
      "Epoch [3/15], Batch [40/1944], Loss: 0.0242\n",
      "Epoch [3/15], Batch [50/1944], Loss: 0.0281\n",
      "Epoch [3/15], Batch [60/1944], Loss: 0.0284\n",
      "Epoch [3/15], Batch [70/1944], Loss: 0.0192\n",
      "Epoch [3/15], Batch [80/1944], Loss: 0.0147\n",
      "Epoch [3/15], Batch [90/1944], Loss: 0.0232\n",
      "Epoch [3/15], Batch [100/1944], Loss: 0.0214\n",
      "Epoch [3/15], Batch [110/1944], Loss: 0.0244\n",
      "Epoch [3/15], Batch [120/1944], Loss: 0.0213\n",
      "Epoch [3/15], Batch [130/1944], Loss: 0.0212\n",
      "Epoch [3/15], Batch [140/1944], Loss: 0.0194\n",
      "Epoch [3/15], Batch [150/1944], Loss: 0.0186\n",
      "Epoch [3/15], Batch [160/1944], Loss: 0.0232\n",
      "Epoch [3/15], Batch [170/1944], Loss: 0.0285\n",
      "Epoch [3/15], Batch [180/1944], Loss: 0.0280\n",
      "Epoch [3/15], Batch [190/1944], Loss: 0.0279\n",
      "Epoch [3/15], Batch [200/1944], Loss: 0.0202\n",
      "Epoch [3/15], Batch [210/1944], Loss: 0.0163\n",
      "Epoch [3/15], Batch [220/1944], Loss: 0.0689\n",
      "Epoch [3/15], Batch [230/1944], Loss: 0.0310\n",
      "Epoch [3/15], Batch [240/1944], Loss: 0.0278\n",
      "Epoch [3/15], Batch [250/1944], Loss: 0.0285\n",
      "Epoch [3/15], Batch [260/1944], Loss: 0.0282\n",
      "Epoch [3/15], Batch [270/1944], Loss: 0.0314\n",
      "Epoch [3/15], Batch [280/1944], Loss: 0.0251\n",
      "Epoch [3/15], Batch [290/1944], Loss: 0.0161\n",
      "Epoch [3/15], Batch [300/1944], Loss: 0.0162\n",
      "Epoch [3/15], Batch [310/1944], Loss: 0.0250\n",
      "Epoch [3/15], Batch [320/1944], Loss: 0.0197\n",
      "Epoch [3/15], Batch [330/1944], Loss: 0.0240\n",
      "Epoch [3/15], Batch [340/1944], Loss: 0.0173\n",
      "Epoch [3/15], Batch [350/1944], Loss: 0.0182\n",
      "Epoch [3/15], Batch [360/1944], Loss: 0.0171\n",
      "Epoch [3/15], Batch [370/1944], Loss: 0.0178\n",
      "Epoch [3/15], Batch [380/1944], Loss: 0.0257\n",
      "Epoch [3/15], Batch [390/1944], Loss: 0.0290\n",
      "Epoch [3/15], Batch [400/1944], Loss: 0.0254\n",
      "Epoch [3/15], Batch [410/1944], Loss: 0.0238\n",
      "Epoch [3/15], Batch [420/1944], Loss: 0.0124\n",
      "Epoch [3/15], Batch [430/1944], Loss: 0.0178\n",
      "Epoch [3/15], Batch [440/1944], Loss: 0.0356\n",
      "Epoch [3/15], Batch [450/1944], Loss: 0.0261\n",
      "Epoch [3/15], Batch [460/1944], Loss: 0.0245\n",
      "Epoch [3/15], Batch [470/1944], Loss: 0.0226\n",
      "Epoch [3/15], Batch [480/1944], Loss: 0.0252\n",
      "Epoch [3/15], Batch [490/1944], Loss: 0.0267\n",
      "Epoch [3/15], Batch [500/1944], Loss: 0.0201\n",
      "Epoch [3/15], Batch [510/1944], Loss: 0.0145\n",
      "Epoch [3/15], Batch [520/1944], Loss: 0.0174\n",
      "Epoch [3/15], Batch [530/1944], Loss: 0.0220\n",
      "Epoch [3/15], Batch [540/1944], Loss: 0.0217\n",
      "Epoch [3/15], Batch [550/1944], Loss: 0.0220\n",
      "Epoch [3/15], Batch [560/1944], Loss: 0.0186\n",
      "Epoch [3/15], Batch [570/1944], Loss: 0.0153\n",
      "Epoch [3/15], Batch [580/1944], Loss: 0.0156\n",
      "Epoch [3/15], Batch [590/1944], Loss: 0.0192\n",
      "Epoch [3/15], Batch [600/1944], Loss: 0.0243\n",
      "Epoch [3/15], Batch [610/1944], Loss: 0.0261\n",
      "Epoch [3/15], Batch [620/1944], Loss: 0.0233\n",
      "Epoch [3/15], Batch [630/1944], Loss: 0.0182\n",
      "Epoch [3/15], Batch [640/1944], Loss: 0.0140\n",
      "Epoch [3/15], Batch [650/1944], Loss: 0.0602\n",
      "Epoch [3/15], Batch [660/1944], Loss: 0.0257\n",
      "Epoch [3/15], Batch [670/1944], Loss: 0.0267\n",
      "Epoch [3/15], Batch [680/1944], Loss: 0.0262\n",
      "Epoch [3/15], Batch [690/1944], Loss: 0.0270\n",
      "Epoch [3/15], Batch [700/1944], Loss: 0.0272\n",
      "Epoch [3/15], Batch [710/1944], Loss: 0.0249\n",
      "Epoch [3/15], Batch [720/1944], Loss: 0.0161\n",
      "Epoch [3/15], Batch [730/1944], Loss: 0.0151\n",
      "Epoch [3/15], Batch [740/1944], Loss: 0.0230\n",
      "Epoch [3/15], Batch [750/1944], Loss: 0.0179\n",
      "Epoch [3/15], Batch [760/1944], Loss: 0.0243\n",
      "Epoch [3/15], Batch [770/1944], Loss: 0.0178\n",
      "Epoch [3/15], Batch [780/1944], Loss: 0.0196\n",
      "Epoch [3/15], Batch [790/1944], Loss: 0.0144\n",
      "Epoch [3/15], Batch [800/1944], Loss: 0.0162\n",
      "Epoch [3/15], Batch [810/1944], Loss: 0.0222\n",
      "Epoch [3/15], Batch [820/1944], Loss: 0.0275\n",
      "Epoch [3/15], Batch [830/1944], Loss: 0.0254\n",
      "Epoch [3/15], Batch [840/1944], Loss: 0.0266\n",
      "Epoch [3/15], Batch [850/1944], Loss: 0.0166\n",
      "Epoch [3/15], Batch [860/1944], Loss: 0.0190\n",
      "Epoch [3/15], Batch [870/1944], Loss: 0.0421\n",
      "Epoch [3/15], Batch [880/1944], Loss: 0.0232\n",
      "Epoch [3/15], Batch [890/1944], Loss: 0.0237\n",
      "Epoch [3/15], Batch [900/1944], Loss: 0.0240\n",
      "Epoch [3/15], Batch [910/1944], Loss: 0.0281\n",
      "Epoch [3/15], Batch [920/1944], Loss: 0.0304\n",
      "Epoch [3/15], Batch [930/1944], Loss: 0.0225\n",
      "Epoch [3/15], Batch [940/1944], Loss: 0.0145\n",
      "Epoch [3/15], Batch [950/1944], Loss: 0.0184\n",
      "Epoch [3/15], Batch [960/1944], Loss: 0.0216\n",
      "Epoch [3/15], Batch [970/1944], Loss: 0.0189\n",
      "Epoch [3/15], Batch [980/1944], Loss: 0.0204\n",
      "Epoch [3/15], Batch [990/1944], Loss: 0.0178\n",
      "Epoch [3/15], Batch [1000/1944], Loss: 0.0169\n",
      "Epoch [3/15], Batch [1010/1944], Loss: 0.0154\n",
      "Epoch [3/15], Batch [1020/1944], Loss: 0.0162\n",
      "Epoch [3/15], Batch [1030/1944], Loss: 0.0258\n",
      "Epoch [3/15], Batch [1040/1944], Loss: 0.0285\n",
      "Epoch [3/15], Batch [1050/1944], Loss: 0.0261\n",
      "Epoch [3/15], Batch [1060/1944], Loss: 0.0225\n",
      "Epoch [3/15], Batch [1070/1944], Loss: 0.0129\n",
      "Epoch [3/15], Batch [1080/1944], Loss: 0.0130\n",
      "Epoch [3/15], Batch [1090/1944], Loss: 0.0215\n",
      "Epoch [3/15], Batch [1100/1944], Loss: 0.0220\n",
      "Epoch [3/15], Batch [1110/1944], Loss: 0.0232\n",
      "Epoch [3/15], Batch [1120/1944], Loss: 0.0227\n",
      "Epoch [3/15], Batch [1130/1944], Loss: 0.0260\n",
      "Epoch [3/15], Batch [1140/1944], Loss: 0.0269\n",
      "Epoch [3/15], Batch [1150/1944], Loss: 0.0187\n",
      "Epoch [3/15], Batch [1160/1944], Loss: 0.0136\n",
      "Epoch [3/15], Batch [1170/1944], Loss: 0.0215\n",
      "Epoch [3/15], Batch [1180/1944], Loss: 0.0195\n",
      "Epoch [3/15], Batch [1190/1944], Loss: 0.0223\n",
      "Epoch [3/15], Batch [1200/1944], Loss: 0.0186\n",
      "Epoch [3/15], Batch [1210/1944], Loss: 0.0186\n",
      "Epoch [3/15], Batch [1220/1944], Loss: 0.0170\n",
      "Epoch [3/15], Batch [1230/1944], Loss: 0.0163\n",
      "Epoch [3/15], Batch [1240/1944], Loss: 0.0210\n",
      "Epoch [3/15], Batch [1250/1944], Loss: 0.0259\n",
      "Epoch [3/15], Batch [1260/1944], Loss: 0.0260\n",
      "Epoch [3/15], Batch [1270/1944], Loss: 0.0257\n",
      "Epoch [3/15], Batch [1280/1944], Loss: 0.0190\n",
      "Epoch [3/15], Batch [1290/1944], Loss: 0.0153\n",
      "Epoch [3/15], Batch [1300/1944], Loss: 0.0506\n",
      "Epoch [3/15], Batch [1310/1944], Loss: 0.0221\n",
      "Epoch [3/15], Batch [1320/1944], Loss: 0.0224\n",
      "Epoch [3/15], Batch [1330/1944], Loss: 0.0225\n",
      "Epoch [3/15], Batch [1340/1944], Loss: 0.0256\n",
      "Epoch [3/15], Batch [1350/1944], Loss: 0.0284\n",
      "Epoch [3/15], Batch [1360/1944], Loss: 0.0233\n",
      "Epoch [3/15], Batch [1370/1944], Loss: 0.0155\n",
      "Epoch [3/15], Batch [1380/1944], Loss: 0.0167\n",
      "Epoch [3/15], Batch [1390/1944], Loss: 0.0256\n",
      "Epoch [3/15], Batch [1400/1944], Loss: 0.0200\n",
      "Epoch [3/15], Batch [1410/1944], Loss: 0.0233\n",
      "Epoch [3/15], Batch [1420/1944], Loss: 0.0169\n",
      "Epoch [3/15], Batch [1430/1944], Loss: 0.0179\n",
      "Epoch [3/15], Batch [1440/1944], Loss: 0.0167\n",
      "Epoch [3/15], Batch [1450/1944], Loss: 0.0176\n",
      "Epoch [3/15], Batch [1460/1944], Loss: 0.0251\n",
      "Epoch [3/15], Batch [1470/1944], Loss: 0.0286\n",
      "Epoch [3/15], Batch [1480/1944], Loss: 0.0254\n",
      "Epoch [3/15], Batch [1490/1944], Loss: 0.0245\n",
      "Epoch [3/15], Batch [1500/1944], Loss: 0.0132\n",
      "Epoch [3/15], Batch [1510/1944], Loss: 0.0186\n",
      "Epoch [3/15], Batch [1520/1944], Loss: 0.0278\n",
      "Epoch [3/15], Batch [1530/1944], Loss: 0.0202\n",
      "Epoch [3/15], Batch [1540/1944], Loss: 0.0220\n",
      "Epoch [3/15], Batch [1550/1944], Loss: 0.0225\n",
      "Epoch [3/15], Batch [1560/1944], Loss: 0.0260\n",
      "Epoch [3/15], Batch [1570/1944], Loss: 0.0266\n",
      "Epoch [3/15], Batch [1580/1944], Loss: 0.0204\n",
      "Epoch [3/15], Batch [1590/1944], Loss: 0.0151\n",
      "Epoch [3/15], Batch [1600/1944], Loss: 0.0188\n",
      "Epoch [3/15], Batch [1610/1944], Loss: 0.0234\n",
      "Epoch [3/15], Batch [1620/1944], Loss: 0.0229\n",
      "Epoch [3/15], Batch [1630/1944], Loss: 0.0221\n",
      "Epoch [3/15], Batch [1640/1944], Loss: 0.0190\n",
      "Epoch [3/15], Batch [1650/1944], Loss: 0.0160\n",
      "Epoch [3/15], Batch [1660/1944], Loss: 0.0162\n",
      "Epoch [3/15], Batch [1670/1944], Loss: 0.0200\n",
      "Epoch [3/15], Batch [1680/1944], Loss: 0.0250\n",
      "Epoch [3/15], Batch [1690/1944], Loss: 0.0274\n",
      "Epoch [3/15], Batch [1700/1944], Loss: 0.0245\n",
      "Epoch [3/15], Batch [1710/1944], Loss: 0.0199\n",
      "Epoch [3/15], Batch [1720/1944], Loss: 0.0153\n",
      "Epoch [3/15], Batch [1730/1944], Loss: 0.0557\n",
      "Epoch [3/15], Batch [1740/1944], Loss: 0.0207\n",
      "Epoch [3/15], Batch [1750/1944], Loss: 0.0231\n",
      "Epoch [3/15], Batch [1760/1944], Loss: 0.0245\n",
      "Epoch [3/15], Batch [1770/1944], Loss: 0.0260\n",
      "Epoch [3/15], Batch [1780/1944], Loss: 0.0267\n",
      "Epoch [3/15], Batch [1790/1944], Loss: 0.0252\n",
      "Epoch [3/15], Batch [1800/1944], Loss: 0.0168\n",
      "Epoch [3/15], Batch [1810/1944], Loss: 0.0162\n",
      "Epoch [3/15], Batch [1820/1944], Loss: 0.0242\n",
      "Epoch [3/15], Batch [1830/1944], Loss: 0.0185\n",
      "Epoch [3/15], Batch [1840/1944], Loss: 0.0247\n",
      "Epoch [3/15], Batch [1850/1944], Loss: 0.0188\n",
      "Epoch [3/15], Batch [1860/1944], Loss: 0.0208\n",
      "Epoch [3/15], Batch [1870/1944], Loss: 0.0154\n",
      "Epoch [3/15], Batch [1880/1944], Loss: 0.0170\n",
      "Epoch [3/15], Batch [1890/1944], Loss: 0.0228\n",
      "Epoch [3/15], Batch [1900/1944], Loss: 0.0282\n",
      "Epoch [3/15], Batch [1910/1944], Loss: 0.0260\n",
      "Epoch [3/15], Batch [1920/1944], Loss: 0.0267\n",
      "Epoch [3/15], Batch [1930/1944], Loss: 0.0167\n",
      "Epoch [3/15], Batch [1940/1944], Loss: 0.0186\n",
      "Epoch [3/15], Average Loss: 0.0227\n",
      "Epoch [3/15], Validation Loss: 0.0866\n",
      "Epoch [3/15], Current Learning Rate: 0.001\n",
      "Epoch [4/15], Batch [10/1944], Loss: 0.0264\n",
      "Epoch [4/15], Batch [20/1944], Loss: 0.0265\n",
      "Epoch [4/15], Batch [30/1944], Loss: 0.0261\n",
      "Epoch [4/15], Batch [40/1944], Loss: 0.0251\n",
      "Epoch [4/15], Batch [50/1944], Loss: 0.0281\n",
      "Epoch [4/15], Batch [60/1944], Loss: 0.0284\n",
      "Epoch [4/15], Batch [70/1944], Loss: 0.0195\n",
      "Epoch [4/15], Batch [80/1944], Loss: 0.0145\n",
      "Epoch [4/15], Batch [90/1944], Loss: 0.0228\n",
      "Epoch [4/15], Batch [100/1944], Loss: 0.0211\n",
      "Epoch [4/15], Batch [110/1944], Loss: 0.0242\n",
      "Epoch [4/15], Batch [120/1944], Loss: 0.0211\n",
      "Epoch [4/15], Batch [130/1944], Loss: 0.0211\n",
      "Epoch [4/15], Batch [140/1944], Loss: 0.0192\n",
      "Epoch [4/15], Batch [150/1944], Loss: 0.0183\n",
      "Epoch [4/15], Batch [160/1944], Loss: 0.0228\n",
      "Epoch [4/15], Batch [170/1944], Loss: 0.0282\n",
      "Epoch [4/15], Batch [180/1944], Loss: 0.0277\n",
      "Epoch [4/15], Batch [190/1944], Loss: 0.0274\n",
      "Epoch [4/15], Batch [200/1944], Loss: 0.0196\n",
      "Epoch [4/15], Batch [210/1944], Loss: 0.0157\n",
      "Epoch [4/15], Batch [220/1944], Loss: 0.0574\n",
      "Epoch [4/15], Batch [230/1944], Loss: 0.0260\n",
      "Epoch [4/15], Batch [240/1944], Loss: 0.0248\n",
      "Epoch [4/15], Batch [250/1944], Loss: 0.0250\n",
      "Epoch [4/15], Batch [260/1944], Loss: 0.0280\n",
      "Epoch [4/15], Batch [270/1944], Loss: 0.0310\n",
      "Epoch [4/15], Batch [280/1944], Loss: 0.0254\n",
      "Epoch [4/15], Batch [290/1944], Loss: 0.0164\n",
      "Epoch [4/15], Batch [300/1944], Loss: 0.0169\n",
      "Epoch [4/15], Batch [310/1944], Loss: 0.0254\n",
      "Epoch [4/15], Batch [320/1944], Loss: 0.0207\n",
      "Epoch [4/15], Batch [330/1944], Loss: 0.0244\n",
      "Epoch [4/15], Batch [340/1944], Loss: 0.0176\n",
      "Epoch [4/15], Batch [350/1944], Loss: 0.0182\n",
      "Epoch [4/15], Batch [360/1944], Loss: 0.0174\n",
      "Epoch [4/15], Batch [370/1944], Loss: 0.0181\n",
      "Epoch [4/15], Batch [380/1944], Loss: 0.0255\n",
      "Epoch [4/15], Batch [390/1944], Loss: 0.0290\n",
      "Epoch [4/15], Batch [400/1944], Loss: 0.0255\n",
      "Epoch [4/15], Batch [410/1944], Loss: 0.0241\n",
      "Epoch [4/15], Batch [420/1944], Loss: 0.0125\n",
      "Epoch [4/15], Batch [430/1944], Loss: 0.0180\n",
      "Epoch [4/15], Batch [440/1944], Loss: 0.0318\n",
      "Epoch [4/15], Batch [450/1944], Loss: 0.0229\n",
      "Epoch [4/15], Batch [460/1944], Loss: 0.0241\n",
      "Epoch [4/15], Batch [470/1944], Loss: 0.0247\n",
      "Epoch [4/15], Batch [480/1944], Loss: 0.0280\n",
      "Epoch [4/15], Batch [490/1944], Loss: 0.0289\n",
      "Epoch [4/15], Batch [500/1944], Loss: 0.0222\n",
      "Epoch [4/15], Batch [510/1944], Loss: 0.0161\n",
      "Epoch [4/15], Batch [520/1944], Loss: 0.0193\n",
      "Epoch [4/15], Batch [530/1944], Loss: 0.0231\n",
      "Epoch [4/15], Batch [540/1944], Loss: 0.0232\n",
      "Epoch [4/15], Batch [550/1944], Loss: 0.0225\n",
      "Epoch [4/15], Batch [560/1944], Loss: 0.0185\n",
      "Epoch [4/15], Batch [570/1944], Loss: 0.0153\n",
      "Epoch [4/15], Batch [580/1944], Loss: 0.0158\n",
      "Epoch [4/15], Batch [590/1944], Loss: 0.0196\n",
      "Epoch [4/15], Batch [600/1944], Loss: 0.0250\n",
      "Epoch [4/15], Batch [610/1944], Loss: 0.0271\n",
      "Epoch [4/15], Batch [620/1944], Loss: 0.0243\n",
      "Epoch [4/15], Batch [630/1944], Loss: 0.0192\n",
      "Epoch [4/15], Batch [640/1944], Loss: 0.0144\n",
      "Epoch [4/15], Batch [650/1944], Loss: 0.0588\n",
      "Epoch [4/15], Batch [660/1944], Loss: 0.0220\n",
      "Epoch [4/15], Batch [670/1944], Loss: 0.0234\n",
      "Epoch [4/15], Batch [680/1944], Loss: 0.0247\n",
      "Epoch [4/15], Batch [690/1944], Loss: 0.0265\n",
      "Epoch [4/15], Batch [700/1944], Loss: 0.0274\n",
      "Epoch [4/15], Batch [710/1944], Loss: 0.0254\n",
      "Epoch [4/15], Batch [720/1944], Loss: 0.0163\n",
      "Epoch [4/15], Batch [730/1944], Loss: 0.0153\n",
      "Epoch [4/15], Batch [740/1944], Loss: 0.0226\n",
      "Epoch [4/15], Batch [750/1944], Loss: 0.0174\n",
      "Epoch [4/15], Batch [760/1944], Loss: 0.0239\n",
      "Epoch [4/15], Batch [770/1944], Loss: 0.0176\n",
      "Epoch [4/15], Batch [780/1944], Loss: 0.0195\n",
      "Epoch [4/15], Batch [790/1944], Loss: 0.0144\n",
      "Epoch [4/15], Batch [800/1944], Loss: 0.0163\n",
      "Epoch [4/15], Batch [810/1944], Loss: 0.0222\n",
      "Epoch [4/15], Batch [820/1944], Loss: 0.0274\n",
      "Epoch [4/15], Batch [830/1944], Loss: 0.0251\n",
      "Epoch [4/15], Batch [840/1944], Loss: 0.0261\n",
      "Epoch [4/15], Batch [850/1944], Loss: 0.0162\n",
      "Epoch [4/15], Batch [860/1944], Loss: 0.0184\n",
      "Epoch [4/15], Batch [870/1944], Loss: 0.0401\n",
      "Epoch [4/15], Batch [880/1944], Loss: 0.0209\n",
      "Epoch [4/15], Batch [890/1944], Loss: 0.0223\n",
      "Epoch [4/15], Batch [900/1944], Loss: 0.0240\n",
      "Epoch [4/15], Batch [910/1944], Loss: 0.0281\n",
      "Epoch [4/15], Batch [920/1944], Loss: 0.0304\n",
      "Epoch [4/15], Batch [930/1944], Loss: 0.0226\n",
      "Epoch [4/15], Batch [940/1944], Loss: 0.0146\n",
      "Epoch [4/15], Batch [950/1944], Loss: 0.0188\n",
      "Epoch [4/15], Batch [960/1944], Loss: 0.0221\n",
      "Epoch [4/15], Batch [970/1944], Loss: 0.0194\n",
      "Epoch [4/15], Batch [980/1944], Loss: 0.0205\n",
      "Epoch [4/15], Batch [990/1944], Loss: 0.0178\n",
      "Epoch [4/15], Batch [1000/1944], Loss: 0.0168\n",
      "Epoch [4/15], Batch [1010/1944], Loss: 0.0153\n",
      "Epoch [4/15], Batch [1020/1944], Loss: 0.0162\n",
      "Epoch [4/15], Batch [1030/1944], Loss: 0.0259\n",
      "Epoch [4/15], Batch [1040/1944], Loss: 0.0287\n",
      "Epoch [4/15], Batch [1050/1944], Loss: 0.0264\n",
      "Epoch [4/15], Batch [1060/1944], Loss: 0.0226\n",
      "Epoch [4/15], Batch [1070/1944], Loss: 0.0131\n",
      "Epoch [4/15], Batch [1080/1944], Loss: 0.0130\n",
      "Epoch [4/15], Batch [1090/1944], Loss: 0.0218\n",
      "Epoch [4/15], Batch [1100/1944], Loss: 0.0223\n",
      "Epoch [4/15], Batch [1110/1944], Loss: 0.0233\n",
      "Epoch [4/15], Batch [1120/1944], Loss: 0.0229\n",
      "Epoch [4/15], Batch [1130/1944], Loss: 0.0260\n",
      "Epoch [4/15], Batch [1140/1944], Loss: 0.0268\n",
      "Epoch [4/15], Batch [1150/1944], Loss: 0.0187\n",
      "Epoch [4/15], Batch [1160/1944], Loss: 0.0136\n",
      "Epoch [4/15], Batch [1170/1944], Loss: 0.0213\n",
      "Epoch [4/15], Batch [1180/1944], Loss: 0.0193\n",
      "Epoch [4/15], Batch [1190/1944], Loss: 0.0223\n",
      "Epoch [4/15], Batch [1200/1944], Loss: 0.0185\n",
      "Epoch [4/15], Batch [1210/1944], Loss: 0.0185\n",
      "Epoch [4/15], Batch [1220/1944], Loss: 0.0170\n",
      "Epoch [4/15], Batch [1230/1944], Loss: 0.0163\n",
      "Epoch [4/15], Batch [1240/1944], Loss: 0.0210\n",
      "Epoch [4/15], Batch [1250/1944], Loss: 0.0259\n",
      "Epoch [4/15], Batch [1260/1944], Loss: 0.0262\n",
      "Epoch [4/15], Batch [1270/1944], Loss: 0.0258\n",
      "Epoch [4/15], Batch [1280/1944], Loss: 0.0189\n",
      "Epoch [4/15], Batch [1290/1944], Loss: 0.0152\n",
      "Epoch [4/15], Batch [1300/1944], Loss: 0.0506\n",
      "Epoch [4/15], Batch [1310/1944], Loss: 0.0220\n",
      "Epoch [4/15], Batch [1320/1944], Loss: 0.0223\n",
      "Epoch [4/15], Batch [1330/1944], Loss: 0.0222\n",
      "Epoch [4/15], Batch [1340/1944], Loss: 0.0249\n",
      "Epoch [4/15], Batch [1350/1944], Loss: 0.0278\n",
      "Epoch [4/15], Batch [1360/1944], Loss: 0.0229\n",
      "Epoch [4/15], Batch [1370/1944], Loss: 0.0149\n",
      "Epoch [4/15], Batch [1380/1944], Loss: 0.0162\n",
      "Epoch [4/15], Batch [1390/1944], Loss: 0.0253\n",
      "Epoch [4/15], Batch [1400/1944], Loss: 0.0197\n",
      "Epoch [4/15], Batch [1410/1944], Loss: 0.0230\n",
      "Epoch [4/15], Batch [1420/1944], Loss: 0.0166\n",
      "Epoch [4/15], Batch [1430/1944], Loss: 0.0176\n",
      "Epoch [4/15], Batch [1440/1944], Loss: 0.0163\n",
      "Epoch [4/15], Batch [1450/1944], Loss: 0.0172\n",
      "Epoch [4/15], Batch [1460/1944], Loss: 0.0249\n",
      "Epoch [4/15], Batch [1470/1944], Loss: 0.0284\n",
      "Epoch [4/15], Batch [1480/1944], Loss: 0.0253\n",
      "Epoch [4/15], Batch [1490/1944], Loss: 0.0240\n",
      "Epoch [4/15], Batch [1500/1944], Loss: 0.0125\n",
      "Epoch [4/15], Batch [1510/1944], Loss: 0.0176\n",
      "Epoch [4/15], Batch [1520/1944], Loss: 0.0264\n",
      "Epoch [4/15], Batch [1530/1944], Loss: 0.0191\n",
      "Epoch [4/15], Batch [1540/1944], Loss: 0.0209\n",
      "Epoch [4/15], Batch [1550/1944], Loss: 0.0217\n",
      "Epoch [4/15], Batch [1560/1944], Loss: 0.0253\n",
      "Epoch [4/15], Batch [1570/1944], Loss: 0.0263\n",
      "Epoch [4/15], Batch [1580/1944], Loss: 0.0200\n",
      "Epoch [4/15], Batch [1590/1944], Loss: 0.0145\n",
      "Epoch [4/15], Batch [1600/1944], Loss: 0.0186\n",
      "Epoch [4/15], Batch [1610/1944], Loss: 0.0237\n",
      "Epoch [4/15], Batch [1620/1944], Loss: 0.0226\n",
      "Epoch [4/15], Batch [1630/1944], Loss: 0.0220\n",
      "Epoch [4/15], Batch [1640/1944], Loss: 0.0191\n",
      "Epoch [4/15], Batch [1650/1944], Loss: 0.0159\n",
      "Epoch [4/15], Batch [1660/1944], Loss: 0.0158\n",
      "Epoch [4/15], Batch [1670/1944], Loss: 0.0195\n",
      "Epoch [4/15], Batch [1680/1944], Loss: 0.0248\n",
      "Epoch [4/15], Batch [1690/1944], Loss: 0.0270\n",
      "Epoch [4/15], Batch [1700/1944], Loss: 0.0242\n",
      "Epoch [4/15], Batch [1710/1944], Loss: 0.0192\n",
      "Epoch [4/15], Batch [1720/1944], Loss: 0.0144\n",
      "Epoch [4/15], Batch [1730/1944], Loss: 0.0564\n",
      "Epoch [4/15], Batch [1740/1944], Loss: 0.0206\n",
      "Epoch [4/15], Batch [1750/1944], Loss: 0.0225\n",
      "Epoch [4/15], Batch [1760/1944], Loss: 0.0239\n",
      "Epoch [4/15], Batch [1770/1944], Loss: 0.0260\n",
      "Epoch [4/15], Batch [1780/1944], Loss: 0.0269\n",
      "Epoch [4/15], Batch [1790/1944], Loss: 0.0254\n",
      "Epoch [4/15], Batch [1800/1944], Loss: 0.0170\n",
      "Epoch [4/15], Batch [1810/1944], Loss: 0.0163\n",
      "Epoch [4/15], Batch [1820/1944], Loss: 0.0243\n",
      "Epoch [4/15], Batch [1830/1944], Loss: 0.0185\n",
      "Epoch [4/15], Batch [1840/1944], Loss: 0.0248\n",
      "Epoch [4/15], Batch [1850/1944], Loss: 0.0187\n",
      "Epoch [4/15], Batch [1860/1944], Loss: 0.0207\n",
      "Epoch [4/15], Batch [1870/1944], Loss: 0.0152\n",
      "Epoch [4/15], Batch [1880/1944], Loss: 0.0169\n",
      "Epoch [4/15], Batch [1890/1944], Loss: 0.0229\n",
      "Epoch [4/15], Batch [1900/1944], Loss: 0.0282\n",
      "Epoch [4/15], Batch [1910/1944], Loss: 0.0260\n",
      "Epoch [4/15], Batch [1920/1944], Loss: 0.0270\n",
      "Epoch [4/15], Batch [1930/1944], Loss: 0.0171\n",
      "Epoch [4/15], Batch [1940/1944], Loss: 0.0193\n",
      "Epoch [4/15], Average Loss: 0.0225\n",
      "Epoch [4/15], Validation Loss: 0.0878\n",
      "Epoch [4/15], Current Learning Rate: 0.001\n",
      "Epoch [5/15], Batch [10/1944], Loss: 0.0250\n",
      "Epoch [5/15], Batch [20/1944], Loss: 0.0256\n",
      "Epoch [5/15], Batch [30/1944], Loss: 0.0252\n",
      "Epoch [5/15], Batch [40/1944], Loss: 0.0246\n",
      "Epoch [5/15], Batch [50/1944], Loss: 0.0274\n",
      "Epoch [5/15], Batch [60/1944], Loss: 0.0282\n",
      "Epoch [5/15], Batch [70/1944], Loss: 0.0191\n",
      "Epoch [5/15], Batch [80/1944], Loss: 0.0143\n",
      "Epoch [5/15], Batch [90/1944], Loss: 0.0229\n",
      "Epoch [5/15], Batch [100/1944], Loss: 0.0209\n",
      "Epoch [5/15], Batch [110/1944], Loss: 0.0241\n",
      "Epoch [5/15], Batch [120/1944], Loss: 0.0210\n",
      "Epoch [5/15], Batch [130/1944], Loss: 0.0210\n",
      "Epoch [5/15], Batch [140/1944], Loss: 0.0191\n",
      "Epoch [5/15], Batch [150/1944], Loss: 0.0182\n",
      "Epoch [5/15], Batch [160/1944], Loss: 0.0227\n",
      "Epoch [5/15], Batch [170/1944], Loss: 0.0280\n",
      "Epoch [5/15], Batch [180/1944], Loss: 0.0271\n",
      "Epoch [5/15], Batch [190/1944], Loss: 0.0267\n",
      "Epoch [5/15], Batch [200/1944], Loss: 0.0194\n",
      "Epoch [5/15], Batch [210/1944], Loss: 0.0152\n",
      "Epoch [5/15], Batch [220/1944], Loss: 0.0548\n",
      "Epoch [5/15], Batch [230/1944], Loss: 0.0228\n",
      "Epoch [5/15], Batch [240/1944], Loss: 0.0235\n",
      "Epoch [5/15], Batch [250/1944], Loss: 0.0234\n",
      "Epoch [5/15], Batch [260/1944], Loss: 0.0265\n",
      "Epoch [5/15], Batch [270/1944], Loss: 0.0298\n",
      "Epoch [5/15], Batch [280/1944], Loss: 0.0243\n",
      "Epoch [5/15], Batch [290/1944], Loss: 0.0155\n",
      "Epoch [5/15], Batch [300/1944], Loss: 0.0161\n",
      "Epoch [5/15], Batch [310/1944], Loss: 0.0249\n",
      "Epoch [5/15], Batch [320/1944], Loss: 0.0194\n",
      "Epoch [5/15], Batch [330/1944], Loss: 0.0239\n",
      "Epoch [5/15], Batch [340/1944], Loss: 0.0173\n",
      "Epoch [5/15], Batch [350/1944], Loss: 0.0181\n",
      "Epoch [5/15], Batch [360/1944], Loss: 0.0172\n",
      "Epoch [5/15], Batch [370/1944], Loss: 0.0179\n",
      "Epoch [5/15], Batch [380/1944], Loss: 0.0255\n",
      "Epoch [5/15], Batch [390/1944], Loss: 0.0289\n",
      "Epoch [5/15], Batch [400/1944], Loss: 0.0254\n",
      "Epoch [5/15], Batch [410/1944], Loss: 0.0239\n",
      "Epoch [5/15], Batch [420/1944], Loss: 0.0125\n",
      "Epoch [5/15], Batch [430/1944], Loss: 0.0177\n",
      "Epoch [5/15], Batch [440/1944], Loss: 0.0315\n",
      "Epoch [5/15], Batch [450/1944], Loss: 0.0220\n",
      "Epoch [5/15], Batch [460/1944], Loss: 0.0232\n",
      "Epoch [5/15], Batch [470/1944], Loss: 0.0239\n",
      "Epoch [5/15], Batch [480/1944], Loss: 0.0271\n",
      "Epoch [5/15], Batch [490/1944], Loss: 0.0279\n",
      "Epoch [5/15], Batch [500/1944], Loss: 0.0207\n",
      "Epoch [5/15], Batch [510/1944], Loss: 0.0148\n",
      "Epoch [5/15], Batch [520/1944], Loss: 0.0178\n",
      "Epoch [5/15], Batch [530/1944], Loss: 0.0222\n",
      "Epoch [5/15], Batch [540/1944], Loss: 0.0223\n",
      "Epoch [5/15], Batch [550/1944], Loss: 0.0221\n",
      "Epoch [5/15], Batch [560/1944], Loss: 0.0184\n",
      "Epoch [5/15], Batch [570/1944], Loss: 0.0152\n",
      "Epoch [5/15], Batch [580/1944], Loss: 0.0157\n",
      "Epoch [5/15], Batch [590/1944], Loss: 0.0195\n",
      "Epoch [5/15], Batch [600/1944], Loss: 0.0247\n",
      "Epoch [5/15], Batch [610/1944], Loss: 0.0267\n",
      "Epoch [5/15], Batch [620/1944], Loss: 0.0241\n",
      "Epoch [5/15], Batch [630/1944], Loss: 0.0191\n",
      "Epoch [5/15], Batch [640/1944], Loss: 0.0143\n",
      "Epoch [5/15], Batch [650/1944], Loss: 0.0590\n",
      "Epoch [5/15], Batch [660/1944], Loss: 0.0233\n",
      "Epoch [5/15], Batch [670/1944], Loss: 0.0246\n",
      "Epoch [5/15], Batch [680/1944], Loss: 0.0254\n",
      "Epoch [5/15], Batch [690/1944], Loss: 0.0268\n",
      "Epoch [5/15], Batch [700/1944], Loss: 0.0275\n",
      "Epoch [5/15], Batch [710/1944], Loss: 0.0256\n",
      "Epoch [5/15], Batch [720/1944], Loss: 0.0167\n",
      "Epoch [5/15], Batch [730/1944], Loss: 0.0154\n",
      "Epoch [5/15], Batch [740/1944], Loss: 0.0224\n",
      "Epoch [5/15], Batch [750/1944], Loss: 0.0173\n",
      "Epoch [5/15], Batch [760/1944], Loss: 0.0240\n",
      "Epoch [5/15], Batch [770/1944], Loss: 0.0177\n",
      "Epoch [5/15], Batch [780/1944], Loss: 0.0195\n",
      "Epoch [5/15], Batch [790/1944], Loss: 0.0144\n",
      "Epoch [5/15], Batch [800/1944], Loss: 0.0163\n",
      "Epoch [5/15], Batch [810/1944], Loss: 0.0223\n",
      "Epoch [5/15], Batch [820/1944], Loss: 0.0274\n",
      "Epoch [5/15], Batch [830/1944], Loss: 0.0252\n",
      "Epoch [5/15], Batch [840/1944], Loss: 0.0261\n",
      "Epoch [5/15], Batch [850/1944], Loss: 0.0159\n",
      "Epoch [5/15], Batch [860/1944], Loss: 0.0179\n",
      "Epoch [5/15], Batch [870/1944], Loss: 0.0403\n",
      "Epoch [5/15], Batch [880/1944], Loss: 0.0209\n",
      "Epoch [5/15], Batch [890/1944], Loss: 0.0223\n",
      "Epoch [5/15], Batch [900/1944], Loss: 0.0241\n",
      "Epoch [5/15], Batch [910/1944], Loss: 0.0282\n",
      "Epoch [5/15], Batch [920/1944], Loss: 0.0306\n",
      "Epoch [5/15], Batch [930/1944], Loss: 0.0229\n",
      "Epoch [5/15], Batch [940/1944], Loss: 0.0146\n",
      "Epoch [5/15], Batch [950/1944], Loss: 0.0188\n",
      "Epoch [5/15], Batch [960/1944], Loss: 0.0219\n",
      "Epoch [5/15], Batch [970/1944], Loss: 0.0192\n",
      "Epoch [5/15], Batch [980/1944], Loss: 0.0204\n",
      "Epoch [5/15], Batch [990/1944], Loss: 0.0177\n",
      "Epoch [5/15], Batch [1000/1944], Loss: 0.0167\n",
      "Epoch [5/15], Batch [1010/1944], Loss: 0.0150\n",
      "Epoch [5/15], Batch [1020/1944], Loss: 0.0161\n",
      "Epoch [5/15], Batch [1030/1944], Loss: 0.0259\n",
      "Epoch [5/15], Batch [1040/1944], Loss: 0.0284\n",
      "Epoch [5/15], Batch [1050/1944], Loss: 0.0261\n",
      "Epoch [5/15], Batch [1060/1944], Loss: 0.0223\n",
      "Epoch [5/15], Batch [1070/1944], Loss: 0.0126\n",
      "Epoch [5/15], Batch [1080/1944], Loss: 0.0128\n",
      "Epoch [5/15], Batch [1090/1944], Loss: 0.0219\n",
      "Epoch [5/15], Batch [1100/1944], Loss: 0.0224\n",
      "Epoch [5/15], Batch [1110/1944], Loss: 0.0233\n",
      "Epoch [5/15], Batch [1120/1944], Loss: 0.0228\n",
      "Epoch [5/15], Batch [1130/1944], Loss: 0.0260\n",
      "Epoch [5/15], Batch [1140/1944], Loss: 0.0271\n",
      "Epoch [5/15], Batch [1150/1944], Loss: 0.0194\n",
      "Epoch [5/15], Batch [1160/1944], Loss: 0.0145\n",
      "Epoch [5/15], Batch [1170/1944], Loss: 0.0224\n",
      "Epoch [5/15], Batch [1180/1944], Loss: 0.0202\n",
      "Epoch [5/15], Batch [1190/1944], Loss: 0.0235\n",
      "Epoch [5/15], Batch [1200/1944], Loss: 0.0188\n",
      "Epoch [5/15], Batch [1210/1944], Loss: 0.0185\n",
      "Epoch [5/15], Batch [1220/1944], Loss: 0.0173\n",
      "Epoch [5/15], Batch [1230/1944], Loss: 0.0167\n",
      "Epoch [5/15], Batch [1240/1944], Loss: 0.0214\n",
      "Epoch [5/15], Batch [1250/1944], Loss: 0.0266\n",
      "Epoch [5/15], Batch [1260/1944], Loss: 0.0273\n",
      "Epoch [5/15], Batch [1270/1944], Loss: 0.0275\n",
      "Epoch [5/15], Batch [1280/1944], Loss: 0.0206\n",
      "Epoch [5/15], Batch [1290/1944], Loss: 0.0174\n",
      "Epoch [5/15], Batch [1300/1944], Loss: 0.0511\n",
      "Epoch [5/15], Batch [1310/1944], Loss: 0.0227\n",
      "Epoch [5/15], Batch [1320/1944], Loss: 0.0233\n",
      "Epoch [5/15], Batch [1330/1944], Loss: 0.0234\n",
      "Epoch [5/15], Batch [1340/1944], Loss: 0.0265\n",
      "Epoch [5/15], Batch [1350/1944], Loss: 0.0295\n",
      "Epoch [5/15], Batch [1360/1944], Loss: 0.0242\n",
      "Epoch [5/15], Batch [1370/1944], Loss: 0.0159\n",
      "Epoch [5/15], Batch [1380/1944], Loss: 0.0166\n",
      "Epoch [5/15], Batch [1390/1944], Loss: 0.0251\n",
      "Epoch [5/15], Batch [1400/1944], Loss: 0.0192\n",
      "Epoch [5/15], Batch [1410/1944], Loss: 0.0229\n",
      "Epoch [5/15], Batch [1420/1944], Loss: 0.0167\n",
      "Epoch [5/15], Batch [1430/1944], Loss: 0.0178\n",
      "Epoch [5/15], Batch [1440/1944], Loss: 0.0168\n",
      "Epoch [5/15], Batch [1450/1944], Loss: 0.0178\n",
      "Epoch [5/15], Batch [1460/1944], Loss: 0.0251\n",
      "Epoch [5/15], Batch [1470/1944], Loss: 0.0285\n",
      "Epoch [5/15], Batch [1480/1944], Loss: 0.0252\n",
      "Epoch [5/15], Batch [1490/1944], Loss: 0.0235\n",
      "Epoch [5/15], Batch [1500/1944], Loss: 0.0122\n",
      "Epoch [5/15], Batch [1510/1944], Loss: 0.0170\n",
      "Epoch [5/15], Batch [1520/1944], Loss: 0.0258\n",
      "Epoch [5/15], Batch [1530/1944], Loss: 0.0186\n",
      "Epoch [5/15], Batch [1540/1944], Loss: 0.0209\n",
      "Epoch [5/15], Batch [1550/1944], Loss: 0.0219\n",
      "Epoch [5/15], Batch [1560/1944], Loss: 0.0253\n",
      "Epoch [5/15], Batch [1570/1944], Loss: 0.0265\n",
      "Epoch [5/15], Batch [1580/1944], Loss: 0.0203\n",
      "Epoch [5/15], Batch [1590/1944], Loss: 0.0152\n",
      "Epoch [5/15], Batch [1600/1944], Loss: 0.0194\n",
      "Epoch [5/15], Batch [1610/1944], Loss: 0.0240\n",
      "Epoch [5/15], Batch [1620/1944], Loss: 0.0235\n",
      "Epoch [5/15], Batch [1630/1944], Loss: 0.0223\n",
      "Epoch [5/15], Batch [1640/1944], Loss: 0.0194\n",
      "Epoch [5/15], Batch [1650/1944], Loss: 0.0163\n",
      "Epoch [5/15], Batch [1660/1944], Loss: 0.0166\n",
      "Epoch [5/15], Batch [1670/1944], Loss: 0.0202\n",
      "Epoch [5/15], Batch [1680/1944], Loss: 0.0254\n",
      "Epoch [5/15], Batch [1690/1944], Loss: 0.0277\n",
      "Epoch [5/15], Batch [1700/1944], Loss: 0.0247\n",
      "Epoch [5/15], Batch [1710/1944], Loss: 0.0202\n",
      "Epoch [5/15], Batch [1720/1944], Loss: 0.0157\n",
      "Epoch [5/15], Batch [1730/1944], Loss: 0.0551\n",
      "Epoch [5/15], Batch [1740/1944], Loss: 0.0208\n",
      "Epoch [5/15], Batch [1750/1944], Loss: 0.0231\n",
      "Epoch [5/15], Batch [1760/1944], Loss: 0.0246\n",
      "Epoch [5/15], Batch [1770/1944], Loss: 0.0266\n",
      "Epoch [5/15], Batch [1780/1944], Loss: 0.0274\n",
      "Epoch [5/15], Batch [1790/1944], Loss: 0.0259\n",
      "Epoch [5/15], Batch [1800/1944], Loss: 0.0175\n",
      "Epoch [5/15], Batch [1810/1944], Loss: 0.0170\n",
      "Epoch [5/15], Batch [1820/1944], Loss: 0.0249\n",
      "Epoch [5/15], Batch [1830/1944], Loss: 0.0194\n",
      "Epoch [5/15], Batch [1840/1944], Loss: 0.0258\n",
      "Epoch [5/15], Batch [1850/1944], Loss: 0.0193\n",
      "Epoch [5/15], Batch [1860/1944], Loss: 0.0211\n",
      "Epoch [5/15], Batch [1870/1944], Loss: 0.0158\n",
      "Epoch [5/15], Batch [1880/1944], Loss: 0.0175\n",
      "Epoch [5/15], Batch [1890/1944], Loss: 0.0236\n",
      "Epoch [5/15], Batch [1900/1944], Loss: 0.0291\n",
      "Epoch [5/15], Batch [1910/1944], Loss: 0.0269\n",
      "Epoch [5/15], Batch [1920/1944], Loss: 0.0280\n",
      "Epoch [5/15], Batch [1930/1944], Loss: 0.0182\n",
      "Epoch [5/15], Batch [1940/1944], Loss: 0.0205\n",
      "Epoch [5/15], Average Loss: 0.0226\n",
      "Epoch [5/15], Validation Loss: 0.0906\n",
      "Epoch [5/15], Current Learning Rate: 0.0005\n",
      "Epoch [6/15], Batch [10/1944], Loss: 0.0241\n",
      "Epoch [6/15], Batch [20/1944], Loss: 0.0240\n",
      "Epoch [6/15], Batch [30/1944], Loss: 0.0234\n",
      "Epoch [6/15], Batch [40/1944], Loss: 0.0232\n",
      "Epoch [6/15], Batch [50/1944], Loss: 0.0272\n",
      "Epoch [6/15], Batch [60/1944], Loss: 0.0276\n",
      "Epoch [6/15], Batch [70/1944], Loss: 0.0186\n",
      "Epoch [6/15], Batch [80/1944], Loss: 0.0139\n",
      "Epoch [6/15], Batch [90/1944], Loss: 0.0227\n",
      "Epoch [6/15], Batch [100/1944], Loss: 0.0211\n",
      "Epoch [6/15], Batch [110/1944], Loss: 0.0242\n",
      "Epoch [6/15], Batch [120/1944], Loss: 0.0207\n",
      "Epoch [6/15], Batch [130/1944], Loss: 0.0209\n",
      "Epoch [6/15], Batch [140/1944], Loss: 0.0192\n",
      "Epoch [6/15], Batch [150/1944], Loss: 0.0182\n",
      "Epoch [6/15], Batch [160/1944], Loss: 0.0226\n",
      "Epoch [6/15], Batch [170/1944], Loss: 0.0275\n",
      "Epoch [6/15], Batch [180/1944], Loss: 0.0267\n",
      "Epoch [6/15], Batch [190/1944], Loss: 0.0263\n",
      "Epoch [6/15], Batch [200/1944], Loss: 0.0191\n",
      "Epoch [6/15], Batch [210/1944], Loss: 0.0151\n",
      "Epoch [6/15], Batch [220/1944], Loss: 0.0597\n",
      "Epoch [6/15], Batch [230/1944], Loss: 0.0236\n",
      "Epoch [6/15], Batch [240/1944], Loss: 0.0249\n",
      "Epoch [6/15], Batch [250/1944], Loss: 0.0253\n",
      "Epoch [6/15], Batch [260/1944], Loss: 0.0284\n",
      "Epoch [6/15], Batch [270/1944], Loss: 0.0312\n",
      "Epoch [6/15], Batch [280/1944], Loss: 0.0255\n",
      "Epoch [6/15], Batch [290/1944], Loss: 0.0164\n",
      "Epoch [6/15], Batch [300/1944], Loss: 0.0168\n",
      "Epoch [6/15], Batch [310/1944], Loss: 0.0252\n",
      "Epoch [6/15], Batch [320/1944], Loss: 0.0201\n",
      "Epoch [6/15], Batch [330/1944], Loss: 0.0242\n",
      "Epoch [6/15], Batch [340/1944], Loss: 0.0175\n",
      "Epoch [6/15], Batch [350/1944], Loss: 0.0183\n",
      "Epoch [6/15], Batch [360/1944], Loss: 0.0176\n",
      "Epoch [6/15], Batch [370/1944], Loss: 0.0182\n",
      "Epoch [6/15], Batch [380/1944], Loss: 0.0253\n",
      "Epoch [6/15], Batch [390/1944], Loss: 0.0287\n",
      "Epoch [6/15], Batch [400/1944], Loss: 0.0255\n",
      "Epoch [6/15], Batch [410/1944], Loss: 0.0243\n",
      "Epoch [6/15], Batch [420/1944], Loss: 0.0129\n",
      "Epoch [6/15], Batch [430/1944], Loss: 0.0184\n",
      "Epoch [6/15], Batch [440/1944], Loss: 0.0315\n",
      "Epoch [6/15], Batch [450/1944], Loss: 0.0229\n",
      "Epoch [6/15], Batch [460/1944], Loss: 0.0237\n",
      "Epoch [6/15], Batch [470/1944], Loss: 0.0243\n",
      "Epoch [6/15], Batch [480/1944], Loss: 0.0276\n",
      "Epoch [6/15], Batch [490/1944], Loss: 0.0285\n",
      "Epoch [6/15], Batch [500/1944], Loss: 0.0217\n",
      "Epoch [6/15], Batch [510/1944], Loss: 0.0158\n",
      "Epoch [6/15], Batch [520/1944], Loss: 0.0192\n",
      "Epoch [6/15], Batch [530/1944], Loss: 0.0232\n",
      "Epoch [6/15], Batch [540/1944], Loss: 0.0236\n",
      "Epoch [6/15], Batch [550/1944], Loss: 0.0226\n",
      "Epoch [6/15], Batch [560/1944], Loss: 0.0187\n",
      "Epoch [6/15], Batch [570/1944], Loss: 0.0156\n",
      "Epoch [6/15], Batch [580/1944], Loss: 0.0163\n",
      "Epoch [6/15], Batch [590/1944], Loss: 0.0202\n",
      "Epoch [6/15], Batch [600/1944], Loss: 0.0258\n",
      "Epoch [6/15], Batch [610/1944], Loss: 0.0281\n",
      "Epoch [6/15], Batch [620/1944], Loss: 0.0259\n",
      "Epoch [6/15], Batch [630/1944], Loss: 0.0216\n",
      "Epoch [6/15], Batch [640/1944], Loss: 0.0170\n",
      "Epoch [6/15], Batch [650/1944], Loss: 0.0571\n",
      "Epoch [6/15], Batch [660/1944], Loss: 0.0213\n",
      "Epoch [6/15], Batch [670/1944], Loss: 0.0235\n",
      "Epoch [6/15], Batch [680/1944], Loss: 0.0248\n",
      "Epoch [6/15], Batch [690/1944], Loss: 0.0266\n",
      "Epoch [6/15], Batch [700/1944], Loss: 0.0277\n",
      "Epoch [6/15], Batch [710/1944], Loss: 0.0258\n",
      "Epoch [6/15], Batch [720/1944], Loss: 0.0172\n",
      "Epoch [6/15], Batch [730/1944], Loss: 0.0161\n",
      "Epoch [6/15], Batch [740/1944], Loss: 0.0232\n",
      "Epoch [6/15], Batch [750/1944], Loss: 0.0182\n",
      "Epoch [6/15], Batch [760/1944], Loss: 0.0248\n",
      "Epoch [6/15], Batch [770/1944], Loss: 0.0180\n",
      "Epoch [6/15], Batch [780/1944], Loss: 0.0196\n",
      "Epoch [6/15], Batch [790/1944], Loss: 0.0146\n",
      "Epoch [6/15], Batch [800/1944], Loss: 0.0165\n",
      "Epoch [6/15], Batch [810/1944], Loss: 0.0226\n",
      "Epoch [6/15], Batch [820/1944], Loss: 0.0278\n",
      "Epoch [6/15], Batch [830/1944], Loss: 0.0256\n",
      "Epoch [6/15], Batch [840/1944], Loss: 0.0264\n",
      "Epoch [6/15], Batch [850/1944], Loss: 0.0162\n",
      "Epoch [6/15], Batch [860/1944], Loss: 0.0182\n",
      "Epoch [6/15], Batch [870/1944], Loss: 0.0398\n",
      "Epoch [6/15], Batch [880/1944], Loss: 0.0202\n",
      "Epoch [6/15], Batch [890/1944], Loss: 0.0223\n",
      "Epoch [6/15], Batch [900/1944], Loss: 0.0244\n",
      "Epoch [6/15], Batch [910/1944], Loss: 0.0287\n",
      "Epoch [6/15], Batch [920/1944], Loss: 0.0312\n",
      "Epoch [6/15], Batch [930/1944], Loss: 0.0238\n",
      "Epoch [6/15], Batch [940/1944], Loss: 0.0159\n",
      "Epoch [6/15], Batch [950/1944], Loss: 0.0204\n",
      "Epoch [6/15], Batch [960/1944], Loss: 0.0233\n",
      "Epoch [6/15], Batch [970/1944], Loss: 0.0208\n",
      "Epoch [6/15], Batch [980/1944], Loss: 0.0212\n",
      "Epoch [6/15], Batch [990/1944], Loss: 0.0179\n",
      "Epoch [6/15], Batch [1000/1944], Loss: 0.0168\n",
      "Epoch [6/15], Batch [1010/1944], Loss: 0.0155\n",
      "Epoch [6/15], Batch [1020/1944], Loss: 0.0163\n",
      "Epoch [6/15], Batch [1030/1944], Loss: 0.0264\n",
      "Epoch [6/15], Batch [1040/1944], Loss: 0.0295\n",
      "Epoch [6/15], Batch [1050/1944], Loss: 0.0274\n",
      "Epoch [6/15], Batch [1060/1944], Loss: 0.0238\n",
      "Epoch [6/15], Batch [1070/1944], Loss: 0.0142\n",
      "Epoch [6/15], Batch [1080/1944], Loss: 0.0137\n",
      "Epoch [6/15], Batch [1090/1944], Loss: 0.0214\n",
      "Epoch [6/15], Batch [1100/1944], Loss: 0.0230\n",
      "Epoch [6/15], Batch [1110/1944], Loss: 0.0242\n",
      "Epoch [6/15], Batch [1120/1944], Loss: 0.0234\n",
      "Epoch [6/15], Batch [1130/1944], Loss: 0.0267\n",
      "Epoch [6/15], Batch [1140/1944], Loss: 0.0279\n",
      "Epoch [6/15], Batch [1150/1944], Loss: 0.0202\n",
      "Epoch [6/15], Batch [1160/1944], Loss: 0.0153\n",
      "Epoch [6/15], Batch [1170/1944], Loss: 0.0234\n",
      "Epoch [6/15], Batch [1180/1944], Loss: 0.0212\n",
      "Epoch [6/15], Batch [1190/1944], Loss: 0.0246\n",
      "Epoch [6/15], Batch [1200/1944], Loss: 0.0196\n",
      "Epoch [6/15], Batch [1210/1944], Loss: 0.0190\n",
      "Epoch [6/15], Batch [1220/1944], Loss: 0.0178\n",
      "Epoch [6/15], Batch [1230/1944], Loss: 0.0174\n",
      "Epoch [6/15], Batch [1240/1944], Loss: 0.0222\n",
      "Epoch [6/15], Batch [1250/1944], Loss: 0.0276\n",
      "Epoch [6/15], Batch [1260/1944], Loss: 0.0288\n",
      "Epoch [6/15], Batch [1270/1944], Loss: 0.0292\n",
      "Epoch [6/15], Batch [1280/1944], Loss: 0.0223\n",
      "Epoch [6/15], Batch [1290/1944], Loss: 0.0195\n",
      "Epoch [6/15], Batch [1300/1944], Loss: 0.0501\n",
      "Epoch [6/15], Batch [1310/1944], Loss: 0.0224\n",
      "Epoch [6/15], Batch [1320/1944], Loss: 0.0236\n",
      "Epoch [6/15], Batch [1330/1944], Loss: 0.0233\n",
      "Epoch [6/15], Batch [1340/1944], Loss: 0.0263\n",
      "Epoch [6/15], Batch [1350/1944], Loss: 0.0293\n",
      "Epoch [6/15], Batch [1360/1944], Loss: 0.0242\n",
      "Epoch [6/15], Batch [1370/1944], Loss: 0.0162\n",
      "Epoch [6/15], Batch [1380/1944], Loss: 0.0172\n",
      "Epoch [6/15], Batch [1390/1944], Loss: 0.0258\n",
      "Epoch [6/15], Batch [1400/1944], Loss: 0.0200\n",
      "Epoch [6/15], Batch [1410/1944], Loss: 0.0230\n",
      "Epoch [6/15], Batch [1420/1944], Loss: 0.0167\n",
      "Epoch [6/15], Batch [1430/1944], Loss: 0.0177\n",
      "Epoch [6/15], Batch [1440/1944], Loss: 0.0165\n",
      "Epoch [6/15], Batch [1450/1944], Loss: 0.0173\n",
      "Epoch [6/15], Batch [1460/1944], Loss: 0.0246\n",
      "Epoch [6/15], Batch [1470/1944], Loss: 0.0277\n",
      "Epoch [6/15], Batch [1480/1944], Loss: 0.0239\n",
      "Epoch [6/15], Batch [1490/1944], Loss: 0.0223\n",
      "Epoch [6/15], Batch [1500/1944], Loss: 0.0117\n",
      "Epoch [6/15], Batch [1510/1944], Loss: 0.0173\n",
      "Epoch [6/15], Batch [1520/1944], Loss: 0.0245\n",
      "Epoch [6/15], Batch [1530/1944], Loss: 0.0183\n",
      "Epoch [6/15], Batch [1540/1944], Loss: 0.0211\n",
      "Epoch [6/15], Batch [1550/1944], Loss: 0.0223\n",
      "Epoch [6/15], Batch [1560/1944], Loss: 0.0261\n",
      "Epoch [6/15], Batch [1570/1944], Loss: 0.0271\n",
      "Epoch [6/15], Batch [1580/1944], Loss: 0.0206\n",
      "Epoch [6/15], Batch [1590/1944], Loss: 0.0154\n",
      "Epoch [6/15], Batch [1600/1944], Loss: 0.0199\n",
      "Epoch [6/15], Batch [1610/1944], Loss: 0.0245\n",
      "Epoch [6/15], Batch [1620/1944], Loss: 0.0240\n",
      "Epoch [6/15], Batch [1630/1944], Loss: 0.0226\n",
      "Epoch [6/15], Batch [1640/1944], Loss: 0.0192\n",
      "Epoch [6/15], Batch [1650/1944], Loss: 0.0162\n",
      "Epoch [6/15], Batch [1660/1944], Loss: 0.0166\n",
      "Epoch [6/15], Batch [1670/1944], Loss: 0.0205\n",
      "Epoch [6/15], Batch [1680/1944], Loss: 0.0261\n",
      "Epoch [6/15], Batch [1690/1944], Loss: 0.0286\n",
      "Epoch [6/15], Batch [1700/1944], Loss: 0.0257\n",
      "Epoch [6/15], Batch [1710/1944], Loss: 0.0214\n",
      "Epoch [6/15], Batch [1720/1944], Loss: 0.0171\n",
      "Epoch [6/15], Batch [1730/1944], Loss: 0.0540\n",
      "Epoch [6/15], Batch [1740/1944], Loss: 0.0203\n",
      "Epoch [6/15], Batch [1750/1944], Loss: 0.0234\n",
      "Epoch [6/15], Batch [1760/1944], Loss: 0.0246\n",
      "Epoch [6/15], Batch [1770/1944], Loss: 0.0265\n",
      "Epoch [6/15], Batch [1780/1944], Loss: 0.0274\n",
      "Epoch [6/15], Batch [1790/1944], Loss: 0.0259\n",
      "Epoch [6/15], Batch [1800/1944], Loss: 0.0174\n",
      "Epoch [6/15], Batch [1810/1944], Loss: 0.0169\n",
      "Epoch [6/15], Batch [1820/1944], Loss: 0.0250\n",
      "Epoch [6/15], Batch [1830/1944], Loss: 0.0193\n",
      "Epoch [6/15], Batch [1840/1944], Loss: 0.0257\n",
      "Epoch [6/15], Batch [1850/1944], Loss: 0.0192\n",
      "Epoch [6/15], Batch [1860/1944], Loss: 0.0211\n",
      "Epoch [6/15], Batch [1870/1944], Loss: 0.0159\n",
      "Epoch [6/15], Batch [1880/1944], Loss: 0.0176\n",
      "Epoch [6/15], Batch [1890/1944], Loss: 0.0238\n",
      "Epoch [6/15], Batch [1900/1944], Loss: 0.0296\n",
      "Epoch [6/15], Batch [1910/1944], Loss: 0.0274\n",
      "Epoch [6/15], Batch [1920/1944], Loss: 0.0285\n",
      "Epoch [6/15], Batch [1930/1944], Loss: 0.0188\n",
      "Epoch [6/15], Batch [1940/1944], Loss: 0.0212\n",
      "Epoch [6/15], Average Loss: 0.0229\n",
      "Epoch [6/15], Validation Loss: 0.0882\n",
      "Epoch [6/15], Current Learning Rate: 0.0005\n",
      "Epoch [7/15], Batch [10/1944], Loss: 0.0223\n",
      "Epoch [7/15], Batch [20/1944], Loss: 0.0215\n",
      "Epoch [7/15], Batch [30/1944], Loss: 0.0222\n",
      "Epoch [7/15], Batch [40/1944], Loss: 0.0229\n",
      "Epoch [7/15], Batch [50/1944], Loss: 0.0268\n",
      "Epoch [7/15], Batch [60/1944], Loss: 0.0276\n",
      "Epoch [7/15], Batch [70/1944], Loss: 0.0185\n",
      "Epoch [7/15], Batch [80/1944], Loss: 0.0136\n",
      "Epoch [7/15], Batch [90/1944], Loss: 0.0226\n",
      "Epoch [7/15], Batch [100/1944], Loss: 0.0210\n",
      "Epoch [7/15], Batch [110/1944], Loss: 0.0242\n",
      "Epoch [7/15], Batch [120/1944], Loss: 0.0207\n",
      "Epoch [7/15], Batch [130/1944], Loss: 0.0209\n",
      "Epoch [7/15], Batch [140/1944], Loss: 0.0194\n",
      "Epoch [7/15], Batch [150/1944], Loss: 0.0183\n",
      "Epoch [7/15], Batch [160/1944], Loss: 0.0229\n",
      "Epoch [7/15], Batch [170/1944], Loss: 0.0280\n",
      "Epoch [7/15], Batch [180/1944], Loss: 0.0281\n",
      "Epoch [7/15], Batch [190/1944], Loss: 0.0286\n",
      "Epoch [7/15], Batch [200/1944], Loss: 0.0213\n",
      "Epoch [7/15], Batch [210/1944], Loss: 0.0180\n",
      "Epoch [7/15], Batch [220/1944], Loss: 0.0542\n",
      "Epoch [7/15], Batch [230/1944], Loss: 0.0246\n",
      "Epoch [7/15], Batch [240/1944], Loss: 0.0257\n",
      "Epoch [7/15], Batch [250/1944], Loss: 0.0257\n",
      "Epoch [7/15], Batch [260/1944], Loss: 0.0285\n",
      "Epoch [7/15], Batch [270/1944], Loss: 0.0313\n",
      "Epoch [7/15], Batch [280/1944], Loss: 0.0261\n",
      "Epoch [7/15], Batch [290/1944], Loss: 0.0173\n",
      "Epoch [7/15], Batch [300/1944], Loss: 0.0180\n",
      "Epoch [7/15], Batch [310/1944], Loss: 0.0266\n",
      "Epoch [7/15], Batch [320/1944], Loss: 0.0217\n",
      "Epoch [7/15], Batch [330/1944], Loss: 0.0255\n",
      "Epoch [7/15], Batch [340/1944], Loss: 0.0183\n",
      "Epoch [7/15], Batch [350/1944], Loss: 0.0189\n",
      "Epoch [7/15], Batch [360/1944], Loss: 0.0181\n",
      "Epoch [7/15], Batch [370/1944], Loss: 0.0189\n",
      "Epoch [7/15], Batch [380/1944], Loss: 0.0264\n",
      "Epoch [7/15], Batch [390/1944], Loss: 0.0296\n",
      "Epoch [7/15], Batch [400/1944], Loss: 0.0260\n",
      "Epoch [7/15], Batch [410/1944], Loss: 0.0246\n",
      "Epoch [7/15], Batch [420/1944], Loss: 0.0131\n",
      "Epoch [7/15], Batch [430/1944], Loss: 0.0185\n",
      "Epoch [7/15], Batch [440/1944], Loss: 0.0305\n",
      "Epoch [7/15], Batch [450/1944], Loss: 0.0225\n",
      "Epoch [7/15], Batch [460/1944], Loss: 0.0239\n",
      "Epoch [7/15], Batch [470/1944], Loss: 0.0244\n",
      "Epoch [7/15], Batch [480/1944], Loss: 0.0275\n",
      "Epoch [7/15], Batch [490/1944], Loss: 0.0285\n",
      "Epoch [7/15], Batch [500/1944], Loss: 0.0219\n",
      "Epoch [7/15], Batch [510/1944], Loss: 0.0162\n",
      "Epoch [7/15], Batch [520/1944], Loss: 0.0194\n",
      "Epoch [7/15], Batch [530/1944], Loss: 0.0232\n",
      "Epoch [7/15], Batch [540/1944], Loss: 0.0237\n",
      "Epoch [7/15], Batch [550/1944], Loss: 0.0228\n",
      "Epoch [7/15], Batch [560/1944], Loss: 0.0189\n",
      "Epoch [7/15], Batch [570/1944], Loss: 0.0158\n",
      "Epoch [7/15], Batch [580/1944], Loss: 0.0165\n",
      "Epoch [7/15], Batch [590/1944], Loss: 0.0205\n",
      "Epoch [7/15], Batch [600/1944], Loss: 0.0260\n",
      "Epoch [7/15], Batch [610/1944], Loss: 0.0284\n",
      "Epoch [7/15], Batch [620/1944], Loss: 0.0262\n",
      "Epoch [7/15], Batch [630/1944], Loss: 0.0221\n",
      "Epoch [7/15], Batch [640/1944], Loss: 0.0176\n",
      "Epoch [7/15], Batch [650/1944], Loss: 0.0560\n",
      "Epoch [7/15], Batch [660/1944], Loss: 0.0221\n",
      "Epoch [7/15], Batch [670/1944], Loss: 0.0249\n",
      "Epoch [7/15], Batch [680/1944], Loss: 0.0259\n",
      "Epoch [7/15], Batch [690/1944], Loss: 0.0274\n",
      "Epoch [7/15], Batch [700/1944], Loss: 0.0283\n",
      "Epoch [7/15], Batch [710/1944], Loss: 0.0265\n",
      "Epoch [7/15], Batch [720/1944], Loss: 0.0179\n",
      "Epoch [7/15], Batch [730/1944], Loss: 0.0169\n",
      "Epoch [7/15], Batch [740/1944], Loss: 0.0235\n",
      "Epoch [7/15], Batch [750/1944], Loss: 0.0186\n",
      "Epoch [7/15], Batch [760/1944], Loss: 0.0252\n",
      "Epoch [7/15], Batch [770/1944], Loss: 0.0185\n",
      "Epoch [7/15], Batch [780/1944], Loss: 0.0199\n",
      "Epoch [7/15], Batch [790/1944], Loss: 0.0151\n",
      "Epoch [7/15], Batch [800/1944], Loss: 0.0170\n",
      "Epoch [7/15], Batch [810/1944], Loss: 0.0231\n",
      "Epoch [7/15], Batch [820/1944], Loss: 0.0287\n",
      "Epoch [7/15], Batch [830/1944], Loss: 0.0269\n",
      "Epoch [7/15], Batch [840/1944], Loss: 0.0285\n",
      "Epoch [7/15], Batch [850/1944], Loss: 0.0189\n",
      "Epoch [7/15], Batch [860/1944], Loss: 0.0216\n",
      "Epoch [7/15], Batch [870/1944], Loss: 0.0395\n",
      "Epoch [7/15], Batch [880/1944], Loss: 0.0210\n",
      "Epoch [7/15], Batch [890/1944], Loss: 0.0230\n",
      "Epoch [7/15], Batch [900/1944], Loss: 0.0246\n",
      "Epoch [7/15], Batch [910/1944], Loss: 0.0288\n",
      "Epoch [7/15], Batch [920/1944], Loss: 0.0315\n",
      "Epoch [7/15], Batch [930/1944], Loss: 0.0243\n",
      "Epoch [7/15], Batch [940/1944], Loss: 0.0169\n",
      "Epoch [7/15], Batch [950/1944], Loss: 0.0216\n",
      "Epoch [7/15], Batch [960/1944], Loss: 0.0244\n",
      "Epoch [7/15], Batch [970/1944], Loss: 0.0219\n",
      "Epoch [7/15], Batch [980/1944], Loss: 0.0221\n",
      "Epoch [7/15], Batch [990/1944], Loss: 0.0189\n",
      "Epoch [7/15], Batch [1000/1944], Loss: 0.0179\n",
      "Epoch [7/15], Batch [1010/1944], Loss: 0.0165\n",
      "Epoch [7/15], Batch [1020/1944], Loss: 0.0172\n",
      "Epoch [7/15], Batch [1030/1944], Loss: 0.0271\n",
      "Epoch [7/15], Batch [1040/1944], Loss: 0.0302\n",
      "Epoch [7/15], Batch [1050/1944], Loss: 0.0282\n",
      "Epoch [7/15], Batch [1060/1944], Loss: 0.0245\n",
      "Epoch [7/15], Batch [1070/1944], Loss: 0.0154\n",
      "Epoch [7/15], Batch [1080/1944], Loss: 0.0150\n",
      "Epoch [7/15], Batch [1090/1944], Loss: 0.0210\n",
      "Epoch [7/15], Batch [1100/1944], Loss: 0.0228\n",
      "Epoch [7/15], Batch [1110/1944], Loss: 0.0240\n",
      "Epoch [7/15], Batch [1120/1944], Loss: 0.0235\n",
      "Epoch [7/15], Batch [1130/1944], Loss: 0.0268\n",
      "Epoch [7/15], Batch [1140/1944], Loss: 0.0280\n",
      "Epoch [7/15], Batch [1150/1944], Loss: 0.0202\n",
      "Epoch [7/15], Batch [1160/1944], Loss: 0.0154\n",
      "Epoch [7/15], Batch [1170/1944], Loss: 0.0238\n",
      "Epoch [7/15], Batch [1180/1944], Loss: 0.0215\n",
      "Epoch [7/15], Batch [1190/1944], Loss: 0.0248\n",
      "Epoch [7/15], Batch [1200/1944], Loss: 0.0199\n",
      "Epoch [7/15], Batch [1210/1944], Loss: 0.0194\n",
      "Epoch [7/15], Batch [1220/1944], Loss: 0.0180\n",
      "Epoch [7/15], Batch [1230/1944], Loss: 0.0175\n",
      "Epoch [7/15], Batch [1240/1944], Loss: 0.0224\n",
      "Epoch [7/15], Batch [1250/1944], Loss: 0.0277\n",
      "Epoch [7/15], Batch [1260/1944], Loss: 0.0289\n",
      "Epoch [7/15], Batch [1270/1944], Loss: 0.0294\n",
      "Epoch [7/15], Batch [1280/1944], Loss: 0.0225\n",
      "Epoch [7/15], Batch [1290/1944], Loss: 0.0198\n",
      "Epoch [7/15], Batch [1300/1944], Loss: 0.0503\n",
      "Epoch [7/15], Batch [1310/1944], Loss: 0.0221\n",
      "Epoch [7/15], Batch [1320/1944], Loss: 0.0231\n",
      "Epoch [7/15], Batch [1330/1944], Loss: 0.0226\n",
      "Epoch [7/15], Batch [1340/1944], Loss: 0.0256\n",
      "Epoch [7/15], Batch [1350/1944], Loss: 0.0284\n",
      "Epoch [7/15], Batch [1360/1944], Loss: 0.0232\n",
      "Epoch [7/15], Batch [1370/1944], Loss: 0.0151\n",
      "Epoch [7/15], Batch [1380/1944], Loss: 0.0162\n",
      "Epoch [7/15], Batch [1390/1944], Loss: 0.0251\n",
      "Epoch [7/15], Batch [1400/1944], Loss: 0.0194\n",
      "Epoch [7/15], Batch [1410/1944], Loss: 0.0227\n",
      "Epoch [7/15], Batch [1420/1944], Loss: 0.0164\n",
      "Epoch [7/15], Batch [1430/1944], Loss: 0.0175\n",
      "Epoch [7/15], Batch [1440/1944], Loss: 0.0159\n",
      "Epoch [7/15], Batch [1450/1944], Loss: 0.0165\n",
      "Epoch [7/15], Batch [1460/1944], Loss: 0.0236\n",
      "Epoch [7/15], Batch [1470/1944], Loss: 0.0271\n",
      "Epoch [7/15], Batch [1480/1944], Loss: 0.0232\n",
      "Epoch [7/15], Batch [1490/1944], Loss: 0.0223\n",
      "Epoch [7/15], Batch [1500/1944], Loss: 0.0117\n",
      "Epoch [7/15], Batch [1510/1944], Loss: 0.0172\n",
      "Epoch [7/15], Batch [1520/1944], Loss: 0.0252\n",
      "Epoch [7/15], Batch [1530/1944], Loss: 0.0188\n",
      "Epoch [7/15], Batch [1540/1944], Loss: 0.0213\n",
      "Epoch [7/15], Batch [1550/1944], Loss: 0.0225\n",
      "Epoch [7/15], Batch [1560/1944], Loss: 0.0262\n",
      "Epoch [7/15], Batch [1570/1944], Loss: 0.0273\n",
      "Epoch [7/15], Batch [1580/1944], Loss: 0.0208\n",
      "Epoch [7/15], Batch [1590/1944], Loss: 0.0154\n",
      "Epoch [7/15], Batch [1600/1944], Loss: 0.0200\n",
      "Epoch [7/15], Batch [1610/1944], Loss: 0.0246\n",
      "Epoch [7/15], Batch [1620/1944], Loss: 0.0240\n",
      "Epoch [7/15], Batch [1630/1944], Loss: 0.0226\n",
      "Epoch [7/15], Batch [1640/1944], Loss: 0.0192\n",
      "Epoch [7/15], Batch [1650/1944], Loss: 0.0162\n",
      "Epoch [7/15], Batch [1660/1944], Loss: 0.0165\n",
      "Epoch [7/15], Batch [1670/1944], Loss: 0.0204\n",
      "Epoch [7/15], Batch [1680/1944], Loss: 0.0261\n",
      "Epoch [7/15], Batch [1690/1944], Loss: 0.0286\n",
      "Epoch [7/15], Batch [1700/1944], Loss: 0.0257\n",
      "Epoch [7/15], Batch [1710/1944], Loss: 0.0214\n",
      "Epoch [7/15], Batch [1720/1944], Loss: 0.0170\n",
      "Epoch [7/15], Batch [1730/1944], Loss: 0.0542\n",
      "Epoch [7/15], Batch [1740/1944], Loss: 0.0203\n",
      "Epoch [7/15], Batch [1750/1944], Loss: 0.0235\n",
      "Epoch [7/15], Batch [1760/1944], Loss: 0.0247\n",
      "Epoch [7/15], Batch [1770/1944], Loss: 0.0266\n",
      "Epoch [7/15], Batch [1780/1944], Loss: 0.0275\n",
      "Epoch [7/15], Batch [1790/1944], Loss: 0.0260\n",
      "Epoch [7/15], Batch [1800/1944], Loss: 0.0174\n",
      "Epoch [7/15], Batch [1810/1944], Loss: 0.0169\n",
      "Epoch [7/15], Batch [1820/1944], Loss: 0.0250\n",
      "Epoch [7/15], Batch [1830/1944], Loss: 0.0193\n",
      "Epoch [7/15], Batch [1840/1944], Loss: 0.0257\n",
      "Epoch [7/15], Batch [1850/1944], Loss: 0.0191\n",
      "Epoch [7/15], Batch [1860/1944], Loss: 0.0210\n",
      "Epoch [7/15], Batch [1870/1944], Loss: 0.0157\n",
      "Epoch [7/15], Batch [1880/1944], Loss: 0.0175\n",
      "Epoch [7/15], Batch [1890/1944], Loss: 0.0237\n",
      "Epoch [7/15], Batch [1900/1944], Loss: 0.0295\n",
      "Epoch [7/15], Batch [1910/1944], Loss: 0.0273\n",
      "Epoch [7/15], Batch [1920/1944], Loss: 0.0283\n",
      "Epoch [7/15], Batch [1930/1944], Loss: 0.0186\n",
      "Epoch [7/15], Batch [1940/1944], Loss: 0.0210\n",
      "Epoch [7/15], Average Loss: 0.0231\n",
      "Epoch [7/15], Validation Loss: 0.0891\n",
      "Epoch [7/15], Current Learning Rate: 0.0005\n",
      "Epoch [8/15], Batch [10/1944], Loss: 0.0203\n",
      "Epoch [8/15], Batch [20/1944], Loss: 0.0215\n",
      "Epoch [8/15], Batch [30/1944], Loss: 0.0220\n",
      "Epoch [8/15], Batch [40/1944], Loss: 0.0225\n",
      "Epoch [8/15], Batch [50/1944], Loss: 0.0262\n",
      "Epoch [8/15], Batch [60/1944], Loss: 0.0275\n",
      "Epoch [8/15], Batch [70/1944], Loss: 0.0183\n",
      "Epoch [8/15], Batch [80/1944], Loss: 0.0139\n",
      "Epoch [8/15], Batch [90/1944], Loss: 0.0227\n",
      "Epoch [8/15], Batch [100/1944], Loss: 0.0212\n",
      "Epoch [8/15], Batch [110/1944], Loss: 0.0244\n",
      "Epoch [8/15], Batch [120/1944], Loss: 0.0206\n",
      "Epoch [8/15], Batch [130/1944], Loss: 0.0209\n",
      "Epoch [8/15], Batch [140/1944], Loss: 0.0194\n",
      "Epoch [8/15], Batch [150/1944], Loss: 0.0183\n",
      "Epoch [8/15], Batch [160/1944], Loss: 0.0227\n",
      "Epoch [8/15], Batch [170/1944], Loss: 0.0279\n",
      "Epoch [8/15], Batch [180/1944], Loss: 0.0281\n",
      "Epoch [8/15], Batch [190/1944], Loss: 0.0285\n",
      "Epoch [8/15], Batch [200/1944], Loss: 0.0213\n",
      "Epoch [8/15], Batch [210/1944], Loss: 0.0181\n",
      "Epoch [8/15], Batch [220/1944], Loss: 0.0570\n",
      "Epoch [8/15], Batch [230/1944], Loss: 0.0250\n",
      "Epoch [8/15], Batch [240/1944], Loss: 0.0250\n",
      "Epoch [8/15], Batch [250/1944], Loss: 0.0245\n",
      "Epoch [8/15], Batch [260/1944], Loss: 0.0272\n",
      "Epoch [8/15], Batch [270/1944], Loss: 0.0302\n",
      "Epoch [8/15], Batch [280/1944], Loss: 0.0247\n",
      "Epoch [8/15], Batch [290/1944], Loss: 0.0157\n",
      "Epoch [8/15], Batch [300/1944], Loss: 0.0162\n",
      "Epoch [8/15], Batch [310/1944], Loss: 0.0248\n",
      "Epoch [8/15], Batch [320/1944], Loss: 0.0198\n",
      "Epoch [8/15], Batch [330/1944], Loss: 0.0242\n",
      "Epoch [8/15], Batch [340/1944], Loss: 0.0175\n",
      "Epoch [8/15], Batch [350/1944], Loss: 0.0183\n",
      "Epoch [8/15], Batch [360/1944], Loss: 0.0175\n",
      "Epoch [8/15], Batch [370/1944], Loss: 0.0181\n",
      "Epoch [8/15], Batch [380/1944], Loss: 0.0252\n",
      "Epoch [8/15], Batch [390/1944], Loss: 0.0284\n",
      "Epoch [8/15], Batch [400/1944], Loss: 0.0252\n",
      "Epoch [8/15], Batch [410/1944], Loss: 0.0242\n",
      "Epoch [8/15], Batch [420/1944], Loss: 0.0132\n",
      "Epoch [8/15], Batch [430/1944], Loss: 0.0185\n",
      "Epoch [8/15], Batch [440/1944], Loss: 0.0309\n",
      "Epoch [8/15], Batch [450/1944], Loss: 0.0228\n",
      "Epoch [8/15], Batch [460/1944], Loss: 0.0239\n",
      "Epoch [8/15], Batch [470/1944], Loss: 0.0244\n",
      "Epoch [8/15], Batch [480/1944], Loss: 0.0275\n",
      "Epoch [8/15], Batch [490/1944], Loss: 0.0283\n",
      "Epoch [8/15], Batch [500/1944], Loss: 0.0215\n",
      "Epoch [8/15], Batch [510/1944], Loss: 0.0156\n",
      "Epoch [8/15], Batch [520/1944], Loss: 0.0190\n",
      "Epoch [8/15], Batch [530/1944], Loss: 0.0231\n",
      "Epoch [8/15], Batch [540/1944], Loss: 0.0236\n",
      "Epoch [8/15], Batch [550/1944], Loss: 0.0227\n",
      "Epoch [8/15], Batch [560/1944], Loss: 0.0188\n",
      "Epoch [8/15], Batch [570/1944], Loss: 0.0157\n",
      "Epoch [8/15], Batch [580/1944], Loss: 0.0165\n",
      "Epoch [8/15], Batch [590/1944], Loss: 0.0206\n",
      "Epoch [8/15], Batch [600/1944], Loss: 0.0262\n",
      "Epoch [8/15], Batch [610/1944], Loss: 0.0286\n",
      "Epoch [8/15], Batch [620/1944], Loss: 0.0265\n",
      "Epoch [8/15], Batch [630/1944], Loss: 0.0225\n",
      "Epoch [8/15], Batch [640/1944], Loss: 0.0181\n",
      "Epoch [8/15], Batch [650/1944], Loss: 0.0559\n",
      "Epoch [8/15], Batch [660/1944], Loss: 0.0217\n",
      "Epoch [8/15], Batch [670/1944], Loss: 0.0248\n",
      "Epoch [8/15], Batch [680/1944], Loss: 0.0258\n",
      "Epoch [8/15], Batch [690/1944], Loss: 0.0273\n",
      "Epoch [8/15], Batch [700/1944], Loss: 0.0283\n",
      "Epoch [8/15], Batch [710/1944], Loss: 0.0265\n",
      "Epoch [8/15], Batch [720/1944], Loss: 0.0178\n",
      "Epoch [8/15], Batch [730/1944], Loss: 0.0168\n",
      "Epoch [8/15], Batch [740/1944], Loss: 0.0238\n",
      "Epoch [8/15], Batch [750/1944], Loss: 0.0189\n",
      "Epoch [8/15], Batch [760/1944], Loss: 0.0254\n",
      "Epoch [8/15], Batch [770/1944], Loss: 0.0186\n",
      "Epoch [8/15], Batch [780/1944], Loss: 0.0201\n",
      "Epoch [8/15], Batch [790/1944], Loss: 0.0153\n",
      "Epoch [8/15], Batch [800/1944], Loss: 0.0171\n",
      "Epoch [8/15], Batch [810/1944], Loss: 0.0234\n",
      "Epoch [8/15], Batch [820/1944], Loss: 0.0291\n",
      "Epoch [8/15], Batch [830/1944], Loss: 0.0272\n",
      "Epoch [8/15], Batch [840/1944], Loss: 0.0288\n",
      "Epoch [8/15], Batch [850/1944], Loss: 0.0194\n",
      "Epoch [8/15], Batch [860/1944], Loss: 0.0223\n",
      "Epoch [8/15], Batch [870/1944], Loss: 0.0393\n",
      "Epoch [8/15], Batch [880/1944], Loss: 0.0207\n",
      "Epoch [8/15], Batch [890/1944], Loss: 0.0227\n",
      "Epoch [8/15], Batch [900/1944], Loss: 0.0244\n",
      "Epoch [8/15], Batch [910/1944], Loss: 0.0285\n",
      "Epoch [8/15], Batch [920/1944], Loss: 0.0311\n",
      "Epoch [8/15], Batch [930/1944], Loss: 0.0239\n",
      "Epoch [8/15], Batch [940/1944], Loss: 0.0161\n",
      "Epoch [8/15], Batch [950/1944], Loss: 0.0207\n",
      "Epoch [8/15], Batch [960/1944], Loss: 0.0234\n",
      "Epoch [8/15], Batch [970/1944], Loss: 0.0211\n",
      "Epoch [8/15], Batch [980/1944], Loss: 0.0214\n",
      "Epoch [8/15], Batch [990/1944], Loss: 0.0181\n",
      "Epoch [8/15], Batch [1000/1944], Loss: 0.0171\n",
      "Epoch [8/15], Batch [1010/1944], Loss: 0.0159\n",
      "Epoch [8/15], Batch [1020/1944], Loss: 0.0167\n",
      "Epoch [8/15], Batch [1030/1944], Loss: 0.0267\n",
      "Epoch [8/15], Batch [1040/1944], Loss: 0.0298\n",
      "Epoch [8/15], Batch [1050/1944], Loss: 0.0278\n",
      "Epoch [8/15], Batch [1060/1944], Loss: 0.0242\n",
      "Epoch [8/15], Batch [1070/1944], Loss: 0.0149\n",
      "Epoch [8/15], Batch [1080/1944], Loss: 0.0143\n",
      "Epoch [8/15], Batch [1090/1944], Loss: 0.0210\n",
      "Epoch [8/15], Batch [1100/1944], Loss: 0.0229\n",
      "Epoch [8/15], Batch [1110/1944], Loss: 0.0240\n",
      "Epoch [8/15], Batch [1120/1944], Loss: 0.0233\n",
      "Epoch [8/15], Batch [1130/1944], Loss: 0.0265\n",
      "Epoch [8/15], Batch [1140/1944], Loss: 0.0278\n",
      "Epoch [8/15], Batch [1150/1944], Loss: 0.0202\n",
      "Epoch [8/15], Batch [1160/1944], Loss: 0.0156\n",
      "Epoch [8/15], Batch [1170/1944], Loss: 0.0237\n",
      "Epoch [8/15], Batch [1180/1944], Loss: 0.0215\n",
      "Epoch [8/15], Batch [1190/1944], Loss: 0.0247\n",
      "Epoch [8/15], Batch [1200/1944], Loss: 0.0197\n",
      "Epoch [8/15], Batch [1210/1944], Loss: 0.0192\n",
      "Epoch [8/15], Batch [1220/1944], Loss: 0.0177\n",
      "Epoch [8/15], Batch [1230/1944], Loss: 0.0172\n",
      "Epoch [8/15], Batch [1240/1944], Loss: 0.0219\n",
      "Epoch [8/15], Batch [1250/1944], Loss: 0.0272\n",
      "Epoch [8/15], Batch [1260/1944], Loss: 0.0282\n",
      "Epoch [8/15], Batch [1270/1944], Loss: 0.0286\n",
      "Epoch [8/15], Batch [1280/1944], Loss: 0.0219\n",
      "Epoch [8/15], Batch [1290/1944], Loss: 0.0193\n",
      "Epoch [8/15], Batch [1300/1944], Loss: 0.0495\n",
      "Epoch [8/15], Batch [1310/1944], Loss: 0.0203\n",
      "Epoch [8/15], Batch [1320/1944], Loss: 0.0210\n",
      "Epoch [8/15], Batch [1330/1944], Loss: 0.0210\n",
      "Epoch [8/15], Batch [1340/1944], Loss: 0.0248\n",
      "Epoch [8/15], Batch [1350/1944], Loss: 0.0281\n",
      "Epoch [8/15], Batch [1360/1944], Loss: 0.0230\n",
      "Epoch [8/15], Batch [1370/1944], Loss: 0.0151\n",
      "Epoch [8/15], Batch [1380/1944], Loss: 0.0163\n",
      "Epoch [8/15], Batch [1390/1944], Loss: 0.0253\n",
      "Epoch [8/15], Batch [1400/1944], Loss: 0.0196\n",
      "Epoch [8/15], Batch [1410/1944], Loss: 0.0229\n",
      "Epoch [8/15], Batch [1420/1944], Loss: 0.0166\n",
      "Epoch [8/15], Batch [1430/1944], Loss: 0.0179\n",
      "Epoch [8/15], Batch [1440/1944], Loss: 0.0166\n",
      "Epoch [8/15], Batch [1450/1944], Loss: 0.0177\n",
      "Epoch [8/15], Batch [1460/1944], Loss: 0.0252\n",
      "Epoch [8/15], Batch [1470/1944], Loss: 0.0287\n",
      "Epoch [8/15], Batch [1480/1944], Loss: 0.0257\n",
      "Epoch [8/15], Batch [1490/1944], Loss: 0.0251\n",
      "Epoch [8/15], Batch [1500/1944], Loss: 0.0140\n",
      "Epoch [8/15], Batch [1510/1944], Loss: 0.0193\n",
      "Epoch [8/15], Batch [1520/1944], Loss: 0.0290\n",
      "Epoch [8/15], Batch [1530/1944], Loss: 0.0217\n",
      "Epoch [8/15], Batch [1540/1944], Loss: 0.0235\n",
      "Epoch [8/15], Batch [1550/1944], Loss: 0.0238\n",
      "Epoch [8/15], Batch [1560/1944], Loss: 0.0271\n",
      "Epoch [8/15], Batch [1570/1944], Loss: 0.0279\n",
      "Epoch [8/15], Batch [1580/1944], Loss: 0.0214\n",
      "Epoch [8/15], Batch [1590/1944], Loss: 0.0160\n",
      "Epoch [8/15], Batch [1600/1944], Loss: 0.0202\n",
      "Epoch [8/15], Batch [1610/1944], Loss: 0.0245\n",
      "Epoch [8/15], Batch [1620/1944], Loss: 0.0240\n",
      "Epoch [8/15], Batch [1630/1944], Loss: 0.0226\n",
      "Epoch [8/15], Batch [1640/1944], Loss: 0.0192\n",
      "Epoch [8/15], Batch [1650/1944], Loss: 0.0162\n",
      "Epoch [8/15], Batch [1660/1944], Loss: 0.0167\n",
      "Epoch [8/15], Batch [1670/1944], Loss: 0.0205\n",
      "Epoch [8/15], Batch [1680/1944], Loss: 0.0260\n",
      "Epoch [8/15], Batch [1690/1944], Loss: 0.0286\n",
      "Epoch [8/15], Batch [1700/1944], Loss: 0.0257\n",
      "Epoch [8/15], Batch [1710/1944], Loss: 0.0214\n",
      "Epoch [8/15], Batch [1720/1944], Loss: 0.0171\n",
      "Epoch [8/15], Batch [1730/1944], Loss: 0.0541\n",
      "Epoch [8/15], Batch [1740/1944], Loss: 0.0204\n",
      "Epoch [8/15], Batch [1750/1944], Loss: 0.0235\n",
      "Epoch [8/15], Batch [1760/1944], Loss: 0.0247\n",
      "Epoch [8/15], Batch [1770/1944], Loss: 0.0266\n",
      "Epoch [8/15], Batch [1780/1944], Loss: 0.0275\n",
      "Epoch [8/15], Batch [1790/1944], Loss: 0.0261\n",
      "Epoch [8/15], Batch [1800/1944], Loss: 0.0177\n",
      "Epoch [8/15], Batch [1810/1944], Loss: 0.0172\n",
      "Epoch [8/15], Batch [1820/1944], Loss: 0.0254\n",
      "Epoch [8/15], Batch [1830/1944], Loss: 0.0198\n",
      "Epoch [8/15], Batch [1840/1944], Loss: 0.0260\n",
      "Epoch [8/15], Batch [1850/1944], Loss: 0.0194\n",
      "Epoch [8/15], Batch [1860/1944], Loss: 0.0212\n",
      "Epoch [8/15], Batch [1870/1944], Loss: 0.0159\n",
      "Epoch [8/15], Batch [1880/1944], Loss: 0.0176\n",
      "Epoch [8/15], Batch [1890/1944], Loss: 0.0239\n",
      "Epoch [8/15], Batch [1900/1944], Loss: 0.0296\n",
      "Epoch [8/15], Batch [1910/1944], Loss: 0.0275\n",
      "Epoch [8/15], Batch [1920/1944], Loss: 0.0286\n",
      "Epoch [8/15], Batch [1930/1944], Loss: 0.0189\n",
      "Epoch [8/15], Batch [1940/1944], Loss: 0.0213\n",
      "Epoch [8/15], Average Loss: 0.0231\n",
      "Epoch [8/15], Validation Loss: 0.0899\n",
      "Epoch [8/15], Current Learning Rate: 0.0005\n",
      "Epoch [9/15], Batch [10/1944], Loss: 0.0216\n",
      "Epoch [9/15], Batch [20/1944], Loss: 0.0229\n",
      "Epoch [9/15], Batch [30/1944], Loss: 0.0232\n",
      "Epoch [9/15], Batch [40/1944], Loss: 0.0232\n",
      "Epoch [9/15], Batch [50/1944], Loss: 0.0268\n",
      "Epoch [9/15], Batch [60/1944], Loss: 0.0276\n",
      "Epoch [9/15], Batch [70/1944], Loss: 0.0185\n",
      "Epoch [9/15], Batch [80/1944], Loss: 0.0141\n",
      "Epoch [9/15], Batch [90/1944], Loss: 0.0228\n",
      "Epoch [9/15], Batch [100/1944], Loss: 0.0212\n",
      "Epoch [9/15], Batch [110/1944], Loss: 0.0244\n",
      "Epoch [9/15], Batch [120/1944], Loss: 0.0207\n",
      "Epoch [9/15], Batch [130/1944], Loss: 0.0210\n",
      "Epoch [9/15], Batch [140/1944], Loss: 0.0193\n",
      "Epoch [9/15], Batch [150/1944], Loss: 0.0184\n",
      "Epoch [9/15], Batch [160/1944], Loss: 0.0228\n",
      "Epoch [9/15], Batch [170/1944], Loss: 0.0280\n",
      "Epoch [9/15], Batch [180/1944], Loss: 0.0283\n",
      "Epoch [9/15], Batch [190/1944], Loss: 0.0288\n",
      "Epoch [9/15], Batch [200/1944], Loss: 0.0217\n",
      "Epoch [9/15], Batch [210/1944], Loss: 0.0185\n",
      "Epoch [9/15], Batch [220/1944], Loss: 0.0533\n",
      "Epoch [9/15], Batch [230/1944], Loss: 0.0252\n",
      "Epoch [9/15], Batch [240/1944], Loss: 0.0259\n",
      "Epoch [9/15], Batch [250/1944], Loss: 0.0255\n",
      "Epoch [9/15], Batch [260/1944], Loss: 0.0281\n",
      "Epoch [9/15], Batch [270/1944], Loss: 0.0306\n",
      "Epoch [9/15], Batch [280/1944], Loss: 0.0250\n",
      "Epoch [9/15], Batch [290/1944], Loss: 0.0159\n",
      "Epoch [9/15], Batch [300/1944], Loss: 0.0164\n",
      "Epoch [9/15], Batch [310/1944], Loss: 0.0248\n",
      "Epoch [9/15], Batch [320/1944], Loss: 0.0199\n",
      "Epoch [9/15], Batch [330/1944], Loss: 0.0240\n",
      "Epoch [9/15], Batch [340/1944], Loss: 0.0176\n",
      "Epoch [9/15], Batch [350/1944], Loss: 0.0184\n",
      "Epoch [9/15], Batch [360/1944], Loss: 0.0176\n",
      "Epoch [9/15], Batch [370/1944], Loss: 0.0182\n",
      "Epoch [9/15], Batch [380/1944], Loss: 0.0251\n",
      "Epoch [9/15], Batch [390/1944], Loss: 0.0284\n",
      "Epoch [9/15], Batch [400/1944], Loss: 0.0252\n",
      "Epoch [9/15], Batch [410/1944], Loss: 0.0238\n",
      "Epoch [9/15], Batch [420/1944], Loss: 0.0129\n",
      "Epoch [9/15], Batch [430/1944], Loss: 0.0180\n",
      "Epoch [9/15], Batch [440/1944], Loss: 0.0314\n",
      "Epoch [9/15], Batch [450/1944], Loss: 0.0224\n",
      "Epoch [9/15], Batch [460/1944], Loss: 0.0234\n",
      "Epoch [9/15], Batch [470/1944], Loss: 0.0242\n",
      "Epoch [9/15], Batch [480/1944], Loss: 0.0275\n",
      "Epoch [9/15], Batch [490/1944], Loss: 0.0285\n",
      "Epoch [9/15], Batch [500/1944], Loss: 0.0217\n",
      "Epoch [9/15], Batch [510/1944], Loss: 0.0158\n",
      "Epoch [9/15], Batch [520/1944], Loss: 0.0192\n",
      "Epoch [9/15], Batch [530/1944], Loss: 0.0233\n",
      "Epoch [9/15], Batch [540/1944], Loss: 0.0234\n",
      "Epoch [9/15], Batch [550/1944], Loss: 0.0223\n",
      "Epoch [9/15], Batch [560/1944], Loss: 0.0184\n",
      "Epoch [9/15], Batch [570/1944], Loss: 0.0151\n",
      "Epoch [9/15], Batch [580/1944], Loss: 0.0157\n",
      "Epoch [9/15], Batch [590/1944], Loss: 0.0194\n",
      "Epoch [9/15], Batch [600/1944], Loss: 0.0248\n",
      "Epoch [9/15], Batch [610/1944], Loss: 0.0269\n",
      "Epoch [9/15], Batch [620/1944], Loss: 0.0242\n",
      "Epoch [9/15], Batch [630/1944], Loss: 0.0192\n",
      "Epoch [9/15], Batch [640/1944], Loss: 0.0148\n",
      "Epoch [9/15], Batch [650/1944], Loss: 0.0585\n",
      "Epoch [9/15], Batch [660/1944], Loss: 0.0204\n",
      "Epoch [9/15], Batch [670/1944], Loss: 0.0228\n",
      "Epoch [9/15], Batch [680/1944], Loss: 0.0240\n",
      "Epoch [9/15], Batch [690/1944], Loss: 0.0263\n",
      "Epoch [9/15], Batch [700/1944], Loss: 0.0272\n",
      "Epoch [9/15], Batch [710/1944], Loss: 0.0252\n",
      "Epoch [9/15], Batch [720/1944], Loss: 0.0163\n",
      "Epoch [9/15], Batch [730/1944], Loss: 0.0153\n",
      "Epoch [9/15], Batch [740/1944], Loss: 0.0225\n",
      "Epoch [9/15], Batch [750/1944], Loss: 0.0177\n",
      "Epoch [9/15], Batch [760/1944], Loss: 0.0246\n",
      "Epoch [9/15], Batch [770/1944], Loss: 0.0179\n",
      "Epoch [9/15], Batch [780/1944], Loss: 0.0195\n",
      "Epoch [9/15], Batch [790/1944], Loss: 0.0148\n",
      "Epoch [9/15], Batch [800/1944], Loss: 0.0168\n",
      "Epoch [9/15], Batch [810/1944], Loss: 0.0231\n",
      "Epoch [9/15], Batch [820/1944], Loss: 0.0289\n",
      "Epoch [9/15], Batch [830/1944], Loss: 0.0270\n",
      "Epoch [9/15], Batch [840/1944], Loss: 0.0287\n",
      "Epoch [9/15], Batch [850/1944], Loss: 0.0193\n",
      "Epoch [9/15], Batch [860/1944], Loss: 0.0220\n",
      "Epoch [9/15], Batch [870/1944], Loss: 0.0394\n",
      "Epoch [9/15], Batch [880/1944], Loss: 0.0211\n",
      "Epoch [9/15], Batch [890/1944], Loss: 0.0233\n",
      "Epoch [9/15], Batch [900/1944], Loss: 0.0249\n",
      "Epoch [9/15], Batch [910/1944], Loss: 0.0289\n",
      "Epoch [9/15], Batch [920/1944], Loss: 0.0317\n",
      "Epoch [9/15], Batch [930/1944], Loss: 0.0245\n",
      "Epoch [9/15], Batch [940/1944], Loss: 0.0170\n",
      "Epoch [9/15], Batch [950/1944], Loss: 0.0218\n",
      "Epoch [9/15], Batch [960/1944], Loss: 0.0246\n",
      "Epoch [9/15], Batch [970/1944], Loss: 0.0224\n",
      "Epoch [9/15], Batch [980/1944], Loss: 0.0228\n",
      "Epoch [9/15], Batch [990/1944], Loss: 0.0197\n",
      "Epoch [9/15], Batch [1000/1944], Loss: 0.0188\n",
      "Epoch [9/15], Batch [1010/1944], Loss: 0.0175\n",
      "Epoch [9/15], Batch [1020/1944], Loss: 0.0181\n",
      "Epoch [9/15], Batch [1030/1944], Loss: 0.0282\n",
      "Epoch [9/15], Batch [1040/1944], Loss: 0.0318\n",
      "Epoch [9/15], Batch [1050/1944], Loss: 0.0297\n",
      "Epoch [9/15], Batch [1060/1944], Loss: 0.0262\n",
      "Epoch [9/15], Batch [1070/1944], Loss: 0.0173\n",
      "Epoch [9/15], Batch [1080/1944], Loss: 0.0157\n",
      "Epoch [9/15], Batch [1090/1944], Loss: 0.0197\n",
      "Epoch [9/15], Batch [1100/1944], Loss: 0.0219\n",
      "Epoch [9/15], Batch [1110/1944], Loss: 0.0232\n",
      "Epoch [9/15], Batch [1120/1944], Loss: 0.0228\n",
      "Epoch [9/15], Batch [1130/1944], Loss: 0.0262\n",
      "Epoch [9/15], Batch [1140/1944], Loss: 0.0276\n",
      "Epoch [9/15], Batch [1150/1944], Loss: 0.0200\n",
      "Epoch [9/15], Batch [1160/1944], Loss: 0.0153\n",
      "Epoch [9/15], Batch [1170/1944], Loss: 0.0240\n",
      "Epoch [9/15], Batch [1180/1944], Loss: 0.0218\n",
      "Epoch [9/15], Batch [1190/1944], Loss: 0.0249\n",
      "Epoch [9/15], Batch [1200/1944], Loss: 0.0200\n",
      "Epoch [9/15], Batch [1210/1944], Loss: 0.0196\n",
      "Epoch [9/15], Batch [1220/1944], Loss: 0.0181\n",
      "Epoch [9/15], Batch [1230/1944], Loss: 0.0177\n",
      "Epoch [9/15], Batch [1240/1944], Loss: 0.0225\n",
      "Epoch [9/15], Batch [1250/1944], Loss: 0.0280\n",
      "Epoch [9/15], Batch [1260/1944], Loss: 0.0291\n",
      "Epoch [9/15], Batch [1270/1944], Loss: 0.0295\n",
      "Epoch [9/15], Batch [1280/1944], Loss: 0.0225\n",
      "Epoch [9/15], Batch [1290/1944], Loss: 0.0199\n",
      "Epoch [9/15], Batch [1300/1944], Loss: 0.0482\n",
      "Epoch [9/15], Batch [1310/1944], Loss: 0.0194\n",
      "Epoch [9/15], Batch [1320/1944], Loss: 0.0204\n",
      "Epoch [9/15], Batch [1330/1944], Loss: 0.0208\n",
      "Epoch [9/15], Batch [1340/1944], Loss: 0.0246\n",
      "Epoch [9/15], Batch [1350/1944], Loss: 0.0279\n",
      "Epoch [9/15], Batch [1360/1944], Loss: 0.0227\n",
      "Epoch [9/15], Batch [1370/1944], Loss: 0.0146\n",
      "Epoch [9/15], Batch [1380/1944], Loss: 0.0160\n",
      "Epoch [9/15], Batch [1390/1944], Loss: 0.0252\n",
      "Epoch [9/15], Batch [1400/1944], Loss: 0.0196\n",
      "Epoch [9/15], Batch [1410/1944], Loss: 0.0229\n",
      "Epoch [9/15], Batch [1420/1944], Loss: 0.0164\n",
      "Epoch [9/15], Batch [1430/1944], Loss: 0.0174\n",
      "Epoch [9/15], Batch [1440/1944], Loss: 0.0150\n",
      "Epoch [9/15], Batch [1450/1944], Loss: 0.0153\n",
      "Epoch [9/15], Batch [1460/1944], Loss: 0.0225\n",
      "Epoch [9/15], Batch [1470/1944], Loss: 0.0266\n",
      "Epoch [9/15], Batch [1480/1944], Loss: 0.0230\n",
      "Epoch [9/15], Batch [1490/1944], Loss: 0.0224\n",
      "Epoch [9/15], Batch [1500/1944], Loss: 0.0116\n",
      "Epoch [9/15], Batch [1510/1944], Loss: 0.0175\n",
      "Epoch [9/15], Batch [1520/1944], Loss: 0.0271\n",
      "Epoch [9/15], Batch [1530/1944], Loss: 0.0200\n",
      "Epoch [9/15], Batch [1540/1944], Loss: 0.0224\n",
      "Epoch [9/15], Batch [1550/1944], Loss: 0.0237\n",
      "Epoch [9/15], Batch [1560/1944], Loss: 0.0275\n",
      "Epoch [9/15], Batch [1570/1944], Loss: 0.0284\n",
      "Epoch [9/15], Batch [1580/1944], Loss: 0.0220\n",
      "Epoch [9/15], Batch [1590/1944], Loss: 0.0166\n",
      "Epoch [9/15], Batch [1600/1944], Loss: 0.0210\n",
      "Epoch [9/15], Batch [1610/1944], Loss: 0.0252\n",
      "Epoch [9/15], Batch [1620/1944], Loss: 0.0250\n",
      "Epoch [9/15], Batch [1630/1944], Loss: 0.0235\n",
      "Epoch [9/15], Batch [1640/1944], Loss: 0.0199\n",
      "Epoch [9/15], Batch [1650/1944], Loss: 0.0169\n",
      "Epoch [9/15], Batch [1660/1944], Loss: 0.0174\n",
      "Epoch [9/15], Batch [1670/1944], Loss: 0.0213\n",
      "Epoch [9/15], Batch [1680/1944], Loss: 0.0269\n",
      "Epoch [9/15], Batch [1690/1944], Loss: 0.0297\n",
      "Epoch [9/15], Batch [1700/1944], Loss: 0.0269\n",
      "Epoch [9/15], Batch [1710/1944], Loss: 0.0228\n",
      "Epoch [9/15], Batch [1720/1944], Loss: 0.0185\n",
      "Epoch [9/15], Batch [1730/1944], Loss: 0.0543\n",
      "Epoch [9/15], Batch [1740/1944], Loss: 0.0198\n",
      "Epoch [9/15], Batch [1750/1944], Loss: 0.0234\n",
      "Epoch [9/15], Batch [1760/1944], Loss: 0.0246\n",
      "Epoch [9/15], Batch [1770/1944], Loss: 0.0266\n",
      "Epoch [9/15], Batch [1780/1944], Loss: 0.0274\n",
      "Epoch [9/15], Batch [1790/1944], Loss: 0.0260\n",
      "Epoch [9/15], Batch [1800/1944], Loss: 0.0173\n",
      "Epoch [9/15], Batch [1810/1944], Loss: 0.0168\n",
      "Epoch [9/15], Batch [1820/1944], Loss: 0.0254\n",
      "Epoch [9/15], Batch [1830/1944], Loss: 0.0197\n",
      "Epoch [9/15], Batch [1840/1944], Loss: 0.0259\n",
      "Epoch [9/15], Batch [1850/1944], Loss: 0.0190\n",
      "Epoch [9/15], Batch [1860/1944], Loss: 0.0208\n",
      "Epoch [9/15], Batch [1870/1944], Loss: 0.0155\n",
      "Epoch [9/15], Batch [1880/1944], Loss: 0.0171\n",
      "Epoch [9/15], Batch [1890/1944], Loss: 0.0234\n",
      "Epoch [9/15], Batch [1900/1944], Loss: 0.0292\n",
      "Epoch [9/15], Batch [1910/1944], Loss: 0.0271\n",
      "Epoch [9/15], Batch [1920/1944], Loss: 0.0283\n",
      "Epoch [9/15], Batch [1930/1944], Loss: 0.0187\n",
      "Epoch [9/15], Batch [1940/1944], Loss: 0.0213\n",
      "Epoch [9/15], Average Loss: 0.0230\n",
      "Epoch [9/15], Validation Loss: 0.0907\n",
      "Epoch [9/15], Current Learning Rate: 0.0005\n",
      "Epoch [10/15], Batch [10/1944], Loss: 0.0222\n",
      "Epoch [10/15], Batch [20/1944], Loss: 0.0229\n",
      "Epoch [10/15], Batch [30/1944], Loss: 0.0241\n",
      "Epoch [10/15], Batch [40/1944], Loss: 0.0241\n",
      "Epoch [10/15], Batch [50/1944], Loss: 0.0273\n",
      "Epoch [10/15], Batch [60/1944], Loss: 0.0283\n",
      "Epoch [10/15], Batch [70/1944], Loss: 0.0192\n",
      "Epoch [10/15], Batch [80/1944], Loss: 0.0142\n",
      "Epoch [10/15], Batch [90/1944], Loss: 0.0230\n",
      "Epoch [10/15], Batch [100/1944], Loss: 0.0212\n",
      "Epoch [10/15], Batch [110/1944], Loss: 0.0243\n",
      "Epoch [10/15], Batch [120/1944], Loss: 0.0207\n",
      "Epoch [10/15], Batch [130/1944], Loss: 0.0210\n",
      "Epoch [10/15], Batch [140/1944], Loss: 0.0192\n",
      "Epoch [10/15], Batch [150/1944], Loss: 0.0183\n",
      "Epoch [10/15], Batch [160/1944], Loss: 0.0227\n",
      "Epoch [10/15], Batch [170/1944], Loss: 0.0281\n",
      "Epoch [10/15], Batch [180/1944], Loss: 0.0283\n",
      "Epoch [10/15], Batch [190/1944], Loss: 0.0287\n",
      "Epoch [10/15], Batch [200/1944], Loss: 0.0215\n",
      "Epoch [10/15], Batch [210/1944], Loss: 0.0183\n",
      "Epoch [10/15], Batch [220/1944], Loss: 0.0543\n",
      "Epoch [10/15], Batch [230/1944], Loss: 0.0242\n",
      "Epoch [10/15], Batch [240/1944], Loss: 0.0252\n",
      "Epoch [10/15], Batch [250/1944], Loss: 0.0236\n",
      "Epoch [10/15], Batch [260/1944], Loss: 0.0264\n",
      "Epoch [10/15], Batch [270/1944], Loss: 0.0294\n",
      "Epoch [10/15], Batch [280/1944], Loss: 0.0240\n",
      "Epoch [10/15], Batch [290/1944], Loss: 0.0152\n",
      "Epoch [10/15], Batch [300/1944], Loss: 0.0158\n",
      "Epoch [10/15], Batch [310/1944], Loss: 0.0249\n",
      "Epoch [10/15], Batch [320/1944], Loss: 0.0196\n",
      "Epoch [10/15], Batch [330/1944], Loss: 0.0239\n",
      "Epoch [10/15], Batch [340/1944], Loss: 0.0173\n",
      "Epoch [10/15], Batch [350/1944], Loss: 0.0182\n",
      "Epoch [10/15], Batch [360/1944], Loss: 0.0172\n",
      "Epoch [10/15], Batch [370/1944], Loss: 0.0178\n",
      "Epoch [10/15], Batch [380/1944], Loss: 0.0253\n",
      "Epoch [10/15], Batch [390/1944], Loss: 0.0287\n",
      "Epoch [10/15], Batch [400/1944], Loss: 0.0255\n",
      "Epoch [10/15], Batch [410/1944], Loss: 0.0243\n",
      "Epoch [10/15], Batch [420/1944], Loss: 0.0132\n",
      "Epoch [10/15], Batch [430/1944], Loss: 0.0186\n",
      "Epoch [10/15], Batch [440/1944], Loss: 0.0305\n",
      "Epoch [10/15], Batch [450/1944], Loss: 0.0215\n",
      "Epoch [10/15], Batch [460/1944], Loss: 0.0228\n",
      "Epoch [10/15], Batch [470/1944], Loss: 0.0237\n",
      "Epoch [10/15], Batch [480/1944], Loss: 0.0270\n",
      "Epoch [10/15], Batch [490/1944], Loss: 0.0279\n",
      "Epoch [10/15], Batch [500/1944], Loss: 0.0210\n",
      "Epoch [10/15], Batch [510/1944], Loss: 0.0150\n",
      "Epoch [10/15], Batch [520/1944], Loss: 0.0182\n",
      "Epoch [10/15], Batch [530/1944], Loss: 0.0223\n",
      "Epoch [10/15], Batch [540/1944], Loss: 0.0223\n",
      "Epoch [10/15], Batch [550/1944], Loss: 0.0217\n",
      "Epoch [10/15], Batch [560/1944], Loss: 0.0182\n",
      "Epoch [10/15], Batch [570/1944], Loss: 0.0151\n",
      "Epoch [10/15], Batch [580/1944], Loss: 0.0155\n",
      "Epoch [10/15], Batch [590/1944], Loss: 0.0191\n",
      "Epoch [10/15], Batch [600/1944], Loss: 0.0241\n",
      "Epoch [10/15], Batch [610/1944], Loss: 0.0259\n",
      "Epoch [10/15], Batch [620/1944], Loss: 0.0234\n",
      "Epoch [10/15], Batch [630/1944], Loss: 0.0185\n",
      "Epoch [10/15], Batch [640/1944], Loss: 0.0142\n",
      "Epoch [10/15], Batch [650/1944], Loss: 0.0551\n",
      "Epoch [10/15], Batch [660/1944], Loss: 0.0188\n",
      "Epoch [10/15], Batch [670/1944], Loss: 0.0222\n",
      "Epoch [10/15], Batch [680/1944], Loss: 0.0238\n",
      "Epoch [10/15], Batch [690/1944], Loss: 0.0262\n",
      "Epoch [10/15], Batch [700/1944], Loss: 0.0271\n",
      "Epoch [10/15], Batch [710/1944], Loss: 0.0253\n",
      "Epoch [10/15], Batch [720/1944], Loss: 0.0167\n",
      "Epoch [10/15], Batch [730/1944], Loss: 0.0157\n",
      "Epoch [10/15], Batch [740/1944], Loss: 0.0230\n",
      "Epoch [10/15], Batch [750/1944], Loss: 0.0180\n",
      "Epoch [10/15], Batch [760/1944], Loss: 0.0247\n",
      "Epoch [10/15], Batch [770/1944], Loss: 0.0179\n",
      "Epoch [10/15], Batch [780/1944], Loss: 0.0196\n",
      "Epoch [10/15], Batch [790/1944], Loss: 0.0148\n",
      "Epoch [10/15], Batch [800/1944], Loss: 0.0168\n",
      "Epoch [10/15], Batch [810/1944], Loss: 0.0232\n",
      "Epoch [10/15], Batch [820/1944], Loss: 0.0290\n",
      "Epoch [10/15], Batch [830/1944], Loss: 0.0270\n",
      "Epoch [10/15], Batch [840/1944], Loss: 0.0287\n",
      "Epoch [10/15], Batch [850/1944], Loss: 0.0193\n",
      "Epoch [10/15], Batch [860/1944], Loss: 0.0220\n",
      "Epoch [10/15], Batch [870/1944], Loss: 0.0396\n",
      "Epoch [10/15], Batch [880/1944], Loss: 0.0208\n",
      "Epoch [10/15], Batch [890/1944], Loss: 0.0229\n",
      "Epoch [10/15], Batch [900/1944], Loss: 0.0246\n",
      "Epoch [10/15], Batch [910/1944], Loss: 0.0289\n",
      "Epoch [10/15], Batch [920/1944], Loss: 0.0315\n",
      "Epoch [10/15], Batch [930/1944], Loss: 0.0239\n",
      "Epoch [10/15], Batch [940/1944], Loss: 0.0160\n",
      "Epoch [10/15], Batch [950/1944], Loss: 0.0205\n",
      "Epoch [10/15], Batch [960/1944], Loss: 0.0234\n",
      "Epoch [10/15], Batch [970/1944], Loss: 0.0211\n",
      "Epoch [10/15], Batch [980/1944], Loss: 0.0216\n",
      "Epoch [10/15], Batch [990/1944], Loss: 0.0183\n",
      "Epoch [10/15], Batch [1000/1944], Loss: 0.0173\n",
      "Epoch [10/15], Batch [1010/1944], Loss: 0.0161\n",
      "Epoch [10/15], Batch [1020/1944], Loss: 0.0167\n",
      "Epoch [10/15], Batch [1030/1944], Loss: 0.0271\n",
      "Epoch [10/15], Batch [1040/1944], Loss: 0.0305\n",
      "Epoch [10/15], Batch [1050/1944], Loss: 0.0286\n",
      "Epoch [10/15], Batch [1060/1944], Loss: 0.0251\n",
      "Epoch [10/15], Batch [1070/1944], Loss: 0.0160\n",
      "Epoch [10/15], Batch [1080/1944], Loss: 0.0148\n",
      "Epoch [10/15], Batch [1090/1944], Loss: 0.0201\n",
      "Epoch [10/15], Batch [1100/1944], Loss: 0.0223\n",
      "Epoch [10/15], Batch [1110/1944], Loss: 0.0236\n",
      "Epoch [10/15], Batch [1120/1944], Loss: 0.0230\n",
      "Epoch [10/15], Batch [1130/1944], Loss: 0.0264\n",
      "Epoch [10/15], Batch [1140/1944], Loss: 0.0278\n",
      "Epoch [10/15], Batch [1150/1944], Loss: 0.0202\n",
      "Epoch [10/15], Batch [1160/1944], Loss: 0.0155\n",
      "Epoch [10/15], Batch [1170/1944], Loss: 0.0239\n",
      "Epoch [10/15], Batch [1180/1944], Loss: 0.0217\n",
      "Epoch [10/15], Batch [1190/1944], Loss: 0.0250\n",
      "Epoch [10/15], Batch [1200/1944], Loss: 0.0199\n",
      "Epoch [10/15], Batch [1210/1944], Loss: 0.0194\n",
      "Epoch [10/15], Batch [1220/1944], Loss: 0.0180\n",
      "Epoch [10/15], Batch [1230/1944], Loss: 0.0175\n",
      "Epoch [10/15], Batch [1240/1944], Loss: 0.0222\n",
      "Epoch [10/15], Batch [1250/1944], Loss: 0.0276\n",
      "Epoch [10/15], Batch [1260/1944], Loss: 0.0286\n",
      "Epoch [10/15], Batch [1270/1944], Loss: 0.0288\n",
      "Epoch [10/15], Batch [1280/1944], Loss: 0.0218\n",
      "Epoch [10/15], Batch [1290/1944], Loss: 0.0193\n",
      "Epoch [10/15], Batch [1300/1944], Loss: 0.0511\n",
      "Epoch [10/15], Batch [1310/1944], Loss: 0.0232\n",
      "Epoch [10/15], Batch [1320/1944], Loss: 0.0243\n",
      "Epoch [10/15], Batch [1330/1944], Loss: 0.0241\n",
      "Epoch [10/15], Batch [1340/1944], Loss: 0.0271\n",
      "Epoch [10/15], Batch [1350/1944], Loss: 0.0299\n",
      "Epoch [10/15], Batch [1360/1944], Loss: 0.0247\n",
      "Epoch [10/15], Batch [1370/1944], Loss: 0.0161\n",
      "Epoch [10/15], Batch [1380/1944], Loss: 0.0174\n",
      "Epoch [10/15], Batch [1390/1944], Loss: 0.0259\n",
      "Epoch [10/15], Batch [1400/1944], Loss: 0.0205\n",
      "Epoch [10/15], Batch [1410/1944], Loss: 0.0232\n",
      "Epoch [10/15], Batch [1420/1944], Loss: 0.0165\n",
      "Epoch [10/15], Batch [1430/1944], Loss: 0.0171\n",
      "Epoch [10/15], Batch [1440/1944], Loss: 0.0147\n",
      "Epoch [10/15], Batch [1450/1944], Loss: 0.0152\n",
      "Epoch [10/15], Batch [1460/1944], Loss: 0.0226\n",
      "Epoch [10/15], Batch [1470/1944], Loss: 0.0269\n",
      "Epoch [10/15], Batch [1480/1944], Loss: 0.0233\n",
      "Epoch [10/15], Batch [1490/1944], Loss: 0.0227\n",
      "Epoch [10/15], Batch [1500/1944], Loss: 0.0118\n",
      "Epoch [10/15], Batch [1510/1944], Loss: 0.0177\n",
      "Epoch [10/15], Batch [1520/1944], Loss: 0.0254\n",
      "Epoch [10/15], Batch [1530/1944], Loss: 0.0190\n",
      "Epoch [10/15], Batch [1540/1944], Loss: 0.0217\n",
      "Epoch [10/15], Batch [1550/1944], Loss: 0.0230\n",
      "Epoch [10/15], Batch [1560/1944], Loss: 0.0269\n",
      "Epoch [10/15], Batch [1570/1944], Loss: 0.0281\n",
      "Epoch [10/15], Batch [1580/1944], Loss: 0.0216\n",
      "Epoch [10/15], Batch [1590/1944], Loss: 0.0162\n",
      "Epoch [10/15], Batch [1600/1944], Loss: 0.0208\n",
      "Epoch [10/15], Batch [1610/1944], Loss: 0.0253\n",
      "Epoch [10/15], Batch [1620/1944], Loss: 0.0249\n",
      "Epoch [10/15], Batch [1630/1944], Loss: 0.0233\n",
      "Epoch [10/15], Batch [1640/1944], Loss: 0.0198\n",
      "Epoch [10/15], Batch [1650/1944], Loss: 0.0167\n",
      "Epoch [10/15], Batch [1660/1944], Loss: 0.0171\n",
      "Epoch [10/15], Batch [1670/1944], Loss: 0.0209\n",
      "Epoch [10/15], Batch [1680/1944], Loss: 0.0267\n",
      "Epoch [10/15], Batch [1690/1944], Loss: 0.0293\n",
      "Epoch [10/15], Batch [1700/1944], Loss: 0.0264\n",
      "Epoch [10/15], Batch [1710/1944], Loss: 0.0221\n",
      "Epoch [10/15], Batch [1720/1944], Loss: 0.0178\n",
      "Epoch [10/15], Batch [1730/1944], Loss: 0.0542\n",
      "Epoch [10/15], Batch [1740/1944], Loss: 0.0196\n",
      "Epoch [10/15], Batch [1750/1944], Loss: 0.0232\n",
      "Epoch [10/15], Batch [1760/1944], Loss: 0.0243\n",
      "Epoch [10/15], Batch [1770/1944], Loss: 0.0264\n",
      "Epoch [10/15], Batch [1780/1944], Loss: 0.0273\n",
      "Epoch [10/15], Batch [1790/1944], Loss: 0.0259\n",
      "Epoch [10/15], Batch [1800/1944], Loss: 0.0172\n",
      "Epoch [10/15], Batch [1810/1944], Loss: 0.0168\n",
      "Epoch [10/15], Batch [1820/1944], Loss: 0.0253\n",
      "Epoch [10/15], Batch [1830/1944], Loss: 0.0197\n",
      "Epoch [10/15], Batch [1840/1944], Loss: 0.0260\n",
      "Epoch [10/15], Batch [1850/1944], Loss: 0.0192\n",
      "Epoch [10/15], Batch [1860/1944], Loss: 0.0212\n",
      "Epoch [10/15], Batch [1870/1944], Loss: 0.0159\n",
      "Epoch [10/15], Batch [1880/1944], Loss: 0.0176\n",
      "Epoch [10/15], Batch [1890/1944], Loss: 0.0240\n",
      "Epoch [10/15], Batch [1900/1944], Loss: 0.0299\n",
      "Epoch [10/15], Batch [1910/1944], Loss: 0.0276\n",
      "Epoch [10/15], Batch [1920/1944], Loss: 0.0288\n",
      "Epoch [10/15], Batch [1930/1944], Loss: 0.0193\n",
      "Epoch [10/15], Batch [1940/1944], Loss: 0.0219\n",
      "Epoch [10/15], Average Loss: 0.0229\n",
      "Epoch [10/15], Validation Loss: 0.0904\n",
      "Epoch [10/15], Current Learning Rate: 0.00025\n",
      "Epoch [11/15], Batch [10/1944], Loss: 0.0222\n",
      "Epoch [11/15], Batch [20/1944], Loss: 0.0236\n",
      "Epoch [11/15], Batch [30/1944], Loss: 0.0247\n",
      "Epoch [11/15], Batch [40/1944], Loss: 0.0245\n",
      "Epoch [11/15], Batch [50/1944], Loss: 0.0275\n",
      "Epoch [11/15], Batch [60/1944], Loss: 0.0281\n",
      "Epoch [11/15], Batch [70/1944], Loss: 0.0195\n",
      "Epoch [11/15], Batch [80/1944], Loss: 0.0147\n",
      "Epoch [11/15], Batch [90/1944], Loss: 0.0229\n",
      "Epoch [11/15], Batch [100/1944], Loss: 0.0211\n",
      "Epoch [11/15], Batch [110/1944], Loss: 0.0245\n",
      "Epoch [11/15], Batch [120/1944], Loss: 0.0207\n",
      "Epoch [11/15], Batch [130/1944], Loss: 0.0209\n",
      "Epoch [11/15], Batch [140/1944], Loss: 0.0192\n",
      "Epoch [11/15], Batch [150/1944], Loss: 0.0183\n",
      "Epoch [11/15], Batch [160/1944], Loss: 0.0226\n",
      "Epoch [11/15], Batch [170/1944], Loss: 0.0275\n",
      "Epoch [11/15], Batch [180/1944], Loss: 0.0277\n",
      "Epoch [11/15], Batch [190/1944], Loss: 0.0279\n",
      "Epoch [11/15], Batch [200/1944], Loss: 0.0210\n",
      "Epoch [11/15], Batch [210/1944], Loss: 0.0180\n",
      "Epoch [11/15], Batch [220/1944], Loss: 0.0558\n",
      "Epoch [11/15], Batch [230/1944], Loss: 0.0249\n",
      "Epoch [11/15], Batch [240/1944], Loss: 0.0249\n",
      "Epoch [11/15], Batch [250/1944], Loss: 0.0247\n",
      "Epoch [11/15], Batch [260/1944], Loss: 0.0275\n",
      "Epoch [11/15], Batch [270/1944], Loss: 0.0302\n",
      "Epoch [11/15], Batch [280/1944], Loss: 0.0241\n",
      "Epoch [11/15], Batch [290/1944], Loss: 0.0158\n",
      "Epoch [11/15], Batch [300/1944], Loss: 0.0161\n",
      "Epoch [11/15], Batch [310/1944], Loss: 0.0248\n",
      "Epoch [11/15], Batch [320/1944], Loss: 0.0197\n",
      "Epoch [11/15], Batch [330/1944], Loss: 0.0238\n",
      "Epoch [11/15], Batch [340/1944], Loss: 0.0174\n",
      "Epoch [11/15], Batch [350/1944], Loss: 0.0184\n",
      "Epoch [11/15], Batch [360/1944], Loss: 0.0175\n",
      "Epoch [11/15], Batch [370/1944], Loss: 0.0182\n",
      "Epoch [11/15], Batch [380/1944], Loss: 0.0252\n",
      "Epoch [11/15], Batch [390/1944], Loss: 0.0283\n",
      "Epoch [11/15], Batch [400/1944], Loss: 0.0250\n",
      "Epoch [11/15], Batch [410/1944], Loss: 0.0238\n",
      "Epoch [11/15], Batch [420/1944], Loss: 0.0133\n",
      "Epoch [11/15], Batch [430/1944], Loss: 0.0188\n",
      "Epoch [11/15], Batch [440/1944], Loss: 0.0304\n",
      "Epoch [11/15], Batch [450/1944], Loss: 0.0228\n",
      "Epoch [11/15], Batch [460/1944], Loss: 0.0239\n",
      "Epoch [11/15], Batch [470/1944], Loss: 0.0245\n",
      "Epoch [11/15], Batch [480/1944], Loss: 0.0275\n",
      "Epoch [11/15], Batch [490/1944], Loss: 0.0282\n",
      "Epoch [11/15], Batch [500/1944], Loss: 0.0211\n",
      "Epoch [11/15], Batch [510/1944], Loss: 0.0152\n",
      "Epoch [11/15], Batch [520/1944], Loss: 0.0183\n",
      "Epoch [11/15], Batch [530/1944], Loss: 0.0225\n",
      "Epoch [11/15], Batch [540/1944], Loss: 0.0224\n",
      "Epoch [11/15], Batch [550/1944], Loss: 0.0218\n",
      "Epoch [11/15], Batch [560/1944], Loss: 0.0185\n",
      "Epoch [11/15], Batch [570/1944], Loss: 0.0153\n",
      "Epoch [11/15], Batch [580/1944], Loss: 0.0157\n",
      "Epoch [11/15], Batch [590/1944], Loss: 0.0194\n",
      "Epoch [11/15], Batch [600/1944], Loss: 0.0243\n",
      "Epoch [11/15], Batch [610/1944], Loss: 0.0259\n",
      "Epoch [11/15], Batch [620/1944], Loss: 0.0231\n",
      "Epoch [11/15], Batch [630/1944], Loss: 0.0182\n",
      "Epoch [11/15], Batch [640/1944], Loss: 0.0141\n",
      "Epoch [11/15], Batch [650/1944], Loss: 0.0569\n",
      "Epoch [11/15], Batch [660/1944], Loss: 0.0206\n",
      "Epoch [11/15], Batch [670/1944], Loss: 0.0229\n",
      "Epoch [11/15], Batch [680/1944], Loss: 0.0243\n",
      "Epoch [11/15], Batch [690/1944], Loss: 0.0265\n",
      "Epoch [11/15], Batch [700/1944], Loss: 0.0275\n",
      "Epoch [11/15], Batch [710/1944], Loss: 0.0256\n",
      "Epoch [11/15], Batch [720/1944], Loss: 0.0168\n",
      "Epoch [11/15], Batch [730/1944], Loss: 0.0159\n",
      "Epoch [11/15], Batch [740/1944], Loss: 0.0231\n",
      "Epoch [11/15], Batch [750/1944], Loss: 0.0181\n",
      "Epoch [11/15], Batch [760/1944], Loss: 0.0247\n",
      "Epoch [11/15], Batch [770/1944], Loss: 0.0181\n",
      "Epoch [11/15], Batch [780/1944], Loss: 0.0196\n",
      "Epoch [11/15], Batch [790/1944], Loss: 0.0148\n",
      "Epoch [11/15], Batch [800/1944], Loss: 0.0168\n",
      "Epoch [11/15], Batch [810/1944], Loss: 0.0233\n",
      "Epoch [11/15], Batch [820/1944], Loss: 0.0290\n",
      "Epoch [11/15], Batch [830/1944], Loss: 0.0269\n",
      "Epoch [11/15], Batch [840/1944], Loss: 0.0284\n",
      "Epoch [11/15], Batch [850/1944], Loss: 0.0187\n",
      "Epoch [11/15], Batch [860/1944], Loss: 0.0213\n",
      "Epoch [11/15], Batch [870/1944], Loss: 0.0401\n",
      "Epoch [11/15], Batch [880/1944], Loss: 0.0215\n",
      "Epoch [11/15], Batch [890/1944], Loss: 0.0235\n",
      "Epoch [11/15], Batch [900/1944], Loss: 0.0251\n",
      "Epoch [11/15], Batch [910/1944], Loss: 0.0293\n",
      "Epoch [11/15], Batch [920/1944], Loss: 0.0320\n",
      "Epoch [11/15], Batch [930/1944], Loss: 0.0245\n",
      "Epoch [11/15], Batch [940/1944], Loss: 0.0167\n",
      "Epoch [11/15], Batch [950/1944], Loss: 0.0216\n",
      "Epoch [11/15], Batch [960/1944], Loss: 0.0247\n",
      "Epoch [11/15], Batch [970/1944], Loss: 0.0225\n",
      "Epoch [11/15], Batch [980/1944], Loss: 0.0228\n",
      "Epoch [11/15], Batch [990/1944], Loss: 0.0195\n",
      "Epoch [11/15], Batch [1000/1944], Loss: 0.0186\n",
      "Epoch [11/15], Batch [1010/1944], Loss: 0.0174\n",
      "Epoch [11/15], Batch [1020/1944], Loss: 0.0181\n",
      "Epoch [11/15], Batch [1030/1944], Loss: 0.0285\n",
      "Epoch [11/15], Batch [1040/1944], Loss: 0.0320\n",
      "Epoch [11/15], Batch [1050/1944], Loss: 0.0300\n",
      "Epoch [11/15], Batch [1060/1944], Loss: 0.0269\n",
      "Epoch [11/15], Batch [1070/1944], Loss: 0.0183\n",
      "Epoch [11/15], Batch [1080/1944], Loss: 0.0175\n",
      "Epoch [11/15], Batch [1090/1944], Loss: 0.0185\n",
      "Epoch [11/15], Batch [1100/1944], Loss: 0.0213\n",
      "Epoch [11/15], Batch [1110/1944], Loss: 0.0230\n",
      "Epoch [11/15], Batch [1120/1944], Loss: 0.0227\n",
      "Epoch [11/15], Batch [1130/1944], Loss: 0.0260\n",
      "Epoch [11/15], Batch [1140/1944], Loss: 0.0274\n",
      "Epoch [11/15], Batch [1150/1944], Loss: 0.0195\n",
      "Epoch [11/15], Batch [1160/1944], Loss: 0.0148\n",
      "Epoch [11/15], Batch [1170/1944], Loss: 0.0234\n",
      "Epoch [11/15], Batch [1180/1944], Loss: 0.0214\n",
      "Epoch [11/15], Batch [1190/1944], Loss: 0.0248\n",
      "Epoch [11/15], Batch [1200/1944], Loss: 0.0198\n",
      "Epoch [11/15], Batch [1210/1944], Loss: 0.0193\n",
      "Epoch [11/15], Batch [1220/1944], Loss: 0.0178\n",
      "Epoch [11/15], Batch [1230/1944], Loss: 0.0173\n",
      "Epoch [11/15], Batch [1240/1944], Loss: 0.0222\n",
      "Epoch [11/15], Batch [1250/1944], Loss: 0.0279\n",
      "Epoch [11/15], Batch [1260/1944], Loss: 0.0293\n",
      "Epoch [11/15], Batch [1270/1944], Loss: 0.0300\n",
      "Epoch [11/15], Batch [1280/1944], Loss: 0.0234\n",
      "Epoch [11/15], Batch [1290/1944], Loss: 0.0209\n",
      "Epoch [11/15], Batch [1300/1944], Loss: 0.0494\n",
      "Epoch [11/15], Batch [1310/1944], Loss: 0.0212\n",
      "Epoch [11/15], Batch [1320/1944], Loss: 0.0227\n",
      "Epoch [11/15], Batch [1330/1944], Loss: 0.0225\n",
      "Epoch [11/15], Batch [1340/1944], Loss: 0.0260\n",
      "Epoch [11/15], Batch [1350/1944], Loss: 0.0292\n",
      "Epoch [11/15], Batch [1360/1944], Loss: 0.0239\n",
      "Epoch [11/15], Batch [1370/1944], Loss: 0.0153\n",
      "Epoch [11/15], Batch [1380/1944], Loss: 0.0168\n",
      "Epoch [11/15], Batch [1390/1944], Loss: 0.0256\n",
      "Epoch [11/15], Batch [1400/1944], Loss: 0.0204\n",
      "Epoch [11/15], Batch [1410/1944], Loss: 0.0234\n",
      "Epoch [11/15], Batch [1420/1944], Loss: 0.0166\n",
      "Epoch [11/15], Batch [1430/1944], Loss: 0.0175\n",
      "Epoch [11/15], Batch [1440/1944], Loss: 0.0165\n",
      "Epoch [11/15], Batch [1450/1944], Loss: 0.0178\n",
      "Epoch [11/15], Batch [1460/1944], Loss: 0.0259\n",
      "Epoch [11/15], Batch [1470/1944], Loss: 0.0296\n",
      "Epoch [11/15], Batch [1480/1944], Loss: 0.0268\n",
      "Epoch [11/15], Batch [1490/1944], Loss: 0.0269\n",
      "Epoch [11/15], Batch [1500/1944], Loss: 0.0157\n",
      "Epoch [11/15], Batch [1510/1944], Loss: 0.0210\n",
      "Epoch [11/15], Batch [1520/1944], Loss: 0.0273\n",
      "Epoch [11/15], Batch [1530/1944], Loss: 0.0213\n",
      "Epoch [11/15], Batch [1540/1944], Loss: 0.0238\n",
      "Epoch [11/15], Batch [1550/1944], Loss: 0.0244\n",
      "Epoch [11/15], Batch [1560/1944], Loss: 0.0279\n",
      "Epoch [11/15], Batch [1570/1944], Loss: 0.0288\n",
      "Epoch [11/15], Batch [1580/1944], Loss: 0.0223\n",
      "Epoch [11/15], Batch [1590/1944], Loss: 0.0168\n",
      "Epoch [11/15], Batch [1600/1944], Loss: 0.0214\n",
      "Epoch [11/15], Batch [1610/1944], Loss: 0.0257\n",
      "Epoch [11/15], Batch [1620/1944], Loss: 0.0255\n",
      "Epoch [11/15], Batch [1630/1944], Loss: 0.0239\n",
      "Epoch [11/15], Batch [1640/1944], Loss: 0.0203\n",
      "Epoch [11/15], Batch [1650/1944], Loss: 0.0172\n",
      "Epoch [11/15], Batch [1660/1944], Loss: 0.0176\n",
      "Epoch [11/15], Batch [1670/1944], Loss: 0.0215\n",
      "Epoch [11/15], Batch [1680/1944], Loss: 0.0273\n",
      "Epoch [11/15], Batch [1690/1944], Loss: 0.0301\n",
      "Epoch [11/15], Batch [1700/1944], Loss: 0.0275\n",
      "Epoch [11/15], Batch [1710/1944], Loss: 0.0237\n",
      "Epoch [11/15], Batch [1720/1944], Loss: 0.0195\n",
      "Epoch [11/15], Batch [1730/1944], Loss: 0.0531\n",
      "Epoch [11/15], Batch [1740/1944], Loss: 0.0188\n",
      "Epoch [11/15], Batch [1750/1944], Loss: 0.0231\n",
      "Epoch [11/15], Batch [1760/1944], Loss: 0.0245\n",
      "Epoch [11/15], Batch [1770/1944], Loss: 0.0266\n",
      "Epoch [11/15], Batch [1780/1944], Loss: 0.0276\n",
      "Epoch [11/15], Batch [1790/1944], Loss: 0.0263\n",
      "Epoch [11/15], Batch [1800/1944], Loss: 0.0175\n",
      "Epoch [11/15], Batch [1810/1944], Loss: 0.0171\n",
      "Epoch [11/15], Batch [1820/1944], Loss: 0.0258\n",
      "Epoch [11/15], Batch [1830/1944], Loss: 0.0204\n",
      "Epoch [11/15], Batch [1840/1944], Loss: 0.0265\n",
      "Epoch [11/15], Batch [1850/1944], Loss: 0.0196\n",
      "Epoch [11/15], Batch [1860/1944], Loss: 0.0215\n",
      "Epoch [11/15], Batch [1870/1944], Loss: 0.0162\n",
      "Epoch [11/15], Batch [1880/1944], Loss: 0.0178\n",
      "Epoch [11/15], Batch [1890/1944], Loss: 0.0243\n",
      "Epoch [11/15], Batch [1900/1944], Loss: 0.0304\n",
      "Epoch [11/15], Batch [1910/1944], Loss: 0.0282\n",
      "Epoch [11/15], Batch [1920/1944], Loss: 0.0297\n",
      "Epoch [11/15], Batch [1930/1944], Loss: 0.0206\n",
      "Epoch [11/15], Batch [1940/1944], Loss: 0.0233\n",
      "Epoch [11/15], Average Loss: 0.0233\n",
      "Epoch [11/15], Validation Loss: 0.0889\n",
      "Epoch [11/15], Current Learning Rate: 0.00025\n",
      "Epoch [12/15], Batch [10/1944], Loss: 0.0210\n",
      "Epoch [12/15], Batch [20/1944], Loss: 0.0221\n",
      "Epoch [12/15], Batch [30/1944], Loss: 0.0234\n",
      "Epoch [12/15], Batch [40/1944], Loss: 0.0235\n",
      "Epoch [12/15], Batch [50/1944], Loss: 0.0270\n",
      "Epoch [12/15], Batch [60/1944], Loss: 0.0280\n",
      "Epoch [12/15], Batch [70/1944], Loss: 0.0194\n",
      "Epoch [12/15], Batch [80/1944], Loss: 0.0149\n",
      "Epoch [12/15], Batch [90/1944], Loss: 0.0231\n",
      "Epoch [12/15], Batch [100/1944], Loss: 0.0213\n",
      "Epoch [12/15], Batch [110/1944], Loss: 0.0247\n",
      "Epoch [12/15], Batch [120/1944], Loss: 0.0209\n",
      "Epoch [12/15], Batch [130/1944], Loss: 0.0210\n",
      "Epoch [12/15], Batch [140/1944], Loss: 0.0193\n",
      "Epoch [12/15], Batch [150/1944], Loss: 0.0184\n",
      "Epoch [12/15], Batch [160/1944], Loss: 0.0227\n",
      "Epoch [12/15], Batch [170/1944], Loss: 0.0276\n",
      "Epoch [12/15], Batch [180/1944], Loss: 0.0275\n",
      "Epoch [12/15], Batch [190/1944], Loss: 0.0276\n",
      "Epoch [12/15], Batch [200/1944], Loss: 0.0209\n",
      "Epoch [12/15], Batch [210/1944], Loss: 0.0178\n",
      "Epoch [12/15], Batch [220/1944], Loss: 0.0537\n",
      "Epoch [12/15], Batch [230/1944], Loss: 0.0226\n",
      "Epoch [12/15], Batch [240/1944], Loss: 0.0231\n",
      "Epoch [12/15], Batch [250/1944], Loss: 0.0232\n",
      "Epoch [12/15], Batch [260/1944], Loss: 0.0264\n",
      "Epoch [12/15], Batch [270/1944], Loss: 0.0292\n",
      "Epoch [12/15], Batch [280/1944], Loss: 0.0238\n",
      "Epoch [12/15], Batch [290/1944], Loss: 0.0152\n",
      "Epoch [12/15], Batch [300/1944], Loss: 0.0157\n",
      "Epoch [12/15], Batch [310/1944], Loss: 0.0245\n",
      "Epoch [12/15], Batch [320/1944], Loss: 0.0195\n",
      "Epoch [12/15], Batch [330/1944], Loss: 0.0238\n",
      "Epoch [12/15], Batch [340/1944], Loss: 0.0173\n",
      "Epoch [12/15], Batch [350/1944], Loss: 0.0183\n",
      "Epoch [12/15], Batch [360/1944], Loss: 0.0175\n",
      "Epoch [12/15], Batch [370/1944], Loss: 0.0183\n",
      "Epoch [12/15], Batch [380/1944], Loss: 0.0253\n",
      "Epoch [12/15], Batch [390/1944], Loss: 0.0284\n",
      "Epoch [12/15], Batch [400/1944], Loss: 0.0252\n",
      "Epoch [12/15], Batch [410/1944], Loss: 0.0240\n",
      "Epoch [12/15], Batch [420/1944], Loss: 0.0138\n",
      "Epoch [12/15], Batch [430/1944], Loss: 0.0193\n",
      "Epoch [12/15], Batch [440/1944], Loss: 0.0281\n",
      "Epoch [12/15], Batch [450/1944], Loss: 0.0207\n",
      "Epoch [12/15], Batch [460/1944], Loss: 0.0224\n",
      "Epoch [12/15], Batch [470/1944], Loss: 0.0229\n",
      "Epoch [12/15], Batch [480/1944], Loss: 0.0263\n",
      "Epoch [12/15], Batch [490/1944], Loss: 0.0273\n",
      "Epoch [12/15], Batch [500/1944], Loss: 0.0201\n",
      "Epoch [12/15], Batch [510/1944], Loss: 0.0143\n",
      "Epoch [12/15], Batch [520/1944], Loss: 0.0176\n",
      "Epoch [12/15], Batch [530/1944], Loss: 0.0220\n",
      "Epoch [12/15], Batch [540/1944], Loss: 0.0221\n",
      "Epoch [12/15], Batch [550/1944], Loss: 0.0219\n",
      "Epoch [12/15], Batch [560/1944], Loss: 0.0184\n",
      "Epoch [12/15], Batch [570/1944], Loss: 0.0153\n",
      "Epoch [12/15], Batch [580/1944], Loss: 0.0156\n",
      "Epoch [12/15], Batch [590/1944], Loss: 0.0193\n",
      "Epoch [12/15], Batch [600/1944], Loss: 0.0242\n",
      "Epoch [12/15], Batch [610/1944], Loss: 0.0257\n",
      "Epoch [12/15], Batch [620/1944], Loss: 0.0230\n",
      "Epoch [12/15], Batch [630/1944], Loss: 0.0182\n",
      "Epoch [12/15], Batch [640/1944], Loss: 0.0142\n",
      "Epoch [12/15], Batch [650/1944], Loss: 0.0539\n",
      "Epoch [12/15], Batch [660/1944], Loss: 0.0190\n",
      "Epoch [12/15], Batch [670/1944], Loss: 0.0235\n",
      "Epoch [12/15], Batch [680/1944], Loss: 0.0246\n",
      "Epoch [12/15], Batch [690/1944], Loss: 0.0266\n",
      "Epoch [12/15], Batch [700/1944], Loss: 0.0271\n",
      "Epoch [12/15], Batch [710/1944], Loss: 0.0249\n",
      "Epoch [12/15], Batch [720/1944], Loss: 0.0161\n",
      "Epoch [12/15], Batch [730/1944], Loss: 0.0153\n",
      "Epoch [12/15], Batch [740/1944], Loss: 0.0228\n",
      "Epoch [12/15], Batch [750/1944], Loss: 0.0178\n",
      "Epoch [12/15], Batch [760/1944], Loss: 0.0244\n",
      "Epoch [12/15], Batch [770/1944], Loss: 0.0179\n",
      "Epoch [12/15], Batch [780/1944], Loss: 0.0195\n",
      "Epoch [12/15], Batch [790/1944], Loss: 0.0145\n",
      "Epoch [12/15], Batch [800/1944], Loss: 0.0165\n",
      "Epoch [12/15], Batch [810/1944], Loss: 0.0231\n",
      "Epoch [12/15], Batch [820/1944], Loss: 0.0289\n",
      "Epoch [12/15], Batch [830/1944], Loss: 0.0267\n",
      "Epoch [12/15], Batch [840/1944], Loss: 0.0286\n",
      "Epoch [12/15], Batch [850/1944], Loss: 0.0192\n",
      "Epoch [12/15], Batch [860/1944], Loss: 0.0220\n",
      "Epoch [12/15], Batch [870/1944], Loss: 0.0435\n",
      "Epoch [12/15], Batch [880/1944], Loss: 0.0225\n",
      "Epoch [12/15], Batch [890/1944], Loss: 0.0248\n",
      "Epoch [12/15], Batch [900/1944], Loss: 0.0261\n",
      "Epoch [12/15], Batch [910/1944], Loss: 0.0300\n",
      "Epoch [12/15], Batch [920/1944], Loss: 0.0324\n",
      "Epoch [12/15], Batch [930/1944], Loss: 0.0250\n",
      "Epoch [12/15], Batch [940/1944], Loss: 0.0170\n",
      "Epoch [12/15], Batch [950/1944], Loss: 0.0216\n",
      "Epoch [12/15], Batch [960/1944], Loss: 0.0244\n",
      "Epoch [12/15], Batch [970/1944], Loss: 0.0224\n",
      "Epoch [12/15], Batch [980/1944], Loss: 0.0228\n",
      "Epoch [12/15], Batch [990/1944], Loss: 0.0196\n",
      "Epoch [12/15], Batch [1000/1944], Loss: 0.0185\n",
      "Epoch [12/15], Batch [1010/1944], Loss: 0.0174\n",
      "Epoch [12/15], Batch [1020/1944], Loss: 0.0181\n",
      "Epoch [12/15], Batch [1030/1944], Loss: 0.0285\n",
      "Epoch [12/15], Batch [1040/1944], Loss: 0.0320\n",
      "Epoch [12/15], Batch [1050/1944], Loss: 0.0301\n",
      "Epoch [12/15], Batch [1060/1944], Loss: 0.0270\n",
      "Epoch [12/15], Batch [1070/1944], Loss: 0.0183\n",
      "Epoch [12/15], Batch [1080/1944], Loss: 0.0177\n",
      "Epoch [12/15], Batch [1090/1944], Loss: 0.0198\n",
      "Epoch [12/15], Batch [1100/1944], Loss: 0.0226\n",
      "Epoch [12/15], Batch [1110/1944], Loss: 0.0241\n",
      "Epoch [12/15], Batch [1120/1944], Loss: 0.0234\n",
      "Epoch [12/15], Batch [1130/1944], Loss: 0.0265\n",
      "Epoch [12/15], Batch [1140/1944], Loss: 0.0279\n",
      "Epoch [12/15], Batch [1150/1944], Loss: 0.0203\n",
      "Epoch [12/15], Batch [1160/1944], Loss: 0.0154\n",
      "Epoch [12/15], Batch [1170/1944], Loss: 0.0241\n",
      "Epoch [12/15], Batch [1180/1944], Loss: 0.0220\n",
      "Epoch [12/15], Batch [1190/1944], Loss: 0.0253\n",
      "Epoch [12/15], Batch [1200/1944], Loss: 0.0200\n",
      "Epoch [12/15], Batch [1210/1944], Loss: 0.0195\n",
      "Epoch [12/15], Batch [1220/1944], Loss: 0.0180\n",
      "Epoch [12/15], Batch [1230/1944], Loss: 0.0175\n",
      "Epoch [12/15], Batch [1240/1944], Loss: 0.0225\n",
      "Epoch [12/15], Batch [1250/1944], Loss: 0.0282\n",
      "Epoch [12/15], Batch [1260/1944], Loss: 0.0296\n",
      "Epoch [12/15], Batch [1270/1944], Loss: 0.0301\n",
      "Epoch [12/15], Batch [1280/1944], Loss: 0.0236\n",
      "Epoch [12/15], Batch [1290/1944], Loss: 0.0212\n",
      "Epoch [12/15], Batch [1300/1944], Loss: 0.0472\n",
      "Epoch [12/15], Batch [1310/1944], Loss: 0.0199\n",
      "Epoch [12/15], Batch [1320/1944], Loss: 0.0210\n",
      "Epoch [12/15], Batch [1330/1944], Loss: 0.0214\n",
      "Epoch [12/15], Batch [1340/1944], Loss: 0.0253\n",
      "Epoch [12/15], Batch [1350/1944], Loss: 0.0286\n",
      "Epoch [12/15], Batch [1360/1944], Loss: 0.0233\n",
      "Epoch [12/15], Batch [1370/1944], Loss: 0.0147\n",
      "Epoch [12/15], Batch [1380/1944], Loss: 0.0162\n",
      "Epoch [12/15], Batch [1390/1944], Loss: 0.0252\n",
      "Epoch [12/15], Batch [1400/1944], Loss: 0.0199\n",
      "Epoch [12/15], Batch [1410/1944], Loss: 0.0232\n",
      "Epoch [12/15], Batch [1420/1944], Loss: 0.0164\n",
      "Epoch [12/15], Batch [1430/1944], Loss: 0.0174\n",
      "Epoch [12/15], Batch [1440/1944], Loss: 0.0163\n",
      "Epoch [12/15], Batch [1450/1944], Loss: 0.0177\n",
      "Epoch [12/15], Batch [1460/1944], Loss: 0.0257\n",
      "Epoch [12/15], Batch [1470/1944], Loss: 0.0295\n",
      "Epoch [12/15], Batch [1480/1944], Loss: 0.0267\n",
      "Epoch [12/15], Batch [1490/1944], Loss: 0.0270\n",
      "Epoch [12/15], Batch [1500/1944], Loss: 0.0157\n",
      "Epoch [12/15], Batch [1510/1944], Loss: 0.0210\n",
      "Epoch [12/15], Batch [1520/1944], Loss: 0.0275\n",
      "Epoch [12/15], Batch [1530/1944], Loss: 0.0215\n",
      "Epoch [12/15], Batch [1540/1944], Loss: 0.0240\n",
      "Epoch [12/15], Batch [1550/1944], Loss: 0.0245\n",
      "Epoch [12/15], Batch [1560/1944], Loss: 0.0280\n",
      "Epoch [12/15], Batch [1570/1944], Loss: 0.0288\n",
      "Epoch [12/15], Batch [1580/1944], Loss: 0.0224\n",
      "Epoch [12/15], Batch [1590/1944], Loss: 0.0170\n",
      "Epoch [12/15], Batch [1600/1944], Loss: 0.0217\n",
      "Epoch [12/15], Batch [1610/1944], Loss: 0.0260\n",
      "Epoch [12/15], Batch [1620/1944], Loss: 0.0259\n",
      "Epoch [12/15], Batch [1630/1944], Loss: 0.0242\n",
      "Epoch [12/15], Batch [1640/1944], Loss: 0.0207\n",
      "Epoch [12/15], Batch [1650/1944], Loss: 0.0177\n",
      "Epoch [12/15], Batch [1660/1944], Loss: 0.0179\n",
      "Epoch [12/15], Batch [1670/1944], Loss: 0.0217\n",
      "Epoch [12/15], Batch [1680/1944], Loss: 0.0275\n",
      "Epoch [12/15], Batch [1690/1944], Loss: 0.0304\n",
      "Epoch [12/15], Batch [1700/1944], Loss: 0.0277\n",
      "Epoch [12/15], Batch [1710/1944], Loss: 0.0238\n",
      "Epoch [12/15], Batch [1720/1944], Loss: 0.0196\n",
      "Epoch [12/15], Batch [1730/1944], Loss: 0.0525\n",
      "Epoch [12/15], Batch [1740/1944], Loss: 0.0182\n",
      "Epoch [12/15], Batch [1750/1944], Loss: 0.0225\n",
      "Epoch [12/15], Batch [1760/1944], Loss: 0.0239\n",
      "Epoch [12/15], Batch [1770/1944], Loss: 0.0261\n",
      "Epoch [12/15], Batch [1780/1944], Loss: 0.0272\n",
      "Epoch [12/15], Batch [1790/1944], Loss: 0.0259\n",
      "Epoch [12/15], Batch [1800/1944], Loss: 0.0173\n",
      "Epoch [12/15], Batch [1810/1944], Loss: 0.0170\n",
      "Epoch [12/15], Batch [1820/1944], Loss: 0.0258\n",
      "Epoch [12/15], Batch [1830/1944], Loss: 0.0203\n",
      "Epoch [12/15], Batch [1840/1944], Loss: 0.0264\n",
      "Epoch [12/15], Batch [1850/1944], Loss: 0.0197\n",
      "Epoch [12/15], Batch [1860/1944], Loss: 0.0216\n",
      "Epoch [12/15], Batch [1870/1944], Loss: 0.0163\n",
      "Epoch [12/15], Batch [1880/1944], Loss: 0.0180\n",
      "Epoch [12/15], Batch [1890/1944], Loss: 0.0246\n",
      "Epoch [12/15], Batch [1900/1944], Loss: 0.0307\n",
      "Epoch [12/15], Batch [1910/1944], Loss: 0.0285\n",
      "Epoch [12/15], Batch [1920/1944], Loss: 0.0299\n",
      "Epoch [12/15], Batch [1930/1944], Loss: 0.0208\n",
      "Epoch [12/15], Batch [1940/1944], Loss: 0.0236\n",
      "Epoch [12/15], Average Loss: 0.0232\n",
      "Epoch [12/15], Validation Loss: 0.0893\n",
      "Epoch [12/15], Current Learning Rate: 0.00025\n",
      "Epoch [13/15], Batch [10/1944], Loss: 0.0225\n",
      "Epoch [13/15], Batch [20/1944], Loss: 0.0237\n",
      "Epoch [13/15], Batch [30/1944], Loss: 0.0245\n",
      "Epoch [13/15], Batch [40/1944], Loss: 0.0243\n",
      "Epoch [13/15], Batch [50/1944], Loss: 0.0276\n",
      "Epoch [13/15], Batch [60/1944], Loss: 0.0282\n",
      "Epoch [13/15], Batch [70/1944], Loss: 0.0194\n",
      "Epoch [13/15], Batch [80/1944], Loss: 0.0147\n",
      "Epoch [13/15], Batch [90/1944], Loss: 0.0229\n",
      "Epoch [13/15], Batch [100/1944], Loss: 0.0210\n",
      "Epoch [13/15], Batch [110/1944], Loss: 0.0243\n",
      "Epoch [13/15], Batch [120/1944], Loss: 0.0208\n",
      "Epoch [13/15], Batch [130/1944], Loss: 0.0209\n",
      "Epoch [13/15], Batch [140/1944], Loss: 0.0192\n",
      "Epoch [13/15], Batch [150/1944], Loss: 0.0183\n",
      "Epoch [13/15], Batch [160/1944], Loss: 0.0227\n",
      "Epoch [13/15], Batch [170/1944], Loss: 0.0278\n",
      "Epoch [13/15], Batch [180/1944], Loss: 0.0280\n",
      "Epoch [13/15], Batch [190/1944], Loss: 0.0284\n",
      "Epoch [13/15], Batch [200/1944], Loss: 0.0214\n",
      "Epoch [13/15], Batch [210/1944], Loss: 0.0185\n",
      "Epoch [13/15], Batch [220/1944], Loss: 0.0523\n",
      "Epoch [13/15], Batch [230/1944], Loss: 0.0228\n",
      "Epoch [13/15], Batch [240/1944], Loss: 0.0233\n",
      "Epoch [13/15], Batch [250/1944], Loss: 0.0232\n",
      "Epoch [13/15], Batch [260/1944], Loss: 0.0262\n",
      "Epoch [13/15], Batch [270/1944], Loss: 0.0293\n",
      "Epoch [13/15], Batch [280/1944], Loss: 0.0240\n",
      "Epoch [13/15], Batch [290/1944], Loss: 0.0154\n",
      "Epoch [13/15], Batch [300/1944], Loss: 0.0157\n",
      "Epoch [13/15], Batch [310/1944], Loss: 0.0244\n",
      "Epoch [13/15], Batch [320/1944], Loss: 0.0194\n",
      "Epoch [13/15], Batch [330/1944], Loss: 0.0238\n",
      "Epoch [13/15], Batch [340/1944], Loss: 0.0173\n",
      "Epoch [13/15], Batch [350/1944], Loss: 0.0182\n",
      "Epoch [13/15], Batch [360/1944], Loss: 0.0174\n",
      "Epoch [13/15], Batch [370/1944], Loss: 0.0182\n",
      "Epoch [13/15], Batch [380/1944], Loss: 0.0253\n",
      "Epoch [13/15], Batch [390/1944], Loss: 0.0284\n",
      "Epoch [13/15], Batch [400/1944], Loss: 0.0252\n",
      "Epoch [13/15], Batch [410/1944], Loss: 0.0239\n",
      "Epoch [13/15], Batch [420/1944], Loss: 0.0133\n",
      "Epoch [13/15], Batch [430/1944], Loss: 0.0187\n",
      "Epoch [13/15], Batch [440/1944], Loss: 0.0290\n",
      "Epoch [13/15], Batch [450/1944], Loss: 0.0204\n",
      "Epoch [13/15], Batch [460/1944], Loss: 0.0216\n",
      "Epoch [13/15], Batch [470/1944], Loss: 0.0222\n",
      "Epoch [13/15], Batch [480/1944], Loss: 0.0259\n",
      "Epoch [13/15], Batch [490/1944], Loss: 0.0271\n",
      "Epoch [13/15], Batch [500/1944], Loss: 0.0200\n",
      "Epoch [13/15], Batch [510/1944], Loss: 0.0140\n",
      "Epoch [13/15], Batch [520/1944], Loss: 0.0173\n",
      "Epoch [13/15], Batch [530/1944], Loss: 0.0219\n",
      "Epoch [13/15], Batch [540/1944], Loss: 0.0219\n",
      "Epoch [13/15], Batch [550/1944], Loss: 0.0218\n",
      "Epoch [13/15], Batch [560/1944], Loss: 0.0184\n",
      "Epoch [13/15], Batch [570/1944], Loss: 0.0153\n",
      "Epoch [13/15], Batch [580/1944], Loss: 0.0156\n",
      "Epoch [13/15], Batch [590/1944], Loss: 0.0192\n",
      "Epoch [13/15], Batch [600/1944], Loss: 0.0240\n",
      "Epoch [13/15], Batch [610/1944], Loss: 0.0255\n",
      "Epoch [13/15], Batch [620/1944], Loss: 0.0227\n",
      "Epoch [13/15], Batch [630/1944], Loss: 0.0179\n",
      "Epoch [13/15], Batch [640/1944], Loss: 0.0141\n",
      "Epoch [13/15], Batch [650/1944], Loss: 0.0546\n",
      "Epoch [13/15], Batch [660/1944], Loss: 0.0187\n",
      "Epoch [13/15], Batch [670/1944], Loss: 0.0229\n",
      "Epoch [13/15], Batch [680/1944], Loss: 0.0240\n",
      "Epoch [13/15], Batch [690/1944], Loss: 0.0262\n",
      "Epoch [13/15], Batch [700/1944], Loss: 0.0271\n",
      "Epoch [13/15], Batch [710/1944], Loss: 0.0250\n",
      "Epoch [13/15], Batch [720/1944], Loss: 0.0160\n",
      "Epoch [13/15], Batch [730/1944], Loss: 0.0152\n",
      "Epoch [13/15], Batch [740/1944], Loss: 0.0231\n",
      "Epoch [13/15], Batch [750/1944], Loss: 0.0181\n",
      "Epoch [13/15], Batch [760/1944], Loss: 0.0245\n",
      "Epoch [13/15], Batch [770/1944], Loss: 0.0179\n",
      "Epoch [13/15], Batch [780/1944], Loss: 0.0196\n",
      "Epoch [13/15], Batch [790/1944], Loss: 0.0145\n",
      "Epoch [13/15], Batch [800/1944], Loss: 0.0166\n",
      "Epoch [13/15], Batch [810/1944], Loss: 0.0233\n",
      "Epoch [13/15], Batch [820/1944], Loss: 0.0293\n",
      "Epoch [13/15], Batch [830/1944], Loss: 0.0272\n",
      "Epoch [13/15], Batch [840/1944], Loss: 0.0291\n",
      "Epoch [13/15], Batch [850/1944], Loss: 0.0199\n",
      "Epoch [13/15], Batch [860/1944], Loss: 0.0226\n",
      "Epoch [13/15], Batch [870/1944], Loss: 0.0386\n",
      "Epoch [13/15], Batch [880/1944], Loss: 0.0207\n",
      "Epoch [13/15], Batch [890/1944], Loss: 0.0234\n",
      "Epoch [13/15], Batch [900/1944], Loss: 0.0253\n",
      "Epoch [13/15], Batch [910/1944], Loss: 0.0295\n",
      "Epoch [13/15], Batch [920/1944], Loss: 0.0322\n",
      "Epoch [13/15], Batch [930/1944], Loss: 0.0247\n",
      "Epoch [13/15], Batch [940/1944], Loss: 0.0167\n",
      "Epoch [13/15], Batch [950/1944], Loss: 0.0215\n",
      "Epoch [13/15], Batch [960/1944], Loss: 0.0245\n",
      "Epoch [13/15], Batch [970/1944], Loss: 0.0224\n",
      "Epoch [13/15], Batch [980/1944], Loss: 0.0229\n",
      "Epoch [13/15], Batch [990/1944], Loss: 0.0196\n",
      "Epoch [13/15], Batch [1000/1944], Loss: 0.0185\n",
      "Epoch [13/15], Batch [1010/1944], Loss: 0.0173\n",
      "Epoch [13/15], Batch [1020/1944], Loss: 0.0180\n",
      "Epoch [13/15], Batch [1030/1944], Loss: 0.0286\n",
      "Epoch [13/15], Batch [1040/1944], Loss: 0.0319\n",
      "Epoch [13/15], Batch [1050/1944], Loss: 0.0300\n",
      "Epoch [13/15], Batch [1060/1944], Loss: 0.0268\n",
      "Epoch [13/15], Batch [1070/1944], Loss: 0.0182\n",
      "Epoch [13/15], Batch [1080/1944], Loss: 0.0177\n",
      "Epoch [13/15], Batch [1090/1944], Loss: 0.0189\n",
      "Epoch [13/15], Batch [1100/1944], Loss: 0.0218\n",
      "Epoch [13/15], Batch [1110/1944], Loss: 0.0235\n",
      "Epoch [13/15], Batch [1120/1944], Loss: 0.0232\n",
      "Epoch [13/15], Batch [1130/1944], Loss: 0.0265\n",
      "Epoch [13/15], Batch [1140/1944], Loss: 0.0279\n",
      "Epoch [13/15], Batch [1150/1944], Loss: 0.0201\n",
      "Epoch [13/15], Batch [1160/1944], Loss: 0.0152\n",
      "Epoch [13/15], Batch [1170/1944], Loss: 0.0239\n",
      "Epoch [13/15], Batch [1180/1944], Loss: 0.0217\n",
      "Epoch [13/15], Batch [1190/1944], Loss: 0.0252\n",
      "Epoch [13/15], Batch [1200/1944], Loss: 0.0200\n",
      "Epoch [13/15], Batch [1210/1944], Loss: 0.0194\n",
      "Epoch [13/15], Batch [1220/1944], Loss: 0.0179\n",
      "Epoch [13/15], Batch [1230/1944], Loss: 0.0173\n",
      "Epoch [13/15], Batch [1240/1944], Loss: 0.0224\n",
      "Epoch [13/15], Batch [1250/1944], Loss: 0.0282\n",
      "Epoch [13/15], Batch [1260/1944], Loss: 0.0295\n",
      "Epoch [13/15], Batch [1270/1944], Loss: 0.0300\n",
      "Epoch [13/15], Batch [1280/1944], Loss: 0.0234\n",
      "Epoch [13/15], Batch [1290/1944], Loss: 0.0209\n",
      "Epoch [13/15], Batch [1300/1944], Loss: 0.0476\n",
      "Epoch [13/15], Batch [1310/1944], Loss: 0.0194\n",
      "Epoch [13/15], Batch [1320/1944], Loss: 0.0208\n",
      "Epoch [13/15], Batch [1330/1944], Loss: 0.0212\n",
      "Epoch [13/15], Batch [1340/1944], Loss: 0.0251\n",
      "Epoch [13/15], Batch [1350/1944], Loss: 0.0285\n",
      "Epoch [13/15], Batch [1360/1944], Loss: 0.0231\n",
      "Epoch [13/15], Batch [1370/1944], Loss: 0.0146\n",
      "Epoch [13/15], Batch [1380/1944], Loss: 0.0160\n",
      "Epoch [13/15], Batch [1390/1944], Loss: 0.0251\n",
      "Epoch [13/15], Batch [1400/1944], Loss: 0.0198\n",
      "Epoch [13/15], Batch [1410/1944], Loss: 0.0231\n",
      "Epoch [13/15], Batch [1420/1944], Loss: 0.0164\n",
      "Epoch [13/15], Batch [1430/1944], Loss: 0.0173\n",
      "Epoch [13/15], Batch [1440/1944], Loss: 0.0163\n",
      "Epoch [13/15], Batch [1450/1944], Loss: 0.0177\n",
      "Epoch [13/15], Batch [1460/1944], Loss: 0.0257\n",
      "Epoch [13/15], Batch [1470/1944], Loss: 0.0295\n",
      "Epoch [13/15], Batch [1480/1944], Loss: 0.0267\n",
      "Epoch [13/15], Batch [1490/1944], Loss: 0.0270\n",
      "Epoch [13/15], Batch [1500/1944], Loss: 0.0157\n",
      "Epoch [13/15], Batch [1510/1944], Loss: 0.0211\n",
      "Epoch [13/15], Batch [1520/1944], Loss: 0.0275\n",
      "Epoch [13/15], Batch [1530/1944], Loss: 0.0215\n",
      "Epoch [13/15], Batch [1540/1944], Loss: 0.0239\n",
      "Epoch [13/15], Batch [1550/1944], Loss: 0.0245\n",
      "Epoch [13/15], Batch [1560/1944], Loss: 0.0281\n",
      "Epoch [13/15], Batch [1570/1944], Loss: 0.0288\n",
      "Epoch [13/15], Batch [1580/1944], Loss: 0.0224\n",
      "Epoch [13/15], Batch [1590/1944], Loss: 0.0171\n",
      "Epoch [13/15], Batch [1600/1944], Loss: 0.0217\n",
      "Epoch [13/15], Batch [1610/1944], Loss: 0.0260\n",
      "Epoch [13/15], Batch [1620/1944], Loss: 0.0259\n",
      "Epoch [13/15], Batch [1630/1944], Loss: 0.0243\n",
      "Epoch [13/15], Batch [1640/1944], Loss: 0.0207\n",
      "Epoch [13/15], Batch [1650/1944], Loss: 0.0178\n",
      "Epoch [13/15], Batch [1660/1944], Loss: 0.0181\n",
      "Epoch [13/15], Batch [1670/1944], Loss: 0.0218\n",
      "Epoch [13/15], Batch [1680/1944], Loss: 0.0276\n",
      "Epoch [13/15], Batch [1690/1944], Loss: 0.0305\n",
      "Epoch [13/15], Batch [1700/1944], Loss: 0.0279\n",
      "Epoch [13/15], Batch [1710/1944], Loss: 0.0239\n",
      "Epoch [13/15], Batch [1720/1944], Loss: 0.0198\n",
      "Epoch [13/15], Batch [1730/1944], Loss: 0.0523\n",
      "Epoch [13/15], Batch [1740/1944], Loss: 0.0181\n",
      "Epoch [13/15], Batch [1750/1944], Loss: 0.0223\n",
      "Epoch [13/15], Batch [1760/1944], Loss: 0.0237\n",
      "Epoch [13/15], Batch [1770/1944], Loss: 0.0260\n",
      "Epoch [13/15], Batch [1780/1944], Loss: 0.0270\n",
      "Epoch [13/15], Batch [1790/1944], Loss: 0.0257\n",
      "Epoch [13/15], Batch [1800/1944], Loss: 0.0172\n",
      "Epoch [13/15], Batch [1810/1944], Loss: 0.0170\n",
      "Epoch [13/15], Batch [1820/1944], Loss: 0.0257\n",
      "Epoch [13/15], Batch [1830/1944], Loss: 0.0203\n",
      "Epoch [13/15], Batch [1840/1944], Loss: 0.0262\n",
      "Epoch [13/15], Batch [1850/1944], Loss: 0.0196\n",
      "Epoch [13/15], Batch [1860/1944], Loss: 0.0215\n",
      "Epoch [13/15], Batch [1870/1944], Loss: 0.0162\n",
      "Epoch [13/15], Batch [1880/1944], Loss: 0.0179\n",
      "Epoch [13/15], Batch [1890/1944], Loss: 0.0244\n",
      "Epoch [13/15], Batch [1900/1944], Loss: 0.0305\n",
      "Epoch [13/15], Batch [1910/1944], Loss: 0.0282\n",
      "Epoch [13/15], Batch [1920/1944], Loss: 0.0296\n",
      "Epoch [13/15], Batch [1930/1944], Loss: 0.0205\n",
      "Epoch [13/15], Batch [1940/1944], Loss: 0.0233\n",
      "Epoch [13/15], Average Loss: 0.0231\n",
      "Epoch [13/15], Validation Loss: 0.0890\n",
      "Epoch [13/15], Current Learning Rate: 0.00025\n",
      "Epoch [14/15], Batch [10/1944], Loss: 0.0217\n",
      "Epoch [14/15], Batch [20/1944], Loss: 0.0233\n",
      "Epoch [14/15], Batch [30/1944], Loss: 0.0241\n",
      "Epoch [14/15], Batch [40/1944], Loss: 0.0238\n",
      "Epoch [14/15], Batch [50/1944], Loss: 0.0270\n",
      "Epoch [14/15], Batch [60/1944], Loss: 0.0279\n",
      "Epoch [14/15], Batch [70/1944], Loss: 0.0192\n",
      "Epoch [14/15], Batch [80/1944], Loss: 0.0147\n",
      "Epoch [14/15], Batch [90/1944], Loss: 0.0230\n",
      "Epoch [14/15], Batch [100/1944], Loss: 0.0212\n",
      "Epoch [14/15], Batch [110/1944], Loss: 0.0244\n",
      "Epoch [14/15], Batch [120/1944], Loss: 0.0208\n",
      "Epoch [14/15], Batch [130/1944], Loss: 0.0209\n",
      "Epoch [14/15], Batch [140/1944], Loss: 0.0192\n",
      "Epoch [14/15], Batch [150/1944], Loss: 0.0183\n",
      "Epoch [14/15], Batch [160/1944], Loss: 0.0226\n",
      "Epoch [14/15], Batch [170/1944], Loss: 0.0277\n",
      "Epoch [14/15], Batch [180/1944], Loss: 0.0278\n",
      "Epoch [14/15], Batch [190/1944], Loss: 0.0283\n",
      "Epoch [14/15], Batch [200/1944], Loss: 0.0213\n",
      "Epoch [14/15], Batch [210/1944], Loss: 0.0184\n",
      "Epoch [14/15], Batch [220/1944], Loss: 0.0537\n",
      "Epoch [14/15], Batch [230/1944], Loss: 0.0222\n",
      "Epoch [14/15], Batch [240/1944], Loss: 0.0228\n",
      "Epoch [14/15], Batch [250/1944], Loss: 0.0230\n",
      "Epoch [14/15], Batch [260/1944], Loss: 0.0263\n",
      "Epoch [14/15], Batch [270/1944], Loss: 0.0295\n",
      "Epoch [14/15], Batch [280/1944], Loss: 0.0239\n",
      "Epoch [14/15], Batch [290/1944], Loss: 0.0152\n",
      "Epoch [14/15], Batch [300/1944], Loss: 0.0156\n",
      "Epoch [14/15], Batch [310/1944], Loss: 0.0244\n",
      "Epoch [14/15], Batch [320/1944], Loss: 0.0195\n",
      "Epoch [14/15], Batch [330/1944], Loss: 0.0238\n",
      "Epoch [14/15], Batch [340/1944], Loss: 0.0174\n",
      "Epoch [14/15], Batch [350/1944], Loss: 0.0183\n",
      "Epoch [14/15], Batch [360/1944], Loss: 0.0175\n",
      "Epoch [14/15], Batch [370/1944], Loss: 0.0183\n",
      "Epoch [14/15], Batch [380/1944], Loss: 0.0254\n",
      "Epoch [14/15], Batch [390/1944], Loss: 0.0286\n",
      "Epoch [14/15], Batch [400/1944], Loss: 0.0253\n",
      "Epoch [14/15], Batch [410/1944], Loss: 0.0243\n",
      "Epoch [14/15], Batch [420/1944], Loss: 0.0140\n",
      "Epoch [14/15], Batch [430/1944], Loss: 0.0193\n",
      "Epoch [14/15], Batch [440/1944], Loss: 0.0258\n",
      "Epoch [14/15], Batch [450/1944], Loss: 0.0185\n",
      "Epoch [14/15], Batch [460/1944], Loss: 0.0206\n",
      "Epoch [14/15], Batch [470/1944], Loss: 0.0217\n",
      "Epoch [14/15], Batch [480/1944], Loss: 0.0255\n",
      "Epoch [14/15], Batch [490/1944], Loss: 0.0268\n",
      "Epoch [14/15], Batch [500/1944], Loss: 0.0197\n",
      "Epoch [14/15], Batch [510/1944], Loss: 0.0139\n",
      "Epoch [14/15], Batch [520/1944], Loss: 0.0171\n",
      "Epoch [14/15], Batch [530/1944], Loss: 0.0217\n",
      "Epoch [14/15], Batch [540/1944], Loss: 0.0218\n",
      "Epoch [14/15], Batch [550/1944], Loss: 0.0218\n",
      "Epoch [14/15], Batch [560/1944], Loss: 0.0183\n",
      "Epoch [14/15], Batch [570/1944], Loss: 0.0153\n",
      "Epoch [14/15], Batch [580/1944], Loss: 0.0157\n",
      "Epoch [14/15], Batch [590/1944], Loss: 0.0192\n",
      "Epoch [14/15], Batch [600/1944], Loss: 0.0238\n",
      "Epoch [14/15], Batch [610/1944], Loss: 0.0252\n",
      "Epoch [14/15], Batch [620/1944], Loss: 0.0224\n",
      "Epoch [14/15], Batch [630/1944], Loss: 0.0178\n",
      "Epoch [14/15], Batch [640/1944], Loss: 0.0141\n",
      "Epoch [14/15], Batch [650/1944], Loss: 0.0526\n",
      "Epoch [14/15], Batch [660/1944], Loss: 0.0173\n",
      "Epoch [14/15], Batch [670/1944], Loss: 0.0218\n",
      "Epoch [14/15], Batch [680/1944], Loss: 0.0237\n",
      "Epoch [14/15], Batch [690/1944], Loss: 0.0260\n",
      "Epoch [14/15], Batch [700/1944], Loss: 0.0270\n",
      "Epoch [14/15], Batch [710/1944], Loss: 0.0248\n",
      "Epoch [14/15], Batch [720/1944], Loss: 0.0157\n",
      "Epoch [14/15], Batch [730/1944], Loss: 0.0150\n",
      "Epoch [14/15], Batch [740/1944], Loss: 0.0230\n",
      "Epoch [14/15], Batch [750/1944], Loss: 0.0181\n",
      "Epoch [14/15], Batch [760/1944], Loss: 0.0245\n",
      "Epoch [14/15], Batch [770/1944], Loss: 0.0178\n",
      "Epoch [14/15], Batch [780/1944], Loss: 0.0196\n",
      "Epoch [14/15], Batch [790/1944], Loss: 0.0145\n",
      "Epoch [14/15], Batch [800/1944], Loss: 0.0166\n",
      "Epoch [14/15], Batch [810/1944], Loss: 0.0233\n",
      "Epoch [14/15], Batch [820/1944], Loss: 0.0292\n",
      "Epoch [14/15], Batch [830/1944], Loss: 0.0270\n",
      "Epoch [14/15], Batch [840/1944], Loss: 0.0284\n",
      "Epoch [14/15], Batch [850/1944], Loss: 0.0186\n",
      "Epoch [14/15], Batch [860/1944], Loss: 0.0211\n",
      "Epoch [14/15], Batch [870/1944], Loss: 0.0401\n",
      "Epoch [14/15], Batch [880/1944], Loss: 0.0203\n",
      "Epoch [14/15], Batch [890/1944], Loss: 0.0229\n",
      "Epoch [14/15], Batch [900/1944], Loss: 0.0252\n",
      "Epoch [14/15], Batch [910/1944], Loss: 0.0297\n",
      "Epoch [14/15], Batch [920/1944], Loss: 0.0324\n",
      "Epoch [14/15], Batch [930/1944], Loss: 0.0248\n",
      "Epoch [14/15], Batch [940/1944], Loss: 0.0167\n",
      "Epoch [14/15], Batch [950/1944], Loss: 0.0215\n",
      "Epoch [14/15], Batch [960/1944], Loss: 0.0245\n",
      "Epoch [14/15], Batch [970/1944], Loss: 0.0225\n",
      "Epoch [14/15], Batch [980/1944], Loss: 0.0230\n",
      "Epoch [14/15], Batch [990/1944], Loss: 0.0196\n",
      "Epoch [14/15], Batch [1000/1944], Loss: 0.0186\n",
      "Epoch [14/15], Batch [1010/1944], Loss: 0.0174\n",
      "Epoch [14/15], Batch [1020/1944], Loss: 0.0181\n",
      "Epoch [14/15], Batch [1030/1944], Loss: 0.0285\n",
      "Epoch [14/15], Batch [1040/1944], Loss: 0.0315\n",
      "Epoch [14/15], Batch [1050/1944], Loss: 0.0295\n",
      "Epoch [14/15], Batch [1060/1944], Loss: 0.0261\n",
      "Epoch [14/15], Batch [1070/1944], Loss: 0.0173\n",
      "Epoch [14/15], Batch [1080/1944], Loss: 0.0166\n",
      "Epoch [14/15], Batch [1090/1944], Loss: 0.0184\n",
      "Epoch [14/15], Batch [1100/1944], Loss: 0.0212\n",
      "Epoch [14/15], Batch [1110/1944], Loss: 0.0229\n",
      "Epoch [14/15], Batch [1120/1944], Loss: 0.0230\n",
      "Epoch [14/15], Batch [1130/1944], Loss: 0.0265\n",
      "Epoch [14/15], Batch [1140/1944], Loss: 0.0281\n",
      "Epoch [14/15], Batch [1150/1944], Loss: 0.0202\n",
      "Epoch [14/15], Batch [1160/1944], Loss: 0.0152\n",
      "Epoch [14/15], Batch [1170/1944], Loss: 0.0238\n",
      "Epoch [14/15], Batch [1180/1944], Loss: 0.0216\n",
      "Epoch [14/15], Batch [1190/1944], Loss: 0.0251\n",
      "Epoch [14/15], Batch [1200/1944], Loss: 0.0199\n",
      "Epoch [14/15], Batch [1210/1944], Loss: 0.0193\n",
      "Epoch [14/15], Batch [1220/1944], Loss: 0.0177\n",
      "Epoch [14/15], Batch [1230/1944], Loss: 0.0173\n",
      "Epoch [14/15], Batch [1240/1944], Loss: 0.0223\n",
      "Epoch [14/15], Batch [1250/1944], Loss: 0.0280\n",
      "Epoch [14/15], Batch [1260/1944], Loss: 0.0292\n",
      "Epoch [14/15], Batch [1270/1944], Loss: 0.0297\n",
      "Epoch [14/15], Batch [1280/1944], Loss: 0.0231\n",
      "Epoch [14/15], Batch [1290/1944], Loss: 0.0205\n",
      "Epoch [14/15], Batch [1300/1944], Loss: 0.0469\n",
      "Epoch [14/15], Batch [1310/1944], Loss: 0.0187\n",
      "Epoch [14/15], Batch [1320/1944], Loss: 0.0203\n",
      "Epoch [14/15], Batch [1330/1944], Loss: 0.0209\n",
      "Epoch [14/15], Batch [1340/1944], Loss: 0.0249\n",
      "Epoch [14/15], Batch [1350/1944], Loss: 0.0283\n",
      "Epoch [14/15], Batch [1360/1944], Loss: 0.0229\n",
      "Epoch [14/15], Batch [1370/1944], Loss: 0.0145\n",
      "Epoch [14/15], Batch [1380/1944], Loss: 0.0160\n",
      "Epoch [14/15], Batch [1390/1944], Loss: 0.0250\n",
      "Epoch [14/15], Batch [1400/1944], Loss: 0.0197\n",
      "Epoch [14/15], Batch [1410/1944], Loss: 0.0231\n",
      "Epoch [14/15], Batch [1420/1944], Loss: 0.0164\n",
      "Epoch [14/15], Batch [1430/1944], Loss: 0.0174\n",
      "Epoch [14/15], Batch [1440/1944], Loss: 0.0164\n",
      "Epoch [14/15], Batch [1450/1944], Loss: 0.0177\n",
      "Epoch [14/15], Batch [1460/1944], Loss: 0.0257\n",
      "Epoch [14/15], Batch [1470/1944], Loss: 0.0294\n",
      "Epoch [14/15], Batch [1480/1944], Loss: 0.0266\n",
      "Epoch [14/15], Batch [1490/1944], Loss: 0.0269\n",
      "Epoch [14/15], Batch [1500/1944], Loss: 0.0157\n",
      "Epoch [14/15], Batch [1510/1944], Loss: 0.0210\n",
      "Epoch [14/15], Batch [1520/1944], Loss: 0.0276\n",
      "Epoch [14/15], Batch [1530/1944], Loss: 0.0215\n",
      "Epoch [14/15], Batch [1540/1944], Loss: 0.0239\n",
      "Epoch [14/15], Batch [1550/1944], Loss: 0.0245\n",
      "Epoch [14/15], Batch [1560/1944], Loss: 0.0280\n",
      "Epoch [14/15], Batch [1570/1944], Loss: 0.0288\n",
      "Epoch [14/15], Batch [1580/1944], Loss: 0.0225\n",
      "Epoch [14/15], Batch [1590/1944], Loss: 0.0172\n",
      "Epoch [14/15], Batch [1600/1944], Loss: 0.0218\n",
      "Epoch [14/15], Batch [1610/1944], Loss: 0.0260\n",
      "Epoch [14/15], Batch [1620/1944], Loss: 0.0260\n",
      "Epoch [14/15], Batch [1630/1944], Loss: 0.0244\n",
      "Epoch [14/15], Batch [1640/1944], Loss: 0.0208\n",
      "Epoch [14/15], Batch [1650/1944], Loss: 0.0179\n",
      "Epoch [14/15], Batch [1660/1944], Loss: 0.0182\n",
      "Epoch [14/15], Batch [1670/1944], Loss: 0.0220\n",
      "Epoch [14/15], Batch [1680/1944], Loss: 0.0276\n",
      "Epoch [14/15], Batch [1690/1944], Loss: 0.0306\n",
      "Epoch [14/15], Batch [1700/1944], Loss: 0.0278\n",
      "Epoch [14/15], Batch [1710/1944], Loss: 0.0238\n",
      "Epoch [14/15], Batch [1720/1944], Loss: 0.0197\n",
      "Epoch [14/15], Batch [1730/1944], Loss: 0.0521\n",
      "Epoch [14/15], Batch [1740/1944], Loss: 0.0181\n",
      "Epoch [14/15], Batch [1750/1944], Loss: 0.0222\n",
      "Epoch [14/15], Batch [1760/1944], Loss: 0.0236\n",
      "Epoch [14/15], Batch [1770/1944], Loss: 0.0259\n",
      "Epoch [14/15], Batch [1780/1944], Loss: 0.0269\n",
      "Epoch [14/15], Batch [1790/1944], Loss: 0.0256\n",
      "Epoch [14/15], Batch [1800/1944], Loss: 0.0171\n",
      "Epoch [14/15], Batch [1810/1944], Loss: 0.0169\n",
      "Epoch [14/15], Batch [1820/1944], Loss: 0.0257\n",
      "Epoch [14/15], Batch [1830/1944], Loss: 0.0202\n",
      "Epoch [14/15], Batch [1840/1944], Loss: 0.0261\n",
      "Epoch [14/15], Batch [1850/1944], Loss: 0.0195\n",
      "Epoch [14/15], Batch [1860/1944], Loss: 0.0215\n",
      "Epoch [14/15], Batch [1870/1944], Loss: 0.0161\n",
      "Epoch [14/15], Batch [1880/1944], Loss: 0.0178\n",
      "Epoch [14/15], Batch [1890/1944], Loss: 0.0242\n",
      "Epoch [14/15], Batch [1900/1944], Loss: 0.0303\n",
      "Epoch [14/15], Batch [1910/1944], Loss: 0.0280\n",
      "Epoch [14/15], Batch [1920/1944], Loss: 0.0294\n",
      "Epoch [14/15], Batch [1930/1944], Loss: 0.0202\n",
      "Epoch [14/15], Batch [1940/1944], Loss: 0.0230\n",
      "Epoch [14/15], Average Loss: 0.0229\n",
      "Epoch [14/15], Validation Loss: 0.0894\n",
      "Epoch [14/15], Current Learning Rate: 0.00025\n",
      "Epoch [15/15], Batch [10/1944], Loss: 0.0214\n",
      "Epoch [15/15], Batch [20/1944], Loss: 0.0230\n",
      "Epoch [15/15], Batch [30/1944], Loss: 0.0238\n",
      "Epoch [15/15], Batch [40/1944], Loss: 0.0237\n",
      "Epoch [15/15], Batch [50/1944], Loss: 0.0272\n",
      "Epoch [15/15], Batch [60/1944], Loss: 0.0280\n",
      "Epoch [15/15], Batch [70/1944], Loss: 0.0192\n",
      "Epoch [15/15], Batch [80/1944], Loss: 0.0148\n",
      "Epoch [15/15], Batch [90/1944], Loss: 0.0231\n",
      "Epoch [15/15], Batch [100/1944], Loss: 0.0214\n",
      "Epoch [15/15], Batch [110/1944], Loss: 0.0244\n",
      "Epoch [15/15], Batch [120/1944], Loss: 0.0208\n",
      "Epoch [15/15], Batch [130/1944], Loss: 0.0210\n",
      "Epoch [15/15], Batch [140/1944], Loss: 0.0193\n",
      "Epoch [15/15], Batch [150/1944], Loss: 0.0183\n",
      "Epoch [15/15], Batch [160/1944], Loss: 0.0227\n",
      "Epoch [15/15], Batch [170/1944], Loss: 0.0275\n",
      "Epoch [15/15], Batch [180/1944], Loss: 0.0273\n",
      "Epoch [15/15], Batch [190/1944], Loss: 0.0277\n",
      "Epoch [15/15], Batch [200/1944], Loss: 0.0209\n",
      "Epoch [15/15], Batch [210/1944], Loss: 0.0181\n",
      "Epoch [15/15], Batch [220/1944], Loss: 0.0509\n",
      "Epoch [15/15], Batch [230/1944], Loss: 0.0218\n",
      "Epoch [15/15], Batch [240/1944], Loss: 0.0224\n",
      "Epoch [15/15], Batch [250/1944], Loss: 0.0224\n",
      "Epoch [15/15], Batch [260/1944], Loss: 0.0258\n",
      "Epoch [15/15], Batch [270/1944], Loss: 0.0293\n",
      "Epoch [15/15], Batch [280/1944], Loss: 0.0239\n",
      "Epoch [15/15], Batch [290/1944], Loss: 0.0153\n",
      "Epoch [15/15], Batch [300/1944], Loss: 0.0158\n",
      "Epoch [15/15], Batch [310/1944], Loss: 0.0245\n",
      "Epoch [15/15], Batch [320/1944], Loss: 0.0195\n",
      "Epoch [15/15], Batch [330/1944], Loss: 0.0237\n",
      "Epoch [15/15], Batch [340/1944], Loss: 0.0172\n",
      "Epoch [15/15], Batch [350/1944], Loss: 0.0182\n",
      "Epoch [15/15], Batch [360/1944], Loss: 0.0173\n",
      "Epoch [15/15], Batch [370/1944], Loss: 0.0180\n",
      "Epoch [15/15], Batch [380/1944], Loss: 0.0251\n",
      "Epoch [15/15], Batch [390/1944], Loss: 0.0282\n",
      "Epoch [15/15], Batch [400/1944], Loss: 0.0249\n",
      "Epoch [15/15], Batch [410/1944], Loss: 0.0237\n",
      "Epoch [15/15], Batch [420/1944], Loss: 0.0134\n",
      "Epoch [15/15], Batch [430/1944], Loss: 0.0190\n",
      "Epoch [15/15], Batch [440/1944], Loss: 0.0251\n",
      "Epoch [15/15], Batch [450/1944], Loss: 0.0180\n",
      "Epoch [15/15], Batch [460/1944], Loss: 0.0201\n",
      "Epoch [15/15], Batch [470/1944], Loss: 0.0215\n",
      "Epoch [15/15], Batch [480/1944], Loss: 0.0254\n",
      "Epoch [15/15], Batch [490/1944], Loss: 0.0267\n",
      "Epoch [15/15], Batch [500/1944], Loss: 0.0195\n",
      "Epoch [15/15], Batch [510/1944], Loss: 0.0137\n",
      "Epoch [15/15], Batch [520/1944], Loss: 0.0169\n",
      "Epoch [15/15], Batch [530/1944], Loss: 0.0215\n",
      "Epoch [15/15], Batch [540/1944], Loss: 0.0216\n",
      "Epoch [15/15], Batch [550/1944], Loss: 0.0217\n",
      "Epoch [15/15], Batch [560/1944], Loss: 0.0183\n",
      "Epoch [15/15], Batch [570/1944], Loss: 0.0152\n",
      "Epoch [15/15], Batch [580/1944], Loss: 0.0156\n",
      "Epoch [15/15], Batch [590/1944], Loss: 0.0189\n",
      "Epoch [15/15], Batch [600/1944], Loss: 0.0235\n",
      "Epoch [15/15], Batch [610/1944], Loss: 0.0250\n",
      "Epoch [15/15], Batch [620/1944], Loss: 0.0223\n",
      "Epoch [15/15], Batch [630/1944], Loss: 0.0178\n",
      "Epoch [15/15], Batch [640/1944], Loss: 0.0140\n",
      "Epoch [15/15], Batch [650/1944], Loss: 0.0522\n",
      "Epoch [15/15], Batch [660/1944], Loss: 0.0172\n",
      "Epoch [15/15], Batch [670/1944], Loss: 0.0218\n",
      "Epoch [15/15], Batch [680/1944], Loss: 0.0235\n",
      "Epoch [15/15], Batch [690/1944], Loss: 0.0258\n",
      "Epoch [15/15], Batch [700/1944], Loss: 0.0269\n",
      "Epoch [15/15], Batch [710/1944], Loss: 0.0247\n",
      "Epoch [15/15], Batch [720/1944], Loss: 0.0156\n",
      "Epoch [15/15], Batch [730/1944], Loss: 0.0149\n",
      "Epoch [15/15], Batch [740/1944], Loss: 0.0229\n",
      "Epoch [15/15], Batch [750/1944], Loss: 0.0181\n",
      "Epoch [15/15], Batch [760/1944], Loss: 0.0246\n",
      "Epoch [15/15], Batch [770/1944], Loss: 0.0178\n",
      "Epoch [15/15], Batch [780/1944], Loss: 0.0195\n",
      "Epoch [15/15], Batch [790/1944], Loss: 0.0146\n",
      "Epoch [15/15], Batch [800/1944], Loss: 0.0166\n",
      "Epoch [15/15], Batch [810/1944], Loss: 0.0234\n",
      "Epoch [15/15], Batch [820/1944], Loss: 0.0293\n",
      "Epoch [15/15], Batch [830/1944], Loss: 0.0273\n",
      "Epoch [15/15], Batch [840/1944], Loss: 0.0292\n",
      "Epoch [15/15], Batch [850/1944], Loss: 0.0200\n",
      "Epoch [15/15], Batch [860/1944], Loss: 0.0227\n",
      "Epoch [15/15], Batch [870/1944], Loss: 0.0385\n",
      "Epoch [15/15], Batch [880/1944], Loss: 0.0205\n",
      "Epoch [15/15], Batch [890/1944], Loss: 0.0232\n",
      "Epoch [15/15], Batch [900/1944], Loss: 0.0252\n",
      "Epoch [15/15], Batch [910/1944], Loss: 0.0294\n",
      "Epoch [15/15], Batch [920/1944], Loss: 0.0322\n",
      "Epoch [15/15], Batch [930/1944], Loss: 0.0246\n",
      "Epoch [15/15], Batch [940/1944], Loss: 0.0165\n",
      "Epoch [15/15], Batch [950/1944], Loss: 0.0214\n",
      "Epoch [15/15], Batch [960/1944], Loss: 0.0244\n",
      "Epoch [15/15], Batch [970/1944], Loss: 0.0224\n",
      "Epoch [15/15], Batch [980/1944], Loss: 0.0229\n",
      "Epoch [15/15], Batch [990/1944], Loss: 0.0196\n",
      "Epoch [15/15], Batch [1000/1944], Loss: 0.0185\n",
      "Epoch [15/15], Batch [1010/1944], Loss: 0.0173\n",
      "Epoch [15/15], Batch [1020/1944], Loss: 0.0180\n",
      "Epoch [15/15], Batch [1030/1944], Loss: 0.0284\n",
      "Epoch [15/15], Batch [1040/1944], Loss: 0.0314\n",
      "Epoch [15/15], Batch [1050/1944], Loss: 0.0294\n",
      "Epoch [15/15], Batch [1060/1944], Loss: 0.0260\n",
      "Epoch [15/15], Batch [1070/1944], Loss: 0.0171\n",
      "Epoch [15/15], Batch [1080/1944], Loss: 0.0164\n",
      "Epoch [15/15], Batch [1090/1944], Loss: 0.0181\n",
      "Epoch [15/15], Batch [1100/1944], Loss: 0.0211\n",
      "Epoch [15/15], Batch [1110/1944], Loss: 0.0229\n",
      "Epoch [15/15], Batch [1120/1944], Loss: 0.0230\n",
      "Epoch [15/15], Batch [1130/1944], Loss: 0.0264\n",
      "Epoch [15/15], Batch [1140/1944], Loss: 0.0279\n",
      "Epoch [15/15], Batch [1150/1944], Loss: 0.0198\n",
      "Epoch [15/15], Batch [1160/1944], Loss: 0.0150\n",
      "Epoch [15/15], Batch [1170/1944], Loss: 0.0236\n",
      "Epoch [15/15], Batch [1180/1944], Loss: 0.0215\n",
      "Epoch [15/15], Batch [1190/1944], Loss: 0.0251\n",
      "Epoch [15/15], Batch [1200/1944], Loss: 0.0199\n",
      "Epoch [15/15], Batch [1210/1944], Loss: 0.0192\n",
      "Epoch [15/15], Batch [1220/1944], Loss: 0.0176\n",
      "Epoch [15/15], Batch [1230/1944], Loss: 0.0171\n",
      "Epoch [15/15], Batch [1240/1944], Loss: 0.0222\n",
      "Epoch [15/15], Batch [1250/1944], Loss: 0.0278\n",
      "Epoch [15/15], Batch [1260/1944], Loss: 0.0290\n",
      "Epoch [15/15], Batch [1270/1944], Loss: 0.0294\n",
      "Epoch [15/15], Batch [1280/1944], Loss: 0.0228\n",
      "Epoch [15/15], Batch [1290/1944], Loss: 0.0201\n",
      "Epoch [15/15], Batch [1300/1944], Loss: 0.0478\n",
      "Epoch [15/15], Batch [1310/1944], Loss: 0.0203\n",
      "Epoch [15/15], Batch [1320/1944], Loss: 0.0207\n",
      "Epoch [15/15], Batch [1330/1944], Loss: 0.0213\n",
      "Epoch [15/15], Batch [1340/1944], Loss: 0.0253\n",
      "Epoch [15/15], Batch [1350/1944], Loss: 0.0285\n",
      "Epoch [15/15], Batch [1360/1944], Loss: 0.0231\n",
      "Epoch [15/15], Batch [1370/1944], Loss: 0.0146\n",
      "Epoch [15/15], Batch [1380/1944], Loss: 0.0161\n",
      "Epoch [15/15], Batch [1390/1944], Loss: 0.0250\n",
      "Epoch [15/15], Batch [1400/1944], Loss: 0.0197\n",
      "Epoch [15/15], Batch [1410/1944], Loss: 0.0230\n",
      "Epoch [15/15], Batch [1420/1944], Loss: 0.0164\n",
      "Epoch [15/15], Batch [1430/1944], Loss: 0.0174\n",
      "Epoch [15/15], Batch [1440/1944], Loss: 0.0164\n",
      "Epoch [15/15], Batch [1450/1944], Loss: 0.0177\n",
      "Epoch [15/15], Batch [1460/1944], Loss: 0.0257\n",
      "Epoch [15/15], Batch [1470/1944], Loss: 0.0294\n",
      "Epoch [15/15], Batch [1480/1944], Loss: 0.0266\n",
      "Epoch [15/15], Batch [1490/1944], Loss: 0.0268\n",
      "Epoch [15/15], Batch [1500/1944], Loss: 0.0157\n",
      "Epoch [15/15], Batch [1510/1944], Loss: 0.0209\n",
      "Epoch [15/15], Batch [1520/1944], Loss: 0.0282\n",
      "Epoch [15/15], Batch [1530/1944], Loss: 0.0215\n",
      "Epoch [15/15], Batch [1540/1944], Loss: 0.0240\n",
      "Epoch [15/15], Batch [1550/1944], Loss: 0.0245\n",
      "Epoch [15/15], Batch [1560/1944], Loss: 0.0282\n",
      "Epoch [15/15], Batch [1570/1944], Loss: 0.0288\n",
      "Epoch [15/15], Batch [1580/1944], Loss: 0.0225\n",
      "Epoch [15/15], Batch [1590/1944], Loss: 0.0172\n",
      "Epoch [15/15], Batch [1600/1944], Loss: 0.0218\n",
      "Epoch [15/15], Batch [1610/1944], Loss: 0.0260\n",
      "Epoch [15/15], Batch [1620/1944], Loss: 0.0260\n",
      "Epoch [15/15], Batch [1630/1944], Loss: 0.0244\n",
      "Epoch [15/15], Batch [1640/1944], Loss: 0.0208\n",
      "Epoch [15/15], Batch [1650/1944], Loss: 0.0180\n",
      "Epoch [15/15], Batch [1660/1944], Loss: 0.0183\n",
      "Epoch [15/15], Batch [1670/1944], Loss: 0.0220\n",
      "Epoch [15/15], Batch [1680/1944], Loss: 0.0277\n",
      "Epoch [15/15], Batch [1690/1944], Loss: 0.0306\n",
      "Epoch [15/15], Batch [1700/1944], Loss: 0.0279\n",
      "Epoch [15/15], Batch [1710/1944], Loss: 0.0238\n",
      "Epoch [15/15], Batch [1720/1944], Loss: 0.0198\n",
      "Epoch [15/15], Batch [1730/1944], Loss: 0.0522\n",
      "Epoch [15/15], Batch [1740/1944], Loss: 0.0181\n",
      "Epoch [15/15], Batch [1750/1944], Loss: 0.0222\n",
      "Epoch [15/15], Batch [1760/1944], Loss: 0.0235\n",
      "Epoch [15/15], Batch [1770/1944], Loss: 0.0257\n",
      "Epoch [15/15], Batch [1780/1944], Loss: 0.0268\n",
      "Epoch [15/15], Batch [1790/1944], Loss: 0.0255\n",
      "Epoch [15/15], Batch [1800/1944], Loss: 0.0170\n",
      "Epoch [15/15], Batch [1810/1944], Loss: 0.0168\n",
      "Epoch [15/15], Batch [1820/1944], Loss: 0.0255\n",
      "Epoch [15/15], Batch [1830/1944], Loss: 0.0201\n",
      "Epoch [15/15], Batch [1840/1944], Loss: 0.0260\n",
      "Epoch [15/15], Batch [1850/1944], Loss: 0.0194\n",
      "Epoch [15/15], Batch [1860/1944], Loss: 0.0214\n",
      "Epoch [15/15], Batch [1870/1944], Loss: 0.0160\n",
      "Epoch [15/15], Batch [1880/1944], Loss: 0.0177\n",
      "Epoch [15/15], Batch [1890/1944], Loss: 0.0241\n",
      "Epoch [15/15], Batch [1900/1944], Loss: 0.0302\n",
      "Epoch [15/15], Batch [1910/1944], Loss: 0.0279\n",
      "Epoch [15/15], Batch [1920/1944], Loss: 0.0293\n",
      "Epoch [15/15], Batch [1930/1944], Loss: 0.0201\n",
      "Epoch [15/15], Batch [1940/1944], Loss: 0.0229\n",
      "Epoch [15/15], Average Loss: 0.0229\n",
      "Epoch [15/15], Validation Loss: 0.0895\n",
      "Epoch [15/15], Current Learning Rate: 0.000125\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# 假设 model、criterion、train_loader、test_loader 和 device 已经定义\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 设置总训练轮数为 15\n",
    "num_epochs = 15\n",
    "\n",
    "# 定义初始学习率\n",
    "initial_lr = 0.001\n",
    "\n",
    "# 定义优化器（Adam）\n",
    "optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
    "\n",
    "# 定义学习率调度器，每 5 个 epoch 将学习率减半\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # 检查损失异常\n",
    "        if torch.isnan(loss) or torch.isinf(loss):\n",
    "            print(f\"Loss is NaN or Inf at Epoch {epoch+1}, Batch {batch_idx+1}\")\n",
    "            break\n",
    "            \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # 梯度裁剪\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # 计算并记录训练损失\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(epoch_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item()\n",
    "        # 计算并记录验证损失\n",
    "        epoch_loss = running_loss / len(test_loader)\n",
    "        val_losses.append(epoch_loss)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # 更新学习率（每 5 个 epoch 减半）\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Current Learning Rate: {scheduler.get_last_lr()[0]}\")\n",
    "\n",
    "# 绘制损失变化图\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss', marker='o')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss', marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
